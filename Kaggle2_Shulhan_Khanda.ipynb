{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "2dbccbd6-138b-4f1b-9b23-fd60c7525c14",
    "_execution_state": "idle",
    "_uuid": "c9b1d5dff21d39260eb47af6fe7aac4bd03be233"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x))\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "59617b4b-d797-44ce-9142-05fbfd36aada",
    "_execution_state": "idle",
    "_uuid": "0e694d13459e3e200f6e2c6333c887cbad779ba9"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('all-2/train.csv')\n",
    "test = pd.read_csv('all-2/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "# macro['timestamp'] = pd.to_datetime(macro['timestamp']) \n",
    "\n",
    "train['year_month'] = train['timestamp'].dt.to_period('M')\n",
    "test['year_month'] = test['timestamp'].dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "3678529f-9d76-4853-88c5-4b2d230a85b6",
    "_execution_state": "idle",
    "_uuid": "3a32f51460a02fbe7a9122db55a740eb378dda97"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>material</th>\n",
       "      <th>build_year</th>\n",
       "      <th>num_room</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>state</th>\n",
       "      <th>product_type</th>\n",
       "      <th>sub_area</th>\n",
       "      <th>area_m</th>\n",
       "      <th>raion_popul</th>\n",
       "      <th>green_zone_part</th>\n",
       "      <th>indust_part</th>\n",
       "      <th>children_preschool</th>\n",
       "      <th>preschool_quota</th>\n",
       "      <th>preschool_education_centers_raion</th>\n",
       "      <th>children_school</th>\n",
       "      <th>school_quota</th>\n",
       "      <th>school_education_centers_raion</th>\n",
       "      <th>school_education_centers_top_20_raion</th>\n",
       "      <th>hospital_beds_raion</th>\n",
       "      <th>healthcare_centers_raion</th>\n",
       "      <th>university_top_20_raion</th>\n",
       "      <th>sport_objects_raion</th>\n",
       "      <th>additional_education_raion</th>\n",
       "      <th>culture_objects_top_25</th>\n",
       "      <th>culture_objects_top_25_raion</th>\n",
       "      <th>shopping_centers_raion</th>\n",
       "      <th>office_raion</th>\n",
       "      <th>thermal_power_plant_raion</th>\n",
       "      <th>incineration_raion</th>\n",
       "      <th>oil_chemistry_raion</th>\n",
       "      <th>radiation_raion</th>\n",
       "      <th>railroad_terminal_raion</th>\n",
       "      <th>big_market_raion</th>\n",
       "      <th>nuclear_reactor_raion</th>\n",
       "      <th>detention_facility_raion</th>\n",
       "      <th>full_all</th>\n",
       "      <th>male_f</th>\n",
       "      <th>female_f</th>\n",
       "      <th>young_all</th>\n",
       "      <th>young_male</th>\n",
       "      <th>young_female</th>\n",
       "      <th>work_all</th>\n",
       "      <th>work_male</th>\n",
       "      <th>work_female</th>\n",
       "      <th>ekder_all</th>\n",
       "      <th>ekder_male</th>\n",
       "      <th>ekder_female</th>\n",
       "      <th>0_6_all</th>\n",
       "      <th>0_6_male</th>\n",
       "      <th>0_6_female</th>\n",
       "      <th>7_14_all</th>\n",
       "      <th>7_14_male</th>\n",
       "      <th>7_14_female</th>\n",
       "      <th>0_17_all</th>\n",
       "      <th>0_17_male</th>\n",
       "      <th>0_17_female</th>\n",
       "      <th>16_29_all</th>\n",
       "      <th>16_29_male</th>\n",
       "      <th>16_29_female</th>\n",
       "      <th>0_13_all</th>\n",
       "      <th>0_13_male</th>\n",
       "      <th>0_13_female</th>\n",
       "      <th>raion_build_count_with_material_info</th>\n",
       "      <th>build_count_block</th>\n",
       "      <th>build_count_wood</th>\n",
       "      <th>build_count_frame</th>\n",
       "      <th>build_count_brick</th>\n",
       "      <th>build_count_monolith</th>\n",
       "      <th>build_count_panel</th>\n",
       "      <th>build_count_foam</th>\n",
       "      <th>build_count_slag</th>\n",
       "      <th>build_count_mix</th>\n",
       "      <th>raion_build_count_with_builddate_info</th>\n",
       "      <th>build_count_before_1920</th>\n",
       "      <th>build_count_1921-1945</th>\n",
       "      <th>build_count_1946-1970</th>\n",
       "      <th>build_count_1971-1995</th>\n",
       "      <th>build_count_after_1995</th>\n",
       "      <th>ID_metro</th>\n",
       "      <th>metro_min_avto</th>\n",
       "      <th>metro_km_avto</th>\n",
       "      <th>metro_min_walk</th>\n",
       "      <th>metro_km_walk</th>\n",
       "      <th>kindergarten_km</th>\n",
       "      <th>school_km</th>\n",
       "      <th>park_km</th>\n",
       "      <th>green_zone_km</th>\n",
       "      <th>industrial_km</th>\n",
       "      <th>water_treatment_km</th>\n",
       "      <th>cemetery_km</th>\n",
       "      <th>incineration_km</th>\n",
       "      <th>railroad_station_walk_km</th>\n",
       "      <th>railroad_station_walk_min</th>\n",
       "      <th>ID_railroad_station_walk</th>\n",
       "      <th>railroad_station_avto_km</th>\n",
       "      <th>railroad_station_avto_min</th>\n",
       "      <th>ID_railroad_station_avto</th>\n",
       "      <th>public_transport_station_km</th>\n",
       "      <th>public_transport_station_min_walk</th>\n",
       "      <th>water_km</th>\n",
       "      <th>water_1line</th>\n",
       "      <th>mkad_km</th>\n",
       "      <th>ttk_km</th>\n",
       "      <th>sadovoe_km</th>\n",
       "      <th>bulvar_ring_km</th>\n",
       "      <th>kremlin_km</th>\n",
       "      <th>big_road1_km</th>\n",
       "      <th>ID_big_road1</th>\n",
       "      <th>big_road1_1line</th>\n",
       "      <th>big_road2_km</th>\n",
       "      <th>ID_big_road2</th>\n",
       "      <th>railroad_km</th>\n",
       "      <th>railroad_1line</th>\n",
       "      <th>zd_vokzaly_avto_km</th>\n",
       "      <th>ID_railroad_terminal</th>\n",
       "      <th>bus_terminal_avto_km</th>\n",
       "      <th>ID_bus_terminal</th>\n",
       "      <th>oil_chemistry_km</th>\n",
       "      <th>nuclear_reactor_km</th>\n",
       "      <th>radiation_km</th>\n",
       "      <th>power_transmission_line_km</th>\n",
       "      <th>thermal_power_plant_km</th>\n",
       "      <th>ts_km</th>\n",
       "      <th>big_market_km</th>\n",
       "      <th>market_shop_km</th>\n",
       "      <th>fitness_km</th>\n",
       "      <th>swim_pool_km</th>\n",
       "      <th>ice_rink_km</th>\n",
       "      <th>stadium_km</th>\n",
       "      <th>basketball_km</th>\n",
       "      <th>hospice_morgue_km</th>\n",
       "      <th>detention_facility_km</th>\n",
       "      <th>public_healthcare_km</th>\n",
       "      <th>university_km</th>\n",
       "      <th>workplaces_km</th>\n",
       "      <th>shopping_centers_km</th>\n",
       "      <th>office_km</th>\n",
       "      <th>additional_education_km</th>\n",
       "      <th>preschool_km</th>\n",
       "      <th>big_church_km</th>\n",
       "      <th>church_synagogue_km</th>\n",
       "      <th>mosque_km</th>\n",
       "      <th>theater_km</th>\n",
       "      <th>museum_km</th>\n",
       "      <th>exhibition_km</th>\n",
       "      <th>catering_km</th>\n",
       "      <th>ecology</th>\n",
       "      <th>green_part_500</th>\n",
       "      <th>prom_part_500</th>\n",
       "      <th>office_count_500</th>\n",
       "      <th>office_sqm_500</th>\n",
       "      <th>trc_count_500</th>\n",
       "      <th>trc_sqm_500</th>\n",
       "      <th>cafe_count_500</th>\n",
       "      <th>cafe_sum_500_min_price_avg</th>\n",
       "      <th>cafe_sum_500_max_price_avg</th>\n",
       "      <th>cafe_avg_price_500</th>\n",
       "      <th>cafe_count_500_na_price</th>\n",
       "      <th>cafe_count_500_price_500</th>\n",
       "      <th>cafe_count_500_price_1000</th>\n",
       "      <th>cafe_count_500_price_1500</th>\n",
       "      <th>cafe_count_500_price_2500</th>\n",
       "      <th>cafe_count_500_price_4000</th>\n",
       "      <th>cafe_count_500_price_high</th>\n",
       "      <th>big_church_count_500</th>\n",
       "      <th>church_count_500</th>\n",
       "      <th>mosque_count_500</th>\n",
       "      <th>leisure_count_500</th>\n",
       "      <th>sport_count_500</th>\n",
       "      <th>market_count_500</th>\n",
       "      <th>green_part_1000</th>\n",
       "      <th>prom_part_1000</th>\n",
       "      <th>office_count_1000</th>\n",
       "      <th>office_sqm_1000</th>\n",
       "      <th>trc_count_1000</th>\n",
       "      <th>trc_sqm_1000</th>\n",
       "      <th>cafe_count_1000</th>\n",
       "      <th>cafe_sum_1000_min_price_avg</th>\n",
       "      <th>cafe_sum_1000_max_price_avg</th>\n",
       "      <th>cafe_avg_price_1000</th>\n",
       "      <th>cafe_count_1000_na_price</th>\n",
       "      <th>cafe_count_1000_price_500</th>\n",
       "      <th>cafe_count_1000_price_1000</th>\n",
       "      <th>cafe_count_1000_price_1500</th>\n",
       "      <th>cafe_count_1000_price_2500</th>\n",
       "      <th>cafe_count_1000_price_4000</th>\n",
       "      <th>cafe_count_1000_price_high</th>\n",
       "      <th>big_church_count_1000</th>\n",
       "      <th>church_count_1000</th>\n",
       "      <th>mosque_count_1000</th>\n",
       "      <th>leisure_count_1000</th>\n",
       "      <th>sport_count_1000</th>\n",
       "      <th>market_count_1000</th>\n",
       "      <th>green_part_1500</th>\n",
       "      <th>prom_part_1500</th>\n",
       "      <th>office_count_1500</th>\n",
       "      <th>office_sqm_1500</th>\n",
       "      <th>trc_count_1500</th>\n",
       "      <th>trc_sqm_1500</th>\n",
       "      <th>cafe_count_1500</th>\n",
       "      <th>cafe_sum_1500_min_price_avg</th>\n",
       "      <th>cafe_sum_1500_max_price_avg</th>\n",
       "      <th>cafe_avg_price_1500</th>\n",
       "      <th>cafe_count_1500_na_price</th>\n",
       "      <th>cafe_count_1500_price_500</th>\n",
       "      <th>cafe_count_1500_price_1000</th>\n",
       "      <th>cafe_count_1500_price_1500</th>\n",
       "      <th>cafe_count_1500_price_2500</th>\n",
       "      <th>cafe_count_1500_price_4000</th>\n",
       "      <th>cafe_count_1500_price_high</th>\n",
       "      <th>big_church_count_1500</th>\n",
       "      <th>church_count_1500</th>\n",
       "      <th>mosque_count_1500</th>\n",
       "      <th>leisure_count_1500</th>\n",
       "      <th>sport_count_1500</th>\n",
       "      <th>market_count_1500</th>\n",
       "      <th>green_part_2000</th>\n",
       "      <th>prom_part_2000</th>\n",
       "      <th>office_count_2000</th>\n",
       "      <th>office_sqm_2000</th>\n",
       "      <th>trc_count_2000</th>\n",
       "      <th>trc_sqm_2000</th>\n",
       "      <th>cafe_count_2000</th>\n",
       "      <th>cafe_sum_2000_min_price_avg</th>\n",
       "      <th>cafe_sum_2000_max_price_avg</th>\n",
       "      <th>cafe_avg_price_2000</th>\n",
       "      <th>cafe_count_2000_na_price</th>\n",
       "      <th>cafe_count_2000_price_500</th>\n",
       "      <th>cafe_count_2000_price_1000</th>\n",
       "      <th>cafe_count_2000_price_1500</th>\n",
       "      <th>cafe_count_2000_price_2500</th>\n",
       "      <th>cafe_count_2000_price_4000</th>\n",
       "      <th>cafe_count_2000_price_high</th>\n",
       "      <th>big_church_count_2000</th>\n",
       "      <th>church_count_2000</th>\n",
       "      <th>mosque_count_2000</th>\n",
       "      <th>leisure_count_2000</th>\n",
       "      <th>sport_count_2000</th>\n",
       "      <th>market_count_2000</th>\n",
       "      <th>green_part_3000</th>\n",
       "      <th>prom_part_3000</th>\n",
       "      <th>office_count_3000</th>\n",
       "      <th>office_sqm_3000</th>\n",
       "      <th>trc_count_3000</th>\n",
       "      <th>trc_sqm_3000</th>\n",
       "      <th>cafe_count_3000</th>\n",
       "      <th>cafe_sum_3000_min_price_avg</th>\n",
       "      <th>cafe_sum_3000_max_price_avg</th>\n",
       "      <th>cafe_avg_price_3000</th>\n",
       "      <th>cafe_count_3000_na_price</th>\n",
       "      <th>cafe_count_3000_price_500</th>\n",
       "      <th>cafe_count_3000_price_1000</th>\n",
       "      <th>cafe_count_3000_price_1500</th>\n",
       "      <th>cafe_count_3000_price_2500</th>\n",
       "      <th>cafe_count_3000_price_4000</th>\n",
       "      <th>cafe_count_3000_price_high</th>\n",
       "      <th>big_church_count_3000</th>\n",
       "      <th>church_count_3000</th>\n",
       "      <th>mosque_count_3000</th>\n",
       "      <th>leisure_count_3000</th>\n",
       "      <th>sport_count_3000</th>\n",
       "      <th>market_count_3000</th>\n",
       "      <th>green_part_5000</th>\n",
       "      <th>prom_part_5000</th>\n",
       "      <th>office_count_5000</th>\n",
       "      <th>office_sqm_5000</th>\n",
       "      <th>trc_count_5000</th>\n",
       "      <th>trc_sqm_5000</th>\n",
       "      <th>cafe_count_5000</th>\n",
       "      <th>cafe_sum_5000_min_price_avg</th>\n",
       "      <th>cafe_sum_5000_max_price_avg</th>\n",
       "      <th>cafe_avg_price_5000</th>\n",
       "      <th>cafe_count_5000_na_price</th>\n",
       "      <th>cafe_count_5000_price_500</th>\n",
       "      <th>cafe_count_5000_price_1000</th>\n",
       "      <th>cafe_count_5000_price_1500</th>\n",
       "      <th>cafe_count_5000_price_2500</th>\n",
       "      <th>cafe_count_5000_price_4000</th>\n",
       "      <th>cafe_count_5000_price_high</th>\n",
       "      <th>big_church_count_5000</th>\n",
       "      <th>church_count_5000</th>\n",
       "      <th>mosque_count_5000</th>\n",
       "      <th>leisure_count_5000</th>\n",
       "      <th>sport_count_5000</th>\n",
       "      <th>market_count_5000</th>\n",
       "      <th>price</th>\n",
       "      <th>year_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2014-12-26</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>OwnerOccupier</td>\n",
       "      <td>Nagornoe</td>\n",
       "      <td>5293464.965</td>\n",
       "      <td>77878</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.196</td>\n",
       "      <td>4713</td>\n",
       "      <td>2279.000</td>\n",
       "      <td>4</td>\n",
       "      <td>5212</td>\n",
       "      <td>10027.000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>115352</td>\n",
       "      <td>52813</td>\n",
       "      <td>62539</td>\n",
       "      <td>10600</td>\n",
       "      <td>5422</td>\n",
       "      <td>5178</td>\n",
       "      <td>49882</td>\n",
       "      <td>24603</td>\n",
       "      <td>25279</td>\n",
       "      <td>17396</td>\n",
       "      <td>5130</td>\n",
       "      <td>12266</td>\n",
       "      <td>4713</td>\n",
       "      <td>2390</td>\n",
       "      <td>2323</td>\n",
       "      <td>5212</td>\n",
       "      <td>2677</td>\n",
       "      <td>2535</td>\n",
       "      <td>11749</td>\n",
       "      <td>6001</td>\n",
       "      <td>5748</td>\n",
       "      <td>22625</td>\n",
       "      <td>11064</td>\n",
       "      <td>11561</td>\n",
       "      <td>9319</td>\n",
       "      <td>4737</td>\n",
       "      <td>4582</td>\n",
       "      <td>244.000</td>\n",
       "      <td>71.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>105.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>64.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>243.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>153.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>33.000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.425</td>\n",
       "      <td>5.023</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.352</td>\n",
       "      <td>3.461</td>\n",
       "      <td>7.728</td>\n",
       "      <td>3.054</td>\n",
       "      <td>36.644</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.442</td>\n",
       "      <td>5.700</td>\n",
       "      <td>42</td>\n",
       "      <td>0.121</td>\n",
       "      <td>1.446</td>\n",
       "      <td>0.238</td>\n",
       "      <td>no</td>\n",
       "      <td>9.829</td>\n",
       "      <td>3.417</td>\n",
       "      <td>6.611</td>\n",
       "      <td>8.059</td>\n",
       "      <td>8.673</td>\n",
       "      <td>0.869</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>3.417</td>\n",
       "      <td>4</td>\n",
       "      <td>0.787</td>\n",
       "      <td>no</td>\n",
       "      <td>8.464</td>\n",
       "      <td>32</td>\n",
       "      <td>4.425</td>\n",
       "      <td>2</td>\n",
       "      <td>12.657</td>\n",
       "      <td>3.504</td>\n",
       "      <td>1.508</td>\n",
       "      <td>0.564</td>\n",
       "      <td>3.670</td>\n",
       "      <td>3.012</td>\n",
       "      <td>10.023</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.703</td>\n",
       "      <td>3.052</td>\n",
       "      <td>9.736</td>\n",
       "      <td>5.639</td>\n",
       "      <td>2.039</td>\n",
       "      <td>2.035</td>\n",
       "      <td>12.799</td>\n",
       "      <td>2.342</td>\n",
       "      <td>1.569</td>\n",
       "      <td>1.637</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.607</td>\n",
       "      <td>1.125</td>\n",
       "      <td>0.605</td>\n",
       "      <td>2.566</td>\n",
       "      <td>3.103</td>\n",
       "      <td>3.455</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.426</td>\n",
       "      <td>poor</td>\n",
       "      <td>26.210</td>\n",
       "      <td>45.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>500.000</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>750.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.250</td>\n",
       "      <td>25.680</td>\n",
       "      <td>4</td>\n",
       "      <td>283683</td>\n",
       "      <td>1</td>\n",
       "      <td>15970</td>\n",
       "      <td>4</td>\n",
       "      <td>400.000</td>\n",
       "      <td>750.000</td>\n",
       "      <td>575.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12.510</td>\n",
       "      <td>16.580</td>\n",
       "      <td>11</td>\n",
       "      <td>553411</td>\n",
       "      <td>6</td>\n",
       "      <td>286770</td>\n",
       "      <td>20</td>\n",
       "      <td>735.290</td>\n",
       "      <td>1235.290</td>\n",
       "      <td>985.290</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10.400</td>\n",
       "      <td>20.580</td>\n",
       "      <td>16</td>\n",
       "      <td>710575</td>\n",
       "      <td>9</td>\n",
       "      <td>393270</td>\n",
       "      <td>42</td>\n",
       "      <td>665.790</td>\n",
       "      <td>1157.890</td>\n",
       "      <td>911.840</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8.770</td>\n",
       "      <td>19.500</td>\n",
       "      <td>28</td>\n",
       "      <td>930766</td>\n",
       "      <td>17</td>\n",
       "      <td>772270</td>\n",
       "      <td>100</td>\n",
       "      <td>705.320</td>\n",
       "      <td>1186.170</td>\n",
       "      <td>945.740</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>15.190</td>\n",
       "      <td>19.830</td>\n",
       "      <td>92</td>\n",
       "      <td>3478168</td>\n",
       "      <td>49</td>\n",
       "      <td>2235425</td>\n",
       "      <td>348</td>\n",
       "      <td>755.990</td>\n",
       "      <td>1263.470</td>\n",
       "      <td>1009.730</td>\n",
       "      <td>14</td>\n",
       "      <td>85</td>\n",
       "      <td>113</td>\n",
       "      <td>91</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>75</td>\n",
       "      <td>10</td>\n",
       "      <td>15318960</td>\n",
       "      <td>2014-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-10-04</td>\n",
       "      <td>64</td>\n",
       "      <td>64.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>OwnerOccupier</td>\n",
       "      <td>Poselenie Sosenskoe</td>\n",
       "      <td>66772450.690</td>\n",
       "      <td>9553</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.072</td>\n",
       "      <td>656</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>629</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>13890</td>\n",
       "      <td>6584</td>\n",
       "      <td>7307</td>\n",
       "      <td>1370</td>\n",
       "      <td>709</td>\n",
       "      <td>661</td>\n",
       "      <td>6127</td>\n",
       "      <td>3237</td>\n",
       "      <td>2890</td>\n",
       "      <td>2056</td>\n",
       "      <td>583</td>\n",
       "      <td>1473</td>\n",
       "      <td>656</td>\n",
       "      <td>340</td>\n",
       "      <td>316</td>\n",
       "      <td>629</td>\n",
       "      <td>325</td>\n",
       "      <td>305</td>\n",
       "      <td>1542</td>\n",
       "      <td>801</td>\n",
       "      <td>742</td>\n",
       "      <td>3134</td>\n",
       "      <td>1753</td>\n",
       "      <td>1381</td>\n",
       "      <td>1207</td>\n",
       "      <td>623</td>\n",
       "      <td>584</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>132</td>\n",
       "      <td>8.081</td>\n",
       "      <td>6.307</td>\n",
       "      <td>75.679</td>\n",
       "      <td>6.307</td>\n",
       "      <td>3.710</td>\n",
       "      <td>3.740</td>\n",
       "      <td>4.116</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.236</td>\n",
       "      <td>6.070</td>\n",
       "      <td>2.023</td>\n",
       "      <td>10.287</td>\n",
       "      <td>10.463</td>\n",
       "      <td>125.560</td>\n",
       "      <td>47.000</td>\n",
       "      <td>13.556</td>\n",
       "      <td>12.896</td>\n",
       "      <td>105</td>\n",
       "      <td>0.222</td>\n",
       "      <td>2.665</td>\n",
       "      <td>0.493</td>\n",
       "      <td>no</td>\n",
       "      <td>3.348</td>\n",
       "      <td>16.418</td>\n",
       "      <td>19.383</td>\n",
       "      <td>20.543</td>\n",
       "      <td>21.277</td>\n",
       "      <td>1.035</td>\n",
       "      <td>38</td>\n",
       "      <td>no</td>\n",
       "      <td>3.348</td>\n",
       "      <td>1</td>\n",
       "      <td>4.612</td>\n",
       "      <td>no</td>\n",
       "      <td>22.472</td>\n",
       "      <td>32</td>\n",
       "      <td>7.443</td>\n",
       "      <td>8</td>\n",
       "      <td>22.528</td>\n",
       "      <td>14.973</td>\n",
       "      <td>4.356</td>\n",
       "      <td>0.680</td>\n",
       "      <td>9.814</td>\n",
       "      <td>4.801</td>\n",
       "      <td>4.187</td>\n",
       "      <td>6.318</td>\n",
       "      <td>0.358</td>\n",
       "      <td>8.127</td>\n",
       "      <td>8.664</td>\n",
       "      <td>12.024</td>\n",
       "      <td>7.099</td>\n",
       "      <td>5.182</td>\n",
       "      <td>27.902</td>\n",
       "      <td>5.864</td>\n",
       "      <td>8.846</td>\n",
       "      <td>5.813</td>\n",
       "      <td>4.194</td>\n",
       "      <td>3.335</td>\n",
       "      <td>4.164</td>\n",
       "      <td>3.740</td>\n",
       "      <td>5.146</td>\n",
       "      <td>0.372</td>\n",
       "      <td>4.526</td>\n",
       "      <td>11.585</td>\n",
       "      <td>11.663</td>\n",
       "      <td>8.538</td>\n",
       "      <td>0.829</td>\n",
       "      <td>no data</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16.170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.590</td>\n",
       "      <td>11.830</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>500.000</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>750.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.700</td>\n",
       "      <td>7.810</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>500.000</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>750.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28.720</td>\n",
       "      <td>6.220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>500.000</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>750.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32.120</td>\n",
       "      <td>6.720</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1750.000</td>\n",
       "      <td>2875.000</td>\n",
       "      <td>2312.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34.010</td>\n",
       "      <td>8.700</td>\n",
       "      <td>1</td>\n",
       "      <td>85159</td>\n",
       "      <td>1</td>\n",
       "      <td>189076</td>\n",
       "      <td>14</td>\n",
       "      <td>1108.330</td>\n",
       "      <td>1833.330</td>\n",
       "      <td>1470.830</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6080000</td>\n",
       "      <td>2012-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-02-05</td>\n",
       "      <td>83</td>\n",
       "      <td>44.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1985.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Krylatskoe</td>\n",
       "      <td>12164477.110</td>\n",
       "      <td>78507</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4611</td>\n",
       "      <td>3092.000</td>\n",
       "      <td>7</td>\n",
       "      <td>5067</td>\n",
       "      <td>7478.000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>67710</td>\n",
       "      <td>33382</td>\n",
       "      <td>34328</td>\n",
       "      <td>10175</td>\n",
       "      <td>5105</td>\n",
       "      <td>5070</td>\n",
       "      <td>48620</td>\n",
       "      <td>25579</td>\n",
       "      <td>23041</td>\n",
       "      <td>19712</td>\n",
       "      <td>6368</td>\n",
       "      <td>13344</td>\n",
       "      <td>4611</td>\n",
       "      <td>2331</td>\n",
       "      <td>2280</td>\n",
       "      <td>5067</td>\n",
       "      <td>2522</td>\n",
       "      <td>2545</td>\n",
       "      <td>10892</td>\n",
       "      <td>5480</td>\n",
       "      <td>5412</td>\n",
       "      <td>13540</td>\n",
       "      <td>6769</td>\n",
       "      <td>6771</td>\n",
       "      <td>9168</td>\n",
       "      <td>4583</td>\n",
       "      <td>4585</td>\n",
       "      <td>188.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>66.000</td>\n",
       "      <td>27.000</td>\n",
       "      <td>89.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>188.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>81.000</td>\n",
       "      <td>103.000</td>\n",
       "      <td>92</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.280</td>\n",
       "      <td>3.359</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.155</td>\n",
       "      <td>2.089</td>\n",
       "      <td>19.965</td>\n",
       "      <td>3.966</td>\n",
       "      <td>15.897</td>\n",
       "      <td>4.389</td>\n",
       "      <td>52.672</td>\n",
       "      <td>10.000</td>\n",
       "      <td>5.179</td>\n",
       "      <td>6.127</td>\n",
       "      <td>22</td>\n",
       "      <td>0.143</td>\n",
       "      <td>1.722</td>\n",
       "      <td>1.064</td>\n",
       "      <td>no</td>\n",
       "      <td>2.271</td>\n",
       "      <td>7.909</td>\n",
       "      <td>11.136</td>\n",
       "      <td>12.087</td>\n",
       "      <td>13.016</td>\n",
       "      <td>1.922</td>\n",
       "      <td>29</td>\n",
       "      <td>no</td>\n",
       "      <td>2.271</td>\n",
       "      <td>1</td>\n",
       "      <td>2.454</td>\n",
       "      <td>no</td>\n",
       "      <td>13.735</td>\n",
       "      <td>50</td>\n",
       "      <td>13.063</td>\n",
       "      <td>1</td>\n",
       "      <td>22.243</td>\n",
       "      <td>6.289</td>\n",
       "      <td>1.637</td>\n",
       "      <td>3.398</td>\n",
       "      <td>6.833</td>\n",
       "      <td>1.550</td>\n",
       "      <td>23.428</td>\n",
       "      <td>8.680</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.677</td>\n",
       "      <td>4.908</td>\n",
       "      <td>9.715</td>\n",
       "      <td>5.531</td>\n",
       "      <td>0.485</td>\n",
       "      <td>1.585</td>\n",
       "      <td>2.317</td>\n",
       "      <td>8.734</td>\n",
       "      <td>1.743</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.817</td>\n",
       "      <td>1.850</td>\n",
       "      <td>0.475</td>\n",
       "      <td>1.039</td>\n",
       "      <td>1.136</td>\n",
       "      <td>6.635</td>\n",
       "      <td>7.868</td>\n",
       "      <td>7.608</td>\n",
       "      <td>4.063</td>\n",
       "      <td>0.147</td>\n",
       "      <td>good</td>\n",
       "      <td>11.620</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>37840</td>\n",
       "      <td>10</td>\n",
       "      <td>762.500</td>\n",
       "      <td>1250.000</td>\n",
       "      <td>1006.250</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20.060</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>37500</td>\n",
       "      <td>5</td>\n",
       "      <td>60081</td>\n",
       "      <td>16</td>\n",
       "      <td>885.710</td>\n",
       "      <td>1464.290</td>\n",
       "      <td>1175.000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>28.840</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>37500</td>\n",
       "      <td>5</td>\n",
       "      <td>60081</td>\n",
       "      <td>21</td>\n",
       "      <td>955.560</td>\n",
       "      <td>1583.330</td>\n",
       "      <td>1269.440</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>33.580</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4</td>\n",
       "      <td>291742</td>\n",
       "      <td>8</td>\n",
       "      <td>399081</td>\n",
       "      <td>38</td>\n",
       "      <td>890.630</td>\n",
       "      <td>1500.000</td>\n",
       "      <td>1195.310</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>35.610</td>\n",
       "      <td>2.290</td>\n",
       "      <td>5</td>\n",
       "      <td>392221</td>\n",
       "      <td>9</td>\n",
       "      <td>405581</td>\n",
       "      <td>55</td>\n",
       "      <td>987.500</td>\n",
       "      <td>1645.830</td>\n",
       "      <td>1316.670</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>35.230</td>\n",
       "      <td>4.580</td>\n",
       "      <td>19</td>\n",
       "      <td>755824</td>\n",
       "      <td>19</td>\n",
       "      <td>1015107</td>\n",
       "      <td>95</td>\n",
       "      <td>923.260</td>\n",
       "      <td>1523.260</td>\n",
       "      <td>1223.260</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>17000000</td>\n",
       "      <td>2014-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2012-07-26</td>\n",
       "      <td>71</td>\n",
       "      <td>49.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Matushkino</td>\n",
       "      <td>4708040.470</td>\n",
       "      <td>38075</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.310</td>\n",
       "      <td>2448</td>\n",
       "      <td>2080.000</td>\n",
       "      <td>3</td>\n",
       "      <td>2748</td>\n",
       "      <td>3885.000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>85219</td>\n",
       "      <td>39138</td>\n",
       "      <td>46081</td>\n",
       "      <td>5572</td>\n",
       "      <td>2978</td>\n",
       "      <td>2594</td>\n",
       "      <td>22413</td>\n",
       "      <td>11273</td>\n",
       "      <td>11140</td>\n",
       "      <td>10090</td>\n",
       "      <td>2911</td>\n",
       "      <td>7179</td>\n",
       "      <td>2448</td>\n",
       "      <td>1294</td>\n",
       "      <td>1154</td>\n",
       "      <td>2748</td>\n",
       "      <td>1478</td>\n",
       "      <td>1270</td>\n",
       "      <td>6332</td>\n",
       "      <td>3374</td>\n",
       "      <td>2958</td>\n",
       "      <td>21787</td>\n",
       "      <td>10891</td>\n",
       "      <td>10896</td>\n",
       "      <td>4828</td>\n",
       "      <td>2603</td>\n",
       "      <td>2225</td>\n",
       "      <td>107.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>58.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>107.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>46.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>46.000</td>\n",
       "      <td>12</td>\n",
       "      <td>29.617</td>\n",
       "      <td>25.998</td>\n",
       "      <td>294.672</td>\n",
       "      <td>24.556</td>\n",
       "      <td>1.633</td>\n",
       "      <td>0.519</td>\n",
       "      <td>17.186</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.210</td>\n",
       "      <td>4.467</td>\n",
       "      <td>2.411</td>\n",
       "      <td>28.327</td>\n",
       "      <td>4.936</td>\n",
       "      <td>59.228</td>\n",
       "      <td>28.000</td>\n",
       "      <td>5.317</td>\n",
       "      <td>7.047</td>\n",
       "      <td>28</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.210</td>\n",
       "      <td>no</td>\n",
       "      <td>19.973</td>\n",
       "      <td>33.349</td>\n",
       "      <td>36.082</td>\n",
       "      <td>36.818</td>\n",
       "      <td>38.128</td>\n",
       "      <td>0.798</td>\n",
       "      <td>14</td>\n",
       "      <td>no</td>\n",
       "      <td>4.795</td>\n",
       "      <td>49</td>\n",
       "      <td>1.573</td>\n",
       "      <td>no</td>\n",
       "      <td>37.650</td>\n",
       "      <td>83</td>\n",
       "      <td>32.456</td>\n",
       "      <td>1</td>\n",
       "      <td>44.809</td>\n",
       "      <td>22.981</td>\n",
       "      <td>22.291</td>\n",
       "      <td>19.008</td>\n",
       "      <td>22.947</td>\n",
       "      <td>20.709</td>\n",
       "      <td>39.826</td>\n",
       "      <td>4.035</td>\n",
       "      <td>2.045</td>\n",
       "      <td>3.262</td>\n",
       "      <td>3.204</td>\n",
       "      <td>30.400</td>\n",
       "      <td>18.226</td>\n",
       "      <td>2.160</td>\n",
       "      <td>29.331</td>\n",
       "      <td>3.837</td>\n",
       "      <td>3.287</td>\n",
       "      <td>1.083</td>\n",
       "      <td>1.928</td>\n",
       "      <td>0.997</td>\n",
       "      <td>5.176</td>\n",
       "      <td>0.519</td>\n",
       "      <td>2.818</td>\n",
       "      <td>2.249</td>\n",
       "      <td>29.519</td>\n",
       "      <td>2.511</td>\n",
       "      <td>3.052</td>\n",
       "      <td>22.548</td>\n",
       "      <td>0.417</td>\n",
       "      <td>no data</td>\n",
       "      <td>12.950</td>\n",
       "      <td>17.860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300.000</td>\n",
       "      <td>500.000</td>\n",
       "      <td>400.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.480</td>\n",
       "      <td>28.800</td>\n",
       "      <td>1</td>\n",
       "      <td>20038</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>340.000</td>\n",
       "      <td>600.000</td>\n",
       "      <td>470.000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.290</td>\n",
       "      <td>22.370</td>\n",
       "      <td>1</td>\n",
       "      <td>20038</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>340.000</td>\n",
       "      <td>600.000</td>\n",
       "      <td>470.000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.210</td>\n",
       "      <td>13.110</td>\n",
       "      <td>2</td>\n",
       "      <td>45038</td>\n",
       "      <td>2</td>\n",
       "      <td>32000</td>\n",
       "      <td>8</td>\n",
       "      <td>525.000</td>\n",
       "      <td>875.000</td>\n",
       "      <td>700.000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.340</td>\n",
       "      <td>8.890</td>\n",
       "      <td>2</td>\n",
       "      <td>45038</td>\n",
       "      <td>3</td>\n",
       "      <td>34100</td>\n",
       "      <td>10</td>\n",
       "      <td>500.000</td>\n",
       "      <td>850.000</td>\n",
       "      <td>675.000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20.840</td>\n",
       "      <td>7.280</td>\n",
       "      <td>3</td>\n",
       "      <td>51038</td>\n",
       "      <td>7</td>\n",
       "      <td>49700</td>\n",
       "      <td>14</td>\n",
       "      <td>507.140</td>\n",
       "      <td>857.140</td>\n",
       "      <td>682.140</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>990000</td>\n",
       "      <td>2012-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2014-10-29</td>\n",
       "      <td>60</td>\n",
       "      <td>42.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1970.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Gol'janovo</td>\n",
       "      <td>14286990.830</td>\n",
       "      <td>157010</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.194</td>\n",
       "      <td>7751</td>\n",
       "      <td>5041.000</td>\n",
       "      <td>6</td>\n",
       "      <td>8004</td>\n",
       "      <td>11081.000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>125.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>12327</td>\n",
       "      <td>5588</td>\n",
       "      <td>6739</td>\n",
       "      <td>16831</td>\n",
       "      <td>8637</td>\n",
       "      <td>8194</td>\n",
       "      <td>98260</td>\n",
       "      <td>47405</td>\n",
       "      <td>50855</td>\n",
       "      <td>41919</td>\n",
       "      <td>12424</td>\n",
       "      <td>29495</td>\n",
       "      <td>7751</td>\n",
       "      <td>3941</td>\n",
       "      <td>3810</td>\n",
       "      <td>8004</td>\n",
       "      <td>4152</td>\n",
       "      <td>3852</td>\n",
       "      <td>18912</td>\n",
       "      <td>9716</td>\n",
       "      <td>9196</td>\n",
       "      <td>2780</td>\n",
       "      <td>1351</td>\n",
       "      <td>1429</td>\n",
       "      <td>14694</td>\n",
       "      <td>7551</td>\n",
       "      <td>7143</td>\n",
       "      <td>371.000</td>\n",
       "      <td>88.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>68.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>207.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>371.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>221.000</td>\n",
       "      <td>129.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20</td>\n",
       "      <td>3.372</td>\n",
       "      <td>2.295</td>\n",
       "      <td>27.545</td>\n",
       "      <td>2.295</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.568</td>\n",
       "      <td>16.725</td>\n",
       "      <td>0.866</td>\n",
       "      <td>13.716</td>\n",
       "      <td>6.880</td>\n",
       "      <td>82.557</td>\n",
       "      <td>18.000</td>\n",
       "      <td>8.158</td>\n",
       "      <td>8.410</td>\n",
       "      <td>136</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.148</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.223</td>\n",
       "      <td>9.622</td>\n",
       "      <td>11.781</td>\n",
       "      <td>12.526</td>\n",
       "      <td>14.324</td>\n",
       "      <td>1.223</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>1.632</td>\n",
       "      <td>12</td>\n",
       "      <td>1.976</td>\n",
       "      <td>no</td>\n",
       "      <td>12.236</td>\n",
       "      <td>97</td>\n",
       "      <td>2.225</td>\n",
       "      <td>7</td>\n",
       "      <td>8.388</td>\n",
       "      <td>17.795</td>\n",
       "      <td>2.104</td>\n",
       "      <td>2.789</td>\n",
       "      <td>2.723</td>\n",
       "      <td>8.876</td>\n",
       "      <td>13.366</td>\n",
       "      <td>2.165</td>\n",
       "      <td>0.617</td>\n",
       "      <td>3.194</td>\n",
       "      <td>6.009</td>\n",
       "      <td>6.563</td>\n",
       "      <td>3.109</td>\n",
       "      <td>2.661</td>\n",
       "      <td>10.582</td>\n",
       "      <td>1.736</td>\n",
       "      <td>3.565</td>\n",
       "      <td>1.174</td>\n",
       "      <td>1.277</td>\n",
       "      <td>1.767</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.477</td>\n",
       "      <td>8.458</td>\n",
       "      <td>12.391</td>\n",
       "      <td>8.085</td>\n",
       "      <td>4.430</td>\n",
       "      <td>0.251</td>\n",
       "      <td>good</td>\n",
       "      <td>18.490</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300.000</td>\n",
       "      <td>500.000</td>\n",
       "      <td>400.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.850</td>\n",
       "      <td>3.600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>366.670</td>\n",
       "      <td>666.670</td>\n",
       "      <td>516.670</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.250</td>\n",
       "      <td>2.830</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>320000</td>\n",
       "      <td>6</td>\n",
       "      <td>520.000</td>\n",
       "      <td>900.000</td>\n",
       "      <td>710.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>25.680</td>\n",
       "      <td>5.600</td>\n",
       "      <td>2</td>\n",
       "      <td>142200</td>\n",
       "      <td>3</td>\n",
       "      <td>380110</td>\n",
       "      <td>12</td>\n",
       "      <td>518.180</td>\n",
       "      <td>909.090</td>\n",
       "      <td>713.640</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>27.510</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4</td>\n",
       "      <td>179700</td>\n",
       "      <td>7</td>\n",
       "      <td>441142</td>\n",
       "      <td>26</td>\n",
       "      <td>608.330</td>\n",
       "      <td>1020.830</td>\n",
       "      <td>814.580</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>36.400</td>\n",
       "      <td>9.080</td>\n",
       "      <td>11</td>\n",
       "      <td>300476</td>\n",
       "      <td>16</td>\n",
       "      <td>509176</td>\n",
       "      <td>54</td>\n",
       "      <td>656.000</td>\n",
       "      <td>1110.000</td>\n",
       "      <td>883.000</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>7900000</td>\n",
       "      <td>2014-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  timestamp  full_sq  life_sq  floor  max_floor  material  build_year  \\\n",
       "0   0 2014-12-26        1    1.000  1.000      1.000     1.000       1.000   \n",
       "1   1 2012-10-04       64   64.000 16.000        nan       nan         nan   \n",
       "2   2 2014-02-05       83   44.000  9.000     17.000     1.000    1985.000   \n",
       "3   3 2012-07-26       71   49.000  2.000        nan       nan         nan   \n",
       "4   4 2014-10-29       60   42.000  9.000      9.000     1.000    1970.000   \n",
       "\n",
       "   num_room  kitch_sq  state   product_type             sub_area       area_m  \\\n",
       "0     1.000     1.000  1.000  OwnerOccupier             Nagornoe  5293464.965   \n",
       "1       nan       nan    nan  OwnerOccupier  Poselenie Sosenskoe 66772450.690   \n",
       "2     3.000    10.000  3.000     Investment           Krylatskoe 12164477.110   \n",
       "3       nan       nan    nan     Investment           Matushkino  4708040.470   \n",
       "4     3.000     6.000  2.000     Investment           Gol'janovo 14286990.830   \n",
       "\n",
       "   raion_popul  green_zone_part  indust_part  children_preschool  \\\n",
       "0        77878            0.023        0.196                4713   \n",
       "1         9553            0.336        0.072                 656   \n",
       "2        78507            0.297        0.000                4611   \n",
       "3        38075            0.272        0.310                2448   \n",
       "4       157010            0.389        0.194                7751   \n",
       "\n",
       "   preschool_quota  preschool_education_centers_raion  children_school  \\\n",
       "0         2279.000                                  4             5212   \n",
       "1              nan                                  0              629   \n",
       "2         3092.000                                  7             5067   \n",
       "3         2080.000                                  3             2748   \n",
       "4         5041.000                                  6             8004   \n",
       "\n",
       "   school_quota  school_education_centers_raion  \\\n",
       "0     10027.000                               8   \n",
       "1           nan                               0   \n",
       "2      7478.000                               7   \n",
       "3      3885.000                               4   \n",
       "4     11081.000                               7   \n",
       "\n",
       "   school_education_centers_top_20_raion  hospital_beds_raion  \\\n",
       "0                                      1                  nan   \n",
       "1                                      0                  nan   \n",
       "2                                      0                  nan   \n",
       "3                                      0                  nan   \n",
       "4                                      0              125.000   \n",
       "\n",
       "   healthcare_centers_raion  university_top_20_raion  sport_objects_raion  \\\n",
       "0                         3                        0                    2   \n",
       "1                         0                        0                    1   \n",
       "2                         2                        0                   14   \n",
       "3                         0                        0                    0   \n",
       "4                         3                        0                    5   \n",
       "\n",
       "   additional_education_raion culture_objects_top_25  \\\n",
       "0                           2                     no   \n",
       "1                           0                     no   \n",
       "2                           1                     no   \n",
       "3                           0                     no   \n",
       "4                           3                     no   \n",
       "\n",
       "   culture_objects_top_25_raion  shopping_centers_raion  office_raion  \\\n",
       "0                             0                       2             6   \n",
       "1                             0                       0             1   \n",
       "2                             0                       6             4   \n",
       "3                             0                       0             1   \n",
       "4                             0                       5             3   \n",
       "\n",
       "  thermal_power_plant_raion incineration_raion oil_chemistry_raion  \\\n",
       "0                        no                 no                  no   \n",
       "1                        no                 no                  no   \n",
       "2                        no                 no                  no   \n",
       "3                        no                 no                  no   \n",
       "4                        no                 no                  no   \n",
       "\n",
       "  radiation_raion railroad_terminal_raion big_market_raion  \\\n",
       "0              no                      no               no   \n",
       "1              no                      no              yes   \n",
       "2              no                      no               no   \n",
       "3              no                      no               no   \n",
       "4             yes                      no               no   \n",
       "\n",
       "  nuclear_reactor_raion detention_facility_raion  full_all  male_f  female_f  \\\n",
       "0                    no                       no    115352   52813     62539   \n",
       "1                    no                       no     13890    6584      7307   \n",
       "2                    no                      yes     67710   33382     34328   \n",
       "3                    no                       no     85219   39138     46081   \n",
       "4                    no                       no     12327    5588      6739   \n",
       "\n",
       "   young_all  young_male  young_female  work_all  work_male  work_female  \\\n",
       "0      10600        5422          5178     49882      24603        25279   \n",
       "1       1370         709           661      6127       3237         2890   \n",
       "2      10175        5105          5070     48620      25579        23041   \n",
       "3       5572        2978          2594     22413      11273        11140   \n",
       "4      16831        8637          8194     98260      47405        50855   \n",
       "\n",
       "   ekder_all  ekder_male  ekder_female  0_6_all  0_6_male  0_6_female  \\\n",
       "0      17396        5130         12266     4713      2390        2323   \n",
       "1       2056         583          1473      656       340         316   \n",
       "2      19712        6368         13344     4611      2331        2280   \n",
       "3      10090        2911          7179     2448      1294        1154   \n",
       "4      41919       12424         29495     7751      3941        3810   \n",
       "\n",
       "   7_14_all  7_14_male  7_14_female  0_17_all  0_17_male  0_17_female  \\\n",
       "0      5212       2677         2535     11749       6001         5748   \n",
       "1       629        325          305      1542        801          742   \n",
       "2      5067       2522         2545     10892       5480         5412   \n",
       "3      2748       1478         1270      6332       3374         2958   \n",
       "4      8004       4152         3852     18912       9716         9196   \n",
       "\n",
       "   16_29_all  16_29_male  16_29_female  0_13_all  0_13_male  0_13_female  \\\n",
       "0      22625       11064         11561      9319       4737         4582   \n",
       "1       3134        1753          1381      1207        623          584   \n",
       "2      13540        6769          6771      9168       4583         4585   \n",
       "3      21787       10891         10896      4828       2603         2225   \n",
       "4       2780        1351          1429     14694       7551         7143   \n",
       "\n",
       "   raion_build_count_with_material_info  build_count_block  build_count_wood  \\\n",
       "0                               244.000             71.000             0.000   \n",
       "1                                   nan                nan               nan   \n",
       "2                               188.000              3.000             3.000   \n",
       "3                               107.000             23.000             0.000   \n",
       "4                               371.000             88.000             0.000   \n",
       "\n",
       "   build_count_frame  build_count_brick  build_count_monolith  \\\n",
       "0              0.000            105.000                 4.000   \n",
       "1                nan                nan                   nan   \n",
       "2              0.000             66.000                27.000   \n",
       "3              0.000             10.000                16.000   \n",
       "4              0.000             68.000                 8.000   \n",
       "\n",
       "   build_count_panel  build_count_foam  build_count_slag  build_count_mix  \\\n",
       "0             64.000             0.000             0.000            0.000   \n",
       "1                nan               nan               nan              nan   \n",
       "2             89.000             0.000             0.000            0.000   \n",
       "3             58.000             0.000             0.000            0.000   \n",
       "4            207.000             0.000             0.000            0.000   \n",
       "\n",
       "   raion_build_count_with_builddate_info  build_count_before_1920  \\\n",
       "0                                243.000                    0.000   \n",
       "1                                    nan                      nan   \n",
       "2                                188.000                    1.000   \n",
       "3                                107.000                    0.000   \n",
       "4                                371.000                    0.000   \n",
       "\n",
       "   build_count_1921-1945  build_count_1946-1970  build_count_1971-1995  \\\n",
       "0                  1.000                153.000                 56.000   \n",
       "1                    nan                    nan                    nan   \n",
       "2                  0.000                  3.000                 81.000   \n",
       "3                  0.000                 46.000                 15.000   \n",
       "4                  1.000                221.000                129.000   \n",
       "\n",
       "   build_count_after_1995  ID_metro  metro_min_avto  metro_km_avto  \\\n",
       "0                  33.000        18           0.531          0.425   \n",
       "1                     nan       132           8.081          6.307   \n",
       "2                 103.000        92           0.935          0.280   \n",
       "3                  46.000        12          29.617         25.998   \n",
       "4                  20.000        20           3.372          2.295   \n",
       "\n",
       "   metro_min_walk  metro_km_walk  kindergarten_km  school_km  park_km  \\\n",
       "0           5.023          0.419            0.829      0.607    0.760   \n",
       "1          75.679          6.307            3.710      3.740    4.116   \n",
       "2           3.359          0.280            0.448      0.475    0.397   \n",
       "3         294.672         24.556            1.633      0.519   17.186   \n",
       "4          27.545          2.295            0.181      0.310    0.260   \n",
       "\n",
       "   green_zone_km  industrial_km  water_treatment_km  cemetery_km  \\\n",
       "0          0.223          0.000               4.352        3.461   \n",
       "1          0.604          0.236               6.070        2.023   \n",
       "2          0.155          2.089              19.965        3.966   \n",
       "3          0.041          0.210               4.467        2.411   \n",
       "4          0.052          0.568              16.725        0.866   \n",
       "\n",
       "   incineration_km  railroad_station_walk_km  railroad_station_walk_min  \\\n",
       "0            7.728                     3.054                     36.644   \n",
       "1           10.287                    10.463                    125.560   \n",
       "2           15.897                     4.389                     52.672   \n",
       "3           28.327                     4.936                     59.228   \n",
       "4           13.716                     6.880                     82.557   \n",
       "\n",
       "   ID_railroad_station_walk  railroad_station_avto_km  \\\n",
       "0                     2.000                     4.442   \n",
       "1                    47.000                    13.556   \n",
       "2                    10.000                     5.179   \n",
       "3                    28.000                     5.317   \n",
       "4                    18.000                     8.158   \n",
       "\n",
       "   railroad_station_avto_min  ID_railroad_station_avto  \\\n",
       "0                      5.700                        42   \n",
       "1                     12.896                       105   \n",
       "2                      6.127                        22   \n",
       "3                      7.047                        28   \n",
       "4                      8.410                       136   \n",
       "\n",
       "   public_transport_station_km  public_transport_station_min_walk  water_km  \\\n",
       "0                        0.121                              1.446     0.238   \n",
       "1                        0.222                              2.665     0.493   \n",
       "2                        0.143                              1.722     1.064   \n",
       "3                        0.053                              0.639     0.210   \n",
       "4                        0.075                              0.901     0.148   \n",
       "\n",
       "  water_1line  mkad_km  ttk_km  sadovoe_km  bulvar_ring_km  kremlin_km  \\\n",
       "0          no    9.829   3.417       6.611           8.059       8.673   \n",
       "1          no    3.348  16.418      19.383          20.543      21.277   \n",
       "2          no    2.271   7.909      11.136          12.087      13.016   \n",
       "3          no   19.973  33.349      36.082          36.818      38.128   \n",
       "4         yes    1.223   9.622      11.781          12.526      14.324   \n",
       "\n",
       "   big_road1_km  ID_big_road1 big_road1_1line  big_road2_km  ID_big_road2  \\\n",
       "0         0.869             2              no         3.417             4   \n",
       "1         1.035            38              no         3.348             1   \n",
       "2         1.922            29              no         2.271             1   \n",
       "3         0.798            14              no         4.795            49   \n",
       "4         1.223             1              no         1.632            12   \n",
       "\n",
       "   railroad_km railroad_1line  zd_vokzaly_avto_km  ID_railroad_terminal  \\\n",
       "0        0.787             no               8.464                    32   \n",
       "1        4.612             no              22.472                    32   \n",
       "2        2.454             no              13.735                    50   \n",
       "3        1.573             no              37.650                    83   \n",
       "4        1.976             no              12.236                    97   \n",
       "\n",
       "   bus_terminal_avto_km  ID_bus_terminal  oil_chemistry_km  \\\n",
       "0                 4.425                2            12.657   \n",
       "1                 7.443                8            22.528   \n",
       "2                13.063                1            22.243   \n",
       "3                32.456                1            44.809   \n",
       "4                 2.225                7             8.388   \n",
       "\n",
       "   nuclear_reactor_km  radiation_km  power_transmission_line_km  \\\n",
       "0               3.504         1.508                       0.564   \n",
       "1              14.973         4.356                       0.680   \n",
       "2               6.289         1.637                       3.398   \n",
       "3              22.981        22.291                      19.008   \n",
       "4              17.795         2.104                       2.789   \n",
       "\n",
       "   thermal_power_plant_km  ts_km  big_market_km  market_shop_km  fitness_km  \\\n",
       "0                   3.670  3.012         10.023           1.625       0.703   \n",
       "1                   9.814  4.801          4.187           6.318       0.358   \n",
       "2                   6.833  1.550         23.428           8.680       0.116   \n",
       "3                  22.947 20.709         39.826           4.035       2.045   \n",
       "4                   2.723  8.876         13.366           2.165       0.617   \n",
       "\n",
       "   swim_pool_km  ice_rink_km  stadium_km  basketball_km  hospice_morgue_km  \\\n",
       "0         3.052        9.736       5.639          2.039              2.035   \n",
       "1         8.127        8.664      12.024          7.099              5.182   \n",
       "2         0.677        4.908       9.715          5.531              0.485   \n",
       "3         3.262        3.204      30.400         18.226              2.160   \n",
       "4         3.194        6.009       6.563          3.109              2.661   \n",
       "\n",
       "   detention_facility_km  public_healthcare_km  university_km  workplaces_km  \\\n",
       "0                 12.799                 2.342          1.569          1.637   \n",
       "1                 27.902                 5.864          8.846          5.813   \n",
       "2                  1.585                 2.317          8.734          1.743   \n",
       "3                 29.331                 3.837          3.287          1.083   \n",
       "4                 10.582                 1.736          3.565          1.174   \n",
       "\n",
       "   shopping_centers_km  office_km  additional_education_km  preschool_km  \\\n",
       "0                0.841      0.565                    0.672         0.607   \n",
       "1                4.194      3.335                    4.164         3.740   \n",
       "2                0.116      0.817                    1.850         0.475   \n",
       "3                1.928      0.997                    5.176         0.519   \n",
       "4                1.277      1.767                    0.408         0.310   \n",
       "\n",
       "   big_church_km  church_synagogue_km  mosque_km  theater_km  museum_km  \\\n",
       "0          1.125                0.605      2.566       3.103      3.455   \n",
       "1          5.146                0.372      4.526      11.585     11.663   \n",
       "2          1.039                1.136      6.635       7.868      7.608   \n",
       "3          2.818                2.249     29.519       2.511      3.052   \n",
       "4          0.472                0.477      8.458      12.391      8.085   \n",
       "\n",
       "   exhibition_km  catering_km  ecology  green_part_500  prom_part_500  \\\n",
       "0          0.929        0.426     poor          26.210         45.000   \n",
       "1          8.538        0.829  no data           0.000         16.170   \n",
       "2          4.063        0.147     good          11.620          0.000   \n",
       "3         22.548        0.417  no data          12.950         17.860   \n",
       "4          4.430        0.251     good          18.490          0.000   \n",
       "\n",
       "   office_count_500  office_sqm_500  trc_count_500  trc_sqm_500  \\\n",
       "0                 0               0              0            0   \n",
       "1                 0               0              0            0   \n",
       "2                 0               0              3        37840   \n",
       "3                 0               0              0            0   \n",
       "4                 0               0              0            0   \n",
       "\n",
       "   cafe_count_500  cafe_sum_500_min_price_avg  cafe_sum_500_max_price_avg  \\\n",
       "0               1                     500.000                    1000.000   \n",
       "1               0                         nan                         nan   \n",
       "2              10                     762.500                    1250.000   \n",
       "3               1                     300.000                     500.000   \n",
       "4               1                     300.000                     500.000   \n",
       "\n",
       "   cafe_avg_price_500  cafe_count_500_na_price  cafe_count_500_price_500  \\\n",
       "0             750.000                        0                         0   \n",
       "1                 nan                        0                         0   \n",
       "2            1006.250                        2                         2   \n",
       "3             400.000                        0                         1   \n",
       "4             400.000                        0                         1   \n",
       "\n",
       "   cafe_count_500_price_1000  cafe_count_500_price_1500  \\\n",
       "0                          1                          0   \n",
       "1                          0                          0   \n",
       "2                          2                          3   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "\n",
       "   cafe_count_500_price_2500  cafe_count_500_price_4000  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          1                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "\n",
       "   cafe_count_500_price_high  big_church_count_500  church_count_500  \\\n",
       "0                          0                     0                 0   \n",
       "1                          0                     0                 1   \n",
       "2                          0                     0                 0   \n",
       "3                          0                     0                 0   \n",
       "4                          0                     1                 1   \n",
       "\n",
       "   mosque_count_500  leisure_count_500  sport_count_500  market_count_500  \\\n",
       "0                 0                  0                0                 0   \n",
       "1                 0                  0                1                 0   \n",
       "2                 0                  0                2                 0   \n",
       "3                 0                  0                0                 0   \n",
       "4                 0                  0                0                 0   \n",
       "\n",
       "   green_part_1000  prom_part_1000  office_count_1000  office_sqm_1000  \\\n",
       "0           20.250          25.680                  4           283683   \n",
       "1            3.590          11.830                  0                0   \n",
       "2           20.060           0.000                  2            37500   \n",
       "3           23.480          28.800                  1            20038   \n",
       "4           19.850           3.600                  0                0   \n",
       "\n",
       "   trc_count_1000  trc_sqm_1000  cafe_count_1000  cafe_sum_1000_min_price_avg  \\\n",
       "0               1         15970                4                      400.000   \n",
       "1               0             0                1                      500.000   \n",
       "2               5         60081               16                      885.710   \n",
       "3               0             0                5                      340.000   \n",
       "4               0             0                4                      366.670   \n",
       "\n",
       "   cafe_sum_1000_max_price_avg  cafe_avg_price_1000  cafe_count_1000_na_price  \\\n",
       "0                      750.000              575.000                         0   \n",
       "1                     1000.000              750.000                         0   \n",
       "2                     1464.290             1175.000                         2   \n",
       "3                      600.000              470.000                         0   \n",
       "4                      666.670              516.670                         1   \n",
       "\n",
       "   cafe_count_1000_price_500  cafe_count_1000_price_1000  \\\n",
       "0                          2                           2   \n",
       "1                          0                           1   \n",
       "2                          3                           4   \n",
       "3                          4                           1   \n",
       "4                          2                           1   \n",
       "\n",
       "   cafe_count_1000_price_1500  cafe_count_1000_price_2500  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           4                           2   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   cafe_count_1000_price_4000  cafe_count_1000_price_high  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           1                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   big_church_count_1000  church_count_1000  mosque_count_1000  \\\n",
       "0                      0                  1                  0   \n",
       "1                      0                  1                  0   \n",
       "2                      0                  0                  0   \n",
       "3                      0                  0                  0   \n",
       "4                      1                  1                  0   \n",
       "\n",
       "   leisure_count_1000  sport_count_1000  market_count_1000  green_part_1500  \\\n",
       "0                   1                 2                  1           12.510   \n",
       "1                   0                 1                  0           17.700   \n",
       "2                   0                 4                  0           28.840   \n",
       "3                   0                 0                  0           24.290   \n",
       "4                   0                 2                  0           27.250   \n",
       "\n",
       "   prom_part_1500  office_count_1500  office_sqm_1500  trc_count_1500  \\\n",
       "0          16.580                 11           553411               6   \n",
       "1           7.810                  0                0               0   \n",
       "2           0.000                  2            37500               5   \n",
       "3          22.370                  1            20038               0   \n",
       "4           2.830                  0                0               1   \n",
       "\n",
       "   trc_sqm_1500  cafe_count_1500  cafe_sum_1500_min_price_avg  \\\n",
       "0        286770               20                      735.290   \n",
       "1             0                1                      500.000   \n",
       "2         60081               21                      955.560   \n",
       "3             0                5                      340.000   \n",
       "4        320000                6                      520.000   \n",
       "\n",
       "   cafe_sum_1500_max_price_avg  cafe_avg_price_1500  cafe_count_1500_na_price  \\\n",
       "0                     1235.290              985.290                         3   \n",
       "1                     1000.000              750.000                         0   \n",
       "2                     1583.330             1269.440                         3   \n",
       "3                      600.000              470.000                         0   \n",
       "4                      900.000              710.000                         1   \n",
       "\n",
       "   cafe_count_1500_price_500  cafe_count_1500_price_1000  \\\n",
       "0                          5                           5   \n",
       "1                          0                           1   \n",
       "2                          4                           5   \n",
       "3                          4                           1   \n",
       "4                          2                           2   \n",
       "\n",
       "   cafe_count_1500_price_1500  cafe_count_1500_price_2500  \\\n",
       "0                           4                           3   \n",
       "1                           0                           0   \n",
       "2                           4                           3   \n",
       "3                           0                           0   \n",
       "4                           1                           0   \n",
       "\n",
       "   cafe_count_1500_price_4000  cafe_count_1500_price_high  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           2                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   big_church_count_1500  church_count_1500  mosque_count_1500  \\\n",
       "0                      1                  2                  0   \n",
       "1                      0                  2                  0   \n",
       "2                      1                  3                  0   \n",
       "3                      0                  0                  0   \n",
       "4                      2                  1                  0   \n",
       "\n",
       "   leisure_count_1500  sport_count_1500  market_count_1500  green_part_2000  \\\n",
       "0                   3                 4                  1           10.400   \n",
       "1                   0                 1                  0           28.720   \n",
       "2                   0                 9                  0           33.580   \n",
       "3                   0                 0                  0           28.210   \n",
       "4                   0                 4                  0           25.680   \n",
       "\n",
       "   prom_part_2000  office_count_2000  office_sqm_2000  trc_count_2000  \\\n",
       "0          20.580                 16           710575               9   \n",
       "1           6.220                  0                0               0   \n",
       "2           0.000                  4           291742               8   \n",
       "3          13.110                  2            45038               2   \n",
       "4           5.600                  2           142200               3   \n",
       "\n",
       "   trc_sqm_2000  cafe_count_2000  cafe_sum_2000_min_price_avg  \\\n",
       "0        393270               42                      665.790   \n",
       "1             0                1                      500.000   \n",
       "2        399081               38                      890.630   \n",
       "3         32000                8                      525.000   \n",
       "4        380110               12                      518.180   \n",
       "\n",
       "   cafe_sum_2000_max_price_avg  cafe_avg_price_2000  cafe_count_2000_na_price  \\\n",
       "0                     1157.890              911.840                         4   \n",
       "1                     1000.000              750.000                         0   \n",
       "2                     1500.000             1195.310                         6   \n",
       "3                      875.000              700.000                         0   \n",
       "4                      909.090              713.640                         1   \n",
       "\n",
       "   cafe_count_2000_price_500  cafe_count_2000_price_1000  \\\n",
       "0                         11                          17   \n",
       "1                          0                           1   \n",
       "2                          5                          13   \n",
       "3                          4                           2   \n",
       "4                          4                           5   \n",
       "\n",
       "   cafe_count_2000_price_1500  cafe_count_2000_price_2500  \\\n",
       "0                           5                           4   \n",
       "1                           0                           0   \n",
       "2                           7                           4   \n",
       "3                           2                           0   \n",
       "4                           2                           0   \n",
       "\n",
       "   cafe_count_2000_price_4000  cafe_count_2000_price_high  \\\n",
       "0                           1                           0   \n",
       "1                           0                           0   \n",
       "2                           3                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   big_church_count_2000  church_count_2000  mosque_count_2000  \\\n",
       "0                      1                  3                  0   \n",
       "1                      0                  3                  0   \n",
       "2                      1                  5                  0   \n",
       "3                      0                  0                  0   \n",
       "4                      2                  1                  0   \n",
       "\n",
       "   leisure_count_2000  sport_count_2000  market_count_2000  green_part_3000  \\\n",
       "0                   3                10                  2            8.770   \n",
       "1                   0                 1                  0           32.120   \n",
       "2                   0                13                  0           35.610   \n",
       "3                   1                 0                  0           26.340   \n",
       "4                   0                 8                  2           27.510   \n",
       "\n",
       "   prom_part_3000  office_count_3000  office_sqm_3000  trc_count_3000  \\\n",
       "0          19.500                 28           930766              17   \n",
       "1           6.720                  0                0               0   \n",
       "2           2.290                  5           392221               9   \n",
       "3           8.890                  2            45038               3   \n",
       "4          10.000                  4           179700               7   \n",
       "\n",
       "   trc_sqm_3000  cafe_count_3000  cafe_sum_3000_min_price_avg  \\\n",
       "0        772270              100                      705.320   \n",
       "1             0                4                     1750.000   \n",
       "2        405581               55                      987.500   \n",
       "3         34100               10                      500.000   \n",
       "4        441142               26                      608.330   \n",
       "\n",
       "   cafe_sum_3000_max_price_avg  cafe_avg_price_3000  cafe_count_3000_na_price  \\\n",
       "0                     1186.170              945.740                         6   \n",
       "1                     2875.000             2312.500                         0   \n",
       "2                     1645.830             1316.670                         7   \n",
       "3                      850.000              675.000                         0   \n",
       "4                     1020.830              814.580                         2   \n",
       "\n",
       "   cafe_count_3000_price_500  cafe_count_3000_price_1000  \\\n",
       "0                         26                          32   \n",
       "1                          0                           1   \n",
       "2                          8                          18   \n",
       "3                          5                           3   \n",
       "4                          7                           9   \n",
       "\n",
       "   cafe_count_3000_price_1500  cafe_count_3000_price_2500  \\\n",
       "0                          25                          10   \n",
       "1                           0                           1   \n",
       "2                           9                           7   \n",
       "3                           2                           0   \n",
       "4                           8                           0   \n",
       "\n",
       "   cafe_count_3000_price_4000  cafe_count_3000_price_high  \\\n",
       "0                           1                           0   \n",
       "1                           2                           0   \n",
       "2                           5                           1   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   big_church_count_3000  church_count_3000  mosque_count_3000  \\\n",
       "0                      4                 12                  1   \n",
       "1                      0                  4                  0   \n",
       "2                      2                  8                  0   \n",
       "3                      1                  2                  0   \n",
       "4                      3                  3                  0   \n",
       "\n",
       "   leisure_count_3000  sport_count_3000  market_count_3000  green_part_5000  \\\n",
       "0                   4                31                  8           15.190   \n",
       "1                   0                 1                  0           34.010   \n",
       "2                   0                17                  0           35.230   \n",
       "3                   1                 4                  1           20.840   \n",
       "4                   0                13                  2           36.400   \n",
       "\n",
       "   prom_part_5000  office_count_5000  office_sqm_5000  trc_count_5000  \\\n",
       "0          19.830                 92          3478168              49   \n",
       "1           8.700                  1            85159               1   \n",
       "2           4.580                 19           755824              19   \n",
       "3           7.280                  3            51038               7   \n",
       "4           9.080                 11           300476              16   \n",
       "\n",
       "   trc_sqm_5000  cafe_count_5000  cafe_sum_5000_min_price_avg  \\\n",
       "0       2235425              348                      755.990   \n",
       "1        189076               14                     1108.330   \n",
       "2       1015107               95                      923.260   \n",
       "3         49700               14                      507.140   \n",
       "4        509176               54                      656.000   \n",
       "\n",
       "   cafe_sum_5000_max_price_avg  cafe_avg_price_5000  cafe_count_5000_na_price  \\\n",
       "0                     1263.470             1009.730                        14   \n",
       "1                     1833.330             1470.830                         2   \n",
       "2                     1523.260             1223.260                         9   \n",
       "3                      857.140              682.140                         0   \n",
       "4                     1110.000              883.000                         4   \n",
       "\n",
       "   cafe_count_5000_price_500  cafe_count_5000_price_1000  \\\n",
       "0                         85                         113   \n",
       "1                          1                           4   \n",
       "2                         18                          25   \n",
       "3                          7                           4   \n",
       "4                         16                          18   \n",
       "\n",
       "   cafe_count_5000_price_1500  cafe_count_5000_price_2500  \\\n",
       "0                          91                          36   \n",
       "1                           3                           2   \n",
       "2                          23                          13   \n",
       "3                           3                           0   \n",
       "4                          12                           3   \n",
       "\n",
       "   cafe_count_5000_price_4000  cafe_count_5000_price_high  \\\n",
       "0                           7                           2   \n",
       "1                           2                           0   \n",
       "2                           6                           1   \n",
       "3                           0                           0   \n",
       "4                           1                           0   \n",
       "\n",
       "   big_church_count_5000  church_count_5000  mosque_count_5000  \\\n",
       "0                     15                 33                  1   \n",
       "1                      0                 13                  1   \n",
       "2                      8                 18                  0   \n",
       "3                      1                  3                  0   \n",
       "4                      5                  8                  0   \n",
       "\n",
       "   leisure_count_5000  sport_count_5000  market_count_5000     price  \\\n",
       "0                  12                75                 10  15318960   \n",
       "1                   0                 6                  1   6080000   \n",
       "2                   1                52                  0  17000000   \n",
       "3                   2                 8                  2    990000   \n",
       "4                   1                34                  5   7900000   \n",
       "\n",
       "  year_month  \n",
       "0    2014-12  \n",
       "1    2012-10  \n",
       "2    2014-02  \n",
       "3    2012-07  \n",
       "4    2014-10  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "ff37c1ba-8679-49e0-b3c8-9c53d01b1b04",
    "_execution_state": "idle",
    "_uuid": "816b1463b3dd0daf44949a1fa15ebfbc0e2f1235"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>material</th>\n",
       "      <th>build_year</th>\n",
       "      <th>num_room</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>state</th>\n",
       "      <th>product_type</th>\n",
       "      <th>sub_area</th>\n",
       "      <th>area_m</th>\n",
       "      <th>raion_popul</th>\n",
       "      <th>green_zone_part</th>\n",
       "      <th>indust_part</th>\n",
       "      <th>children_preschool</th>\n",
       "      <th>preschool_quota</th>\n",
       "      <th>preschool_education_centers_raion</th>\n",
       "      <th>children_school</th>\n",
       "      <th>school_quota</th>\n",
       "      <th>school_education_centers_raion</th>\n",
       "      <th>school_education_centers_top_20_raion</th>\n",
       "      <th>hospital_beds_raion</th>\n",
       "      <th>healthcare_centers_raion</th>\n",
       "      <th>university_top_20_raion</th>\n",
       "      <th>sport_objects_raion</th>\n",
       "      <th>additional_education_raion</th>\n",
       "      <th>culture_objects_top_25</th>\n",
       "      <th>culture_objects_top_25_raion</th>\n",
       "      <th>shopping_centers_raion</th>\n",
       "      <th>office_raion</th>\n",
       "      <th>thermal_power_plant_raion</th>\n",
       "      <th>incineration_raion</th>\n",
       "      <th>oil_chemistry_raion</th>\n",
       "      <th>radiation_raion</th>\n",
       "      <th>railroad_terminal_raion</th>\n",
       "      <th>big_market_raion</th>\n",
       "      <th>nuclear_reactor_raion</th>\n",
       "      <th>detention_facility_raion</th>\n",
       "      <th>full_all</th>\n",
       "      <th>male_f</th>\n",
       "      <th>female_f</th>\n",
       "      <th>young_all</th>\n",
       "      <th>young_male</th>\n",
       "      <th>young_female</th>\n",
       "      <th>work_all</th>\n",
       "      <th>work_male</th>\n",
       "      <th>work_female</th>\n",
       "      <th>ekder_all</th>\n",
       "      <th>ekder_male</th>\n",
       "      <th>ekder_female</th>\n",
       "      <th>0_6_all</th>\n",
       "      <th>0_6_male</th>\n",
       "      <th>0_6_female</th>\n",
       "      <th>7_14_all</th>\n",
       "      <th>7_14_male</th>\n",
       "      <th>7_14_female</th>\n",
       "      <th>0_17_all</th>\n",
       "      <th>0_17_male</th>\n",
       "      <th>0_17_female</th>\n",
       "      <th>16_29_all</th>\n",
       "      <th>16_29_male</th>\n",
       "      <th>16_29_female</th>\n",
       "      <th>0_13_all</th>\n",
       "      <th>0_13_male</th>\n",
       "      <th>0_13_female</th>\n",
       "      <th>raion_build_count_with_material_info</th>\n",
       "      <th>build_count_block</th>\n",
       "      <th>build_count_wood</th>\n",
       "      <th>build_count_frame</th>\n",
       "      <th>build_count_brick</th>\n",
       "      <th>build_count_monolith</th>\n",
       "      <th>build_count_panel</th>\n",
       "      <th>build_count_foam</th>\n",
       "      <th>build_count_slag</th>\n",
       "      <th>build_count_mix</th>\n",
       "      <th>raion_build_count_with_builddate_info</th>\n",
       "      <th>build_count_before_1920</th>\n",
       "      <th>build_count_1921-1945</th>\n",
       "      <th>build_count_1946-1970</th>\n",
       "      <th>build_count_1971-1995</th>\n",
       "      <th>build_count_after_1995</th>\n",
       "      <th>ID_metro</th>\n",
       "      <th>metro_min_avto</th>\n",
       "      <th>metro_km_avto</th>\n",
       "      <th>metro_min_walk</th>\n",
       "      <th>metro_km_walk</th>\n",
       "      <th>kindergarten_km</th>\n",
       "      <th>school_km</th>\n",
       "      <th>park_km</th>\n",
       "      <th>green_zone_km</th>\n",
       "      <th>industrial_km</th>\n",
       "      <th>water_treatment_km</th>\n",
       "      <th>cemetery_km</th>\n",
       "      <th>incineration_km</th>\n",
       "      <th>railroad_station_walk_km</th>\n",
       "      <th>railroad_station_walk_min</th>\n",
       "      <th>ID_railroad_station_walk</th>\n",
       "      <th>railroad_station_avto_km</th>\n",
       "      <th>railroad_station_avto_min</th>\n",
       "      <th>ID_railroad_station_avto</th>\n",
       "      <th>public_transport_station_km</th>\n",
       "      <th>public_transport_station_min_walk</th>\n",
       "      <th>water_km</th>\n",
       "      <th>water_1line</th>\n",
       "      <th>mkad_km</th>\n",
       "      <th>ttk_km</th>\n",
       "      <th>sadovoe_km</th>\n",
       "      <th>bulvar_ring_km</th>\n",
       "      <th>kremlin_km</th>\n",
       "      <th>big_road1_km</th>\n",
       "      <th>ID_big_road1</th>\n",
       "      <th>big_road1_1line</th>\n",
       "      <th>big_road2_km</th>\n",
       "      <th>ID_big_road2</th>\n",
       "      <th>railroad_km</th>\n",
       "      <th>railroad_1line</th>\n",
       "      <th>zd_vokzaly_avto_km</th>\n",
       "      <th>ID_railroad_terminal</th>\n",
       "      <th>bus_terminal_avto_km</th>\n",
       "      <th>ID_bus_terminal</th>\n",
       "      <th>oil_chemistry_km</th>\n",
       "      <th>nuclear_reactor_km</th>\n",
       "      <th>radiation_km</th>\n",
       "      <th>power_transmission_line_km</th>\n",
       "      <th>thermal_power_plant_km</th>\n",
       "      <th>ts_km</th>\n",
       "      <th>big_market_km</th>\n",
       "      <th>market_shop_km</th>\n",
       "      <th>fitness_km</th>\n",
       "      <th>swim_pool_km</th>\n",
       "      <th>ice_rink_km</th>\n",
       "      <th>stadium_km</th>\n",
       "      <th>basketball_km</th>\n",
       "      <th>hospice_morgue_km</th>\n",
       "      <th>detention_facility_km</th>\n",
       "      <th>public_healthcare_km</th>\n",
       "      <th>university_km</th>\n",
       "      <th>workplaces_km</th>\n",
       "      <th>shopping_centers_km</th>\n",
       "      <th>office_km</th>\n",
       "      <th>additional_education_km</th>\n",
       "      <th>preschool_km</th>\n",
       "      <th>big_church_km</th>\n",
       "      <th>church_synagogue_km</th>\n",
       "      <th>mosque_km</th>\n",
       "      <th>theater_km</th>\n",
       "      <th>museum_km</th>\n",
       "      <th>exhibition_km</th>\n",
       "      <th>catering_km</th>\n",
       "      <th>ecology</th>\n",
       "      <th>green_part_500</th>\n",
       "      <th>prom_part_500</th>\n",
       "      <th>office_count_500</th>\n",
       "      <th>office_sqm_500</th>\n",
       "      <th>trc_count_500</th>\n",
       "      <th>trc_sqm_500</th>\n",
       "      <th>cafe_count_500</th>\n",
       "      <th>cafe_sum_500_min_price_avg</th>\n",
       "      <th>cafe_sum_500_max_price_avg</th>\n",
       "      <th>cafe_avg_price_500</th>\n",
       "      <th>cafe_count_500_na_price</th>\n",
       "      <th>cafe_count_500_price_500</th>\n",
       "      <th>cafe_count_500_price_1000</th>\n",
       "      <th>cafe_count_500_price_1500</th>\n",
       "      <th>cafe_count_500_price_2500</th>\n",
       "      <th>cafe_count_500_price_4000</th>\n",
       "      <th>cafe_count_500_price_high</th>\n",
       "      <th>big_church_count_500</th>\n",
       "      <th>church_count_500</th>\n",
       "      <th>mosque_count_500</th>\n",
       "      <th>leisure_count_500</th>\n",
       "      <th>sport_count_500</th>\n",
       "      <th>market_count_500</th>\n",
       "      <th>green_part_1000</th>\n",
       "      <th>prom_part_1000</th>\n",
       "      <th>office_count_1000</th>\n",
       "      <th>office_sqm_1000</th>\n",
       "      <th>trc_count_1000</th>\n",
       "      <th>trc_sqm_1000</th>\n",
       "      <th>cafe_count_1000</th>\n",
       "      <th>cafe_sum_1000_min_price_avg</th>\n",
       "      <th>cafe_sum_1000_max_price_avg</th>\n",
       "      <th>cafe_avg_price_1000</th>\n",
       "      <th>cafe_count_1000_na_price</th>\n",
       "      <th>cafe_count_1000_price_500</th>\n",
       "      <th>cafe_count_1000_price_1000</th>\n",
       "      <th>cafe_count_1000_price_1500</th>\n",
       "      <th>cafe_count_1000_price_2500</th>\n",
       "      <th>cafe_count_1000_price_4000</th>\n",
       "      <th>cafe_count_1000_price_high</th>\n",
       "      <th>big_church_count_1000</th>\n",
       "      <th>church_count_1000</th>\n",
       "      <th>mosque_count_1000</th>\n",
       "      <th>leisure_count_1000</th>\n",
       "      <th>sport_count_1000</th>\n",
       "      <th>market_count_1000</th>\n",
       "      <th>green_part_1500</th>\n",
       "      <th>prom_part_1500</th>\n",
       "      <th>office_count_1500</th>\n",
       "      <th>office_sqm_1500</th>\n",
       "      <th>trc_count_1500</th>\n",
       "      <th>trc_sqm_1500</th>\n",
       "      <th>cafe_count_1500</th>\n",
       "      <th>cafe_sum_1500_min_price_avg</th>\n",
       "      <th>cafe_sum_1500_max_price_avg</th>\n",
       "      <th>cafe_avg_price_1500</th>\n",
       "      <th>cafe_count_1500_na_price</th>\n",
       "      <th>cafe_count_1500_price_500</th>\n",
       "      <th>cafe_count_1500_price_1000</th>\n",
       "      <th>cafe_count_1500_price_1500</th>\n",
       "      <th>cafe_count_1500_price_2500</th>\n",
       "      <th>cafe_count_1500_price_4000</th>\n",
       "      <th>cafe_count_1500_price_high</th>\n",
       "      <th>big_church_count_1500</th>\n",
       "      <th>church_count_1500</th>\n",
       "      <th>mosque_count_1500</th>\n",
       "      <th>leisure_count_1500</th>\n",
       "      <th>sport_count_1500</th>\n",
       "      <th>market_count_1500</th>\n",
       "      <th>green_part_2000</th>\n",
       "      <th>prom_part_2000</th>\n",
       "      <th>office_count_2000</th>\n",
       "      <th>office_sqm_2000</th>\n",
       "      <th>trc_count_2000</th>\n",
       "      <th>trc_sqm_2000</th>\n",
       "      <th>cafe_count_2000</th>\n",
       "      <th>cafe_sum_2000_min_price_avg</th>\n",
       "      <th>cafe_sum_2000_max_price_avg</th>\n",
       "      <th>cafe_avg_price_2000</th>\n",
       "      <th>cafe_count_2000_na_price</th>\n",
       "      <th>cafe_count_2000_price_500</th>\n",
       "      <th>cafe_count_2000_price_1000</th>\n",
       "      <th>cafe_count_2000_price_1500</th>\n",
       "      <th>cafe_count_2000_price_2500</th>\n",
       "      <th>cafe_count_2000_price_4000</th>\n",
       "      <th>cafe_count_2000_price_high</th>\n",
       "      <th>big_church_count_2000</th>\n",
       "      <th>church_count_2000</th>\n",
       "      <th>mosque_count_2000</th>\n",
       "      <th>leisure_count_2000</th>\n",
       "      <th>sport_count_2000</th>\n",
       "      <th>market_count_2000</th>\n",
       "      <th>green_part_3000</th>\n",
       "      <th>prom_part_3000</th>\n",
       "      <th>office_count_3000</th>\n",
       "      <th>office_sqm_3000</th>\n",
       "      <th>trc_count_3000</th>\n",
       "      <th>trc_sqm_3000</th>\n",
       "      <th>cafe_count_3000</th>\n",
       "      <th>cafe_sum_3000_min_price_avg</th>\n",
       "      <th>cafe_sum_3000_max_price_avg</th>\n",
       "      <th>cafe_avg_price_3000</th>\n",
       "      <th>cafe_count_3000_na_price</th>\n",
       "      <th>cafe_count_3000_price_500</th>\n",
       "      <th>cafe_count_3000_price_1000</th>\n",
       "      <th>cafe_count_3000_price_1500</th>\n",
       "      <th>cafe_count_3000_price_2500</th>\n",
       "      <th>cafe_count_3000_price_4000</th>\n",
       "      <th>cafe_count_3000_price_high</th>\n",
       "      <th>big_church_count_3000</th>\n",
       "      <th>church_count_3000</th>\n",
       "      <th>mosque_count_3000</th>\n",
       "      <th>leisure_count_3000</th>\n",
       "      <th>sport_count_3000</th>\n",
       "      <th>market_count_3000</th>\n",
       "      <th>green_part_5000</th>\n",
       "      <th>prom_part_5000</th>\n",
       "      <th>office_count_5000</th>\n",
       "      <th>office_sqm_5000</th>\n",
       "      <th>trc_count_5000</th>\n",
       "      <th>trc_sqm_5000</th>\n",
       "      <th>cafe_count_5000</th>\n",
       "      <th>cafe_sum_5000_min_price_avg</th>\n",
       "      <th>cafe_sum_5000_max_price_avg</th>\n",
       "      <th>cafe_avg_price_5000</th>\n",
       "      <th>cafe_count_5000_na_price</th>\n",
       "      <th>cafe_count_5000_price_500</th>\n",
       "      <th>cafe_count_5000_price_1000</th>\n",
       "      <th>cafe_count_5000_price_1500</th>\n",
       "      <th>cafe_count_5000_price_2500</th>\n",
       "      <th>cafe_count_5000_price_4000</th>\n",
       "      <th>cafe_count_5000_price_high</th>\n",
       "      <th>big_church_count_5000</th>\n",
       "      <th>church_count_5000</th>\n",
       "      <th>mosque_count_5000</th>\n",
       "      <th>leisure_count_5000</th>\n",
       "      <th>sport_count_5000</th>\n",
       "      <th>market_count_5000</th>\n",
       "      <th>year_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2014-03-21</td>\n",
       "      <td>28</td>\n",
       "      <td>17.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1957.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Akademicheskoe</td>\n",
       "      <td>5704502.190</td>\n",
       "      <td>106445</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.151</td>\n",
       "      <td>5506</td>\n",
       "      <td>926.000</td>\n",
       "      <td>6</td>\n",
       "      <td>5889</td>\n",
       "      <td>9501.000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>830.000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>1362363</td>\n",
       "      <td>637906</td>\n",
       "      <td>724457</td>\n",
       "      <td>12074</td>\n",
       "      <td>6198</td>\n",
       "      <td>5876</td>\n",
       "      <td>68518</td>\n",
       "      <td>34132</td>\n",
       "      <td>34386</td>\n",
       "      <td>25853</td>\n",
       "      <td>8422</td>\n",
       "      <td>17431</td>\n",
       "      <td>5506</td>\n",
       "      <td>2861</td>\n",
       "      <td>2645</td>\n",
       "      <td>5889</td>\n",
       "      <td>2990</td>\n",
       "      <td>2899</td>\n",
       "      <td>14297</td>\n",
       "      <td>7209</td>\n",
       "      <td>7088</td>\n",
       "      <td>291222</td>\n",
       "      <td>143474</td>\n",
       "      <td>147748</td>\n",
       "      <td>10653</td>\n",
       "      <td>5506</td>\n",
       "      <td>5147</td>\n",
       "      <td>374.000</td>\n",
       "      <td>81.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>205.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>78.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>374.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>304.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>49.000</td>\n",
       "      <td>95</td>\n",
       "      <td>1.149</td>\n",
       "      <td>0.592</td>\n",
       "      <td>5.622</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.263</td>\n",
       "      <td>1.544</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.435</td>\n",
       "      <td>7.173</td>\n",
       "      <td>1.990</td>\n",
       "      <td>10.653</td>\n",
       "      <td>2.466</td>\n",
       "      <td>29.597</td>\n",
       "      <td>42.000</td>\n",
       "      <td>2.466</td>\n",
       "      <td>3.305</td>\n",
       "      <td>42</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.782</td>\n",
       "      <td>1.531</td>\n",
       "      <td>no</td>\n",
       "      <td>9.408</td>\n",
       "      <td>1.769</td>\n",
       "      <td>4.729</td>\n",
       "      <td>5.919</td>\n",
       "      <td>6.640</td>\n",
       "      <td>1.060</td>\n",
       "      <td>16</td>\n",
       "      <td>no</td>\n",
       "      <td>1.769</td>\n",
       "      <td>4</td>\n",
       "      <td>1.234</td>\n",
       "      <td>no</td>\n",
       "      <td>6.923</td>\n",
       "      <td>32</td>\n",
       "      <td>6.878</td>\n",
       "      <td>13</td>\n",
       "      <td>13.368</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.781</td>\n",
       "      <td>1.067</td>\n",
       "      <td>5.414</td>\n",
       "      <td>7.936</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.017</td>\n",
       "      <td>1.020</td>\n",
       "      <td>6.345</td>\n",
       "      <td>5.445</td>\n",
       "      <td>2.174</td>\n",
       "      <td>1.292</td>\n",
       "      <td>10.402</td>\n",
       "      <td>1.762</td>\n",
       "      <td>1.872</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.263</td>\n",
       "      <td>1.057</td>\n",
       "      <td>1.062</td>\n",
       "      <td>4.520</td>\n",
       "      <td>2.878</td>\n",
       "      <td>0.975</td>\n",
       "      <td>2.310</td>\n",
       "      <td>0.066</td>\n",
       "      <td>poor</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.900</td>\n",
       "      <td>1</td>\n",
       "      <td>33400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>1583.330</td>\n",
       "      <td>1291.670</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.750</td>\n",
       "      <td>11.510</td>\n",
       "      <td>7</td>\n",
       "      <td>93706</td>\n",
       "      <td>1</td>\n",
       "      <td>22000</td>\n",
       "      <td>18</td>\n",
       "      <td>938.890</td>\n",
       "      <td>1527.780</td>\n",
       "      <td>1233.330</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.200</td>\n",
       "      <td>11.800</td>\n",
       "      <td>10</td>\n",
       "      <td>140677</td>\n",
       "      <td>3</td>\n",
       "      <td>67940</td>\n",
       "      <td>46</td>\n",
       "      <td>878.260</td>\n",
       "      <td>1456.520</td>\n",
       "      <td>1167.390</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>13.050</td>\n",
       "      <td>6.870</td>\n",
       "      <td>16</td>\n",
       "      <td>247647</td>\n",
       "      <td>7</td>\n",
       "      <td>615440</td>\n",
       "      <td>90</td>\n",
       "      <td>780.680</td>\n",
       "      <td>1295.450</td>\n",
       "      <td>1038.070</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>13.010</td>\n",
       "      <td>4.480</td>\n",
       "      <td>38</td>\n",
       "      <td>755124</td>\n",
       "      <td>16</td>\n",
       "      <td>844740</td>\n",
       "      <td>183</td>\n",
       "      <td>791.950</td>\n",
       "      <td>1321.840</td>\n",
       "      <td>1056.900</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>61</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>11.060</td>\n",
       "      <td>12.240</td>\n",
       "      <td>153</td>\n",
       "      <td>3196866</td>\n",
       "      <td>43</td>\n",
       "      <td>1986780</td>\n",
       "      <td>578</td>\n",
       "      <td>825.050</td>\n",
       "      <td>1366.420</td>\n",
       "      <td>1095.730</td>\n",
       "      <td>39</td>\n",
       "      <td>129</td>\n",
       "      <td>160</td>\n",
       "      <td>154</td>\n",
       "      <td>74</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>2014-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>2014-05-27</td>\n",
       "      <td>45</td>\n",
       "      <td>28.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1967.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Gol'janovo</td>\n",
       "      <td>14286990.830</td>\n",
       "      <td>157010</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.194</td>\n",
       "      <td>7751</td>\n",
       "      <td>5041.000</td>\n",
       "      <td>6</td>\n",
       "      <td>8004</td>\n",
       "      <td>11081.000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>125.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>12327</td>\n",
       "      <td>5588</td>\n",
       "      <td>6739</td>\n",
       "      <td>16831</td>\n",
       "      <td>8637</td>\n",
       "      <td>8194</td>\n",
       "      <td>98260</td>\n",
       "      <td>47405</td>\n",
       "      <td>50855</td>\n",
       "      <td>41919</td>\n",
       "      <td>12424</td>\n",
       "      <td>29495</td>\n",
       "      <td>7751</td>\n",
       "      <td>3941</td>\n",
       "      <td>3810</td>\n",
       "      <td>8004</td>\n",
       "      <td>4152</td>\n",
       "      <td>3852</td>\n",
       "      <td>18912</td>\n",
       "      <td>9716</td>\n",
       "      <td>9196</td>\n",
       "      <td>2780</td>\n",
       "      <td>1351</td>\n",
       "      <td>1429</td>\n",
       "      <td>14694</td>\n",
       "      <td>7551</td>\n",
       "      <td>7143</td>\n",
       "      <td>371.000</td>\n",
       "      <td>88.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>68.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>207.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>371.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>221.000</td>\n",
       "      <td>129.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20</td>\n",
       "      <td>2.506</td>\n",
       "      <td>1.408</td>\n",
       "      <td>16.892</td>\n",
       "      <td>1.408</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.566</td>\n",
       "      <td>2.399</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.065</td>\n",
       "      <td>16.766</td>\n",
       "      <td>1.388</td>\n",
       "      <td>13.930</td>\n",
       "      <td>3.991</td>\n",
       "      <td>47.887</td>\n",
       "      <td>18.000</td>\n",
       "      <td>4.358</td>\n",
       "      <td>6.149</td>\n",
       "      <td>18</td>\n",
       "      <td>0.193</td>\n",
       "      <td>2.315</td>\n",
       "      <td>1.467</td>\n",
       "      <td>no</td>\n",
       "      <td>3.279</td>\n",
       "      <td>7.491</td>\n",
       "      <td>9.638</td>\n",
       "      <td>10.381</td>\n",
       "      <td>12.179</td>\n",
       "      <td>3.105</td>\n",
       "      <td>12</td>\n",
       "      <td>no</td>\n",
       "      <td>3.128</td>\n",
       "      <td>41</td>\n",
       "      <td>0.945</td>\n",
       "      <td>no</td>\n",
       "      <td>9.907</td>\n",
       "      <td>97</td>\n",
       "      <td>1.337</td>\n",
       "      <td>7</td>\n",
       "      <td>6.755</td>\n",
       "      <td>16.242</td>\n",
       "      <td>0.797</td>\n",
       "      <td>1.713</td>\n",
       "      <td>1.232</td>\n",
       "      <td>8.242</td>\n",
       "      <td>16.235</td>\n",
       "      <td>1.278</td>\n",
       "      <td>0.988</td>\n",
       "      <td>2.306</td>\n",
       "      <td>4.520</td>\n",
       "      <td>3.826</td>\n",
       "      <td>1.713</td>\n",
       "      <td>2.086</td>\n",
       "      <td>8.253</td>\n",
       "      <td>0.471</td>\n",
       "      <td>2.678</td>\n",
       "      <td>1.280</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.566</td>\n",
       "      <td>1.583</td>\n",
       "      <td>0.635</td>\n",
       "      <td>9.293</td>\n",
       "      <td>7.431</td>\n",
       "      <td>6.620</td>\n",
       "      <td>2.560</td>\n",
       "      <td>0.263</td>\n",
       "      <td>good</td>\n",
       "      <td>0.000</td>\n",
       "      <td>38.700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3164</td>\n",
       "      <td>2</td>\n",
       "      <td>400.000</td>\n",
       "      <td>750.000</td>\n",
       "      <td>575.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060</td>\n",
       "      <td>43.300</td>\n",
       "      <td>1</td>\n",
       "      <td>6600</td>\n",
       "      <td>2</td>\n",
       "      <td>23732</td>\n",
       "      <td>4</td>\n",
       "      <td>700.000</td>\n",
       "      <td>1125.000</td>\n",
       "      <td>912.500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7.240</td>\n",
       "      <td>36.930</td>\n",
       "      <td>3</td>\n",
       "      <td>11300</td>\n",
       "      <td>4</td>\n",
       "      <td>61032</td>\n",
       "      <td>17</td>\n",
       "      <td>741.180</td>\n",
       "      <td>1235.290</td>\n",
       "      <td>988.240</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>14.690</td>\n",
       "      <td>28.250</td>\n",
       "      <td>5</td>\n",
       "      <td>86300</td>\n",
       "      <td>4</td>\n",
       "      <td>61032</td>\n",
       "      <td>27</td>\n",
       "      <td>672.000</td>\n",
       "      <td>1120.000</td>\n",
       "      <td>896.000</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>25.030</td>\n",
       "      <td>18.360</td>\n",
       "      <td>8</td>\n",
       "      <td>121139</td>\n",
       "      <td>12</td>\n",
       "      <td>122066</td>\n",
       "      <td>50</td>\n",
       "      <td>715.220</td>\n",
       "      <td>1206.520</td>\n",
       "      <td>960.870</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>41.250</td>\n",
       "      <td>9.640</td>\n",
       "      <td>19</td>\n",
       "      <td>380612</td>\n",
       "      <td>20</td>\n",
       "      <td>719166</td>\n",
       "      <td>100</td>\n",
       "      <td>650.000</td>\n",
       "      <td>1101.060</td>\n",
       "      <td>875.530</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20002</td>\n",
       "      <td>2014-01-20</td>\n",
       "      <td>63</td>\n",
       "      <td>36.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1957.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Sokol</td>\n",
       "      <td>3496889.653</td>\n",
       "      <td>57107</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.175</td>\n",
       "      <td>2982</td>\n",
       "      <td>1744.000</td>\n",
       "      <td>4</td>\n",
       "      <td>3379</td>\n",
       "      <td>4960.000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>57995</td>\n",
       "      <td>26205</td>\n",
       "      <td>31790</td>\n",
       "      <td>6807</td>\n",
       "      <td>3590</td>\n",
       "      <td>3217</td>\n",
       "      <td>36496</td>\n",
       "      <td>18719</td>\n",
       "      <td>17777</td>\n",
       "      <td>13804</td>\n",
       "      <td>4608</td>\n",
       "      <td>9196</td>\n",
       "      <td>2982</td>\n",
       "      <td>1549</td>\n",
       "      <td>1433</td>\n",
       "      <td>3379</td>\n",
       "      <td>1804</td>\n",
       "      <td>1575</td>\n",
       "      <td>7887</td>\n",
       "      <td>4153</td>\n",
       "      <td>3734</td>\n",
       "      <td>12073</td>\n",
       "      <td>5873</td>\n",
       "      <td>6200</td>\n",
       "      <td>5981</td>\n",
       "      <td>3138</td>\n",
       "      <td>2843</td>\n",
       "      <td>335.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>42.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>250.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>336.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>110.000</td>\n",
       "      <td>199.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>99</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.174</td>\n",
       "      <td>2.084</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.853</td>\n",
       "      <td>20.228</td>\n",
       "      <td>2.992</td>\n",
       "      <td>7.691</td>\n",
       "      <td>1.185</td>\n",
       "      <td>14.226</td>\n",
       "      <td>40.000</td>\n",
       "      <td>1.185</td>\n",
       "      <td>1.623</td>\n",
       "      <td>40</td>\n",
       "      <td>0.084</td>\n",
       "      <td>1.008</td>\n",
       "      <td>0.660</td>\n",
       "      <td>no</td>\n",
       "      <td>6.171</td>\n",
       "      <td>5.549</td>\n",
       "      <td>8.132</td>\n",
       "      <td>8.934</td>\n",
       "      <td>10.154</td>\n",
       "      <td>0.814</td>\n",
       "      <td>14</td>\n",
       "      <td>no</td>\n",
       "      <td>1.488</td>\n",
       "      <td>28</td>\n",
       "      <td>0.053</td>\n",
       "      <td>yes</td>\n",
       "      <td>7.906</td>\n",
       "      <td>83</td>\n",
       "      <td>5.130</td>\n",
       "      <td>5</td>\n",
       "      <td>18.153</td>\n",
       "      <td>1.983</td>\n",
       "      <td>2.814</td>\n",
       "      <td>1.985</td>\n",
       "      <td>3.374</td>\n",
       "      <td>5.060</td>\n",
       "      <td>18.689</td>\n",
       "      <td>2.527</td>\n",
       "      <td>0.833</td>\n",
       "      <td>2.801</td>\n",
       "      <td>4.201</td>\n",
       "      <td>2.520</td>\n",
       "      <td>2.241</td>\n",
       "      <td>2.236</td>\n",
       "      <td>4.673</td>\n",
       "      <td>2.631</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.481</td>\n",
       "      <td>1.102</td>\n",
       "      <td>0.609</td>\n",
       "      <td>8.155</td>\n",
       "      <td>7.418</td>\n",
       "      <td>7.414</td>\n",
       "      <td>2.553</td>\n",
       "      <td>0.162</td>\n",
       "      <td>poor</td>\n",
       "      <td>14.220</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4</td>\n",
       "      <td>67725</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>660.000</td>\n",
       "      <td>1100.000</td>\n",
       "      <td>880.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.550</td>\n",
       "      <td>1.410</td>\n",
       "      <td>8</td>\n",
       "      <td>175525</td>\n",
       "      <td>3</td>\n",
       "      <td>74000</td>\n",
       "      <td>22</td>\n",
       "      <td>700.000</td>\n",
       "      <td>1166.670</td>\n",
       "      <td>933.330</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28.880</td>\n",
       "      <td>6.580</td>\n",
       "      <td>13</td>\n",
       "      <td>557071</td>\n",
       "      <td>7</td>\n",
       "      <td>496872</td>\n",
       "      <td>63</td>\n",
       "      <td>587.040</td>\n",
       "      <td>990.740</td>\n",
       "      <td>788.890</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23.740</td>\n",
       "      <td>9.480</td>\n",
       "      <td>20</td>\n",
       "      <td>640702</td>\n",
       "      <td>15</td>\n",
       "      <td>741083</td>\n",
       "      <td>108</td>\n",
       "      <td>678.490</td>\n",
       "      <td>1139.780</td>\n",
       "      <td>909.140</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>15.610</td>\n",
       "      <td>12.570</td>\n",
       "      <td>41</td>\n",
       "      <td>1023356</td>\n",
       "      <td>18</td>\n",
       "      <td>769783</td>\n",
       "      <td>159</td>\n",
       "      <td>696.450</td>\n",
       "      <td>1166.670</td>\n",
       "      <td>931.560</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>18.730</td>\n",
       "      <td>12.640</td>\n",
       "      <td>85</td>\n",
       "      <td>2099848</td>\n",
       "      <td>43</td>\n",
       "      <td>1673500</td>\n",
       "      <td>308</td>\n",
       "      <td>717.200</td>\n",
       "      <td>1204.300</td>\n",
       "      <td>960.750</td>\n",
       "      <td>29</td>\n",
       "      <td>87</td>\n",
       "      <td>90</td>\n",
       "      <td>66</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>14</td>\n",
       "      <td>2014-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20003</td>\n",
       "      <td>2014-12-17</td>\n",
       "      <td>45</td>\n",
       "      <td>45.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>OwnerOccupier</td>\n",
       "      <td>Poselenie Sosenskoe</td>\n",
       "      <td>66772450.690</td>\n",
       "      <td>9553</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.072</td>\n",
       "      <td>656</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>629</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>13890</td>\n",
       "      <td>6584</td>\n",
       "      <td>7307</td>\n",
       "      <td>1370</td>\n",
       "      <td>709</td>\n",
       "      <td>661</td>\n",
       "      <td>6127</td>\n",
       "      <td>3237</td>\n",
       "      <td>2890</td>\n",
       "      <td>2056</td>\n",
       "      <td>583</td>\n",
       "      <td>1473</td>\n",
       "      <td>656</td>\n",
       "      <td>340</td>\n",
       "      <td>316</td>\n",
       "      <td>629</td>\n",
       "      <td>325</td>\n",
       "      <td>305</td>\n",
       "      <td>1542</td>\n",
       "      <td>801</td>\n",
       "      <td>742</td>\n",
       "      <td>3134</td>\n",
       "      <td>1753</td>\n",
       "      <td>1381</td>\n",
       "      <td>1207</td>\n",
       "      <td>623</td>\n",
       "      <td>584</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>45</td>\n",
       "      <td>8.234</td>\n",
       "      <td>5.802</td>\n",
       "      <td>69.619</td>\n",
       "      <td>5.802</td>\n",
       "      <td>2.852</td>\n",
       "      <td>3.420</td>\n",
       "      <td>5.406</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.309</td>\n",
       "      <td>5.305</td>\n",
       "      <td>1.018</td>\n",
       "      <td>11.131</td>\n",
       "      <td>9.689</td>\n",
       "      <td>116.268</td>\n",
       "      <td>47.000</td>\n",
       "      <td>9.693</td>\n",
       "      <td>13.781</td>\n",
       "      <td>47</td>\n",
       "      <td>0.844</td>\n",
       "      <td>10.129</td>\n",
       "      <td>0.888</td>\n",
       "      <td>no</td>\n",
       "      <td>4.586</td>\n",
       "      <td>17.704</td>\n",
       "      <td>20.670</td>\n",
       "      <td>21.834</td>\n",
       "      <td>22.568</td>\n",
       "      <td>1.444</td>\n",
       "      <td>38</td>\n",
       "      <td>no</td>\n",
       "      <td>4.586</td>\n",
       "      <td>1</td>\n",
       "      <td>3.852</td>\n",
       "      <td>no</td>\n",
       "      <td>24.613</td>\n",
       "      <td>32</td>\n",
       "      <td>12.909</td>\n",
       "      <td>9</td>\n",
       "      <td>23.425</td>\n",
       "      <td>16.024</td>\n",
       "      <td>5.369</td>\n",
       "      <td>1.921</td>\n",
       "      <td>10.394</td>\n",
       "      <td>6.088</td>\n",
       "      <td>6.328</td>\n",
       "      <td>10.533</td>\n",
       "      <td>1.080</td>\n",
       "      <td>9.791</td>\n",
       "      <td>8.883</td>\n",
       "      <td>14.165</td>\n",
       "      <td>8.176</td>\n",
       "      <td>5.633</td>\n",
       "      <td>28.116</td>\n",
       "      <td>5.090</td>\n",
       "      <td>10.987</td>\n",
       "      <td>7.098</td>\n",
       "      <td>4.909</td>\n",
       "      <td>4.267</td>\n",
       "      <td>3.978</td>\n",
       "      <td>3.420</td>\n",
       "      <td>4.601</td>\n",
       "      <td>0.921</td>\n",
       "      <td>4.263</td>\n",
       "      <td>13.726</td>\n",
       "      <td>12.858</td>\n",
       "      <td>9.831</td>\n",
       "      <td>0.855</td>\n",
       "      <td>no data</td>\n",
       "      <td>17.940</td>\n",
       "      <td>1.510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.340</td>\n",
       "      <td>3.110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>500.000</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>750.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.670</td>\n",
       "      <td>7.860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>500.000</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>750.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.180</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1833.330</td>\n",
       "      <td>3000.000</td>\n",
       "      <td>2416.670</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25.800</td>\n",
       "      <td>4.120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1750.000</td>\n",
       "      <td>2875.000</td>\n",
       "      <td>2312.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32.940</td>\n",
       "      <td>6.050</td>\n",
       "      <td>1</td>\n",
       "      <td>85159</td>\n",
       "      <td>3</td>\n",
       "      <td>73000</td>\n",
       "      <td>14</td>\n",
       "      <td>1176.920</td>\n",
       "      <td>1884.620</td>\n",
       "      <td>1530.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004</td>\n",
       "      <td>2013-03-20</td>\n",
       "      <td>29</td>\n",
       "      <td>nan</td>\n",
       "      <td>21.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>OwnerOccupier</td>\n",
       "      <td>Pokrovskoe Streshnevo</td>\n",
       "      <td>13089795.790</td>\n",
       "      <td>53786</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.151</td>\n",
       "      <td>3051</td>\n",
       "      <td>922.000</td>\n",
       "      <td>2</td>\n",
       "      <td>3433</td>\n",
       "      <td>3577.000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2643.000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>178473</td>\n",
       "      <td>83803</td>\n",
       "      <td>94670</td>\n",
       "      <td>6931</td>\n",
       "      <td>3341</td>\n",
       "      <td>3590</td>\n",
       "      <td>33149</td>\n",
       "      <td>16783</td>\n",
       "      <td>16366</td>\n",
       "      <td>13706</td>\n",
       "      <td>4107</td>\n",
       "      <td>9599</td>\n",
       "      <td>3051</td>\n",
       "      <td>1510</td>\n",
       "      <td>1541</td>\n",
       "      <td>3433</td>\n",
       "      <td>1635</td>\n",
       "      <td>1798</td>\n",
       "      <td>7727</td>\n",
       "      <td>3751</td>\n",
       "      <td>3976</td>\n",
       "      <td>44237</td>\n",
       "      <td>22136</td>\n",
       "      <td>22101</td>\n",
       "      <td>6046</td>\n",
       "      <td>2929</td>\n",
       "      <td>3117</td>\n",
       "      <td>273.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>155.000</td>\n",
       "      <td>58.000</td>\n",
       "      <td>31.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>271.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>145.000</td>\n",
       "      <td>37.000</td>\n",
       "      <td>71.000</td>\n",
       "      <td>64</td>\n",
       "      <td>3.517</td>\n",
       "      <td>2.519</td>\n",
       "      <td>25.815</td>\n",
       "      <td>2.151</td>\n",
       "      <td>1.273</td>\n",
       "      <td>0.454</td>\n",
       "      <td>1.229</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.301</td>\n",
       "      <td>20.282</td>\n",
       "      <td>2.932</td>\n",
       "      <td>8.534</td>\n",
       "      <td>2.464</td>\n",
       "      <td>29.565</td>\n",
       "      <td>20.000</td>\n",
       "      <td>2.672</td>\n",
       "      <td>4.972</td>\n",
       "      <td>20</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.455</td>\n",
       "      <td>no</td>\n",
       "      <td>3.500</td>\n",
       "      <td>8.598</td>\n",
       "      <td>11.217</td>\n",
       "      <td>12.015</td>\n",
       "      <td>13.238</td>\n",
       "      <td>2.146</td>\n",
       "      <td>14</td>\n",
       "      <td>no</td>\n",
       "      <td>3.157</td>\n",
       "      <td>17</td>\n",
       "      <td>0.584</td>\n",
       "      <td>no</td>\n",
       "      <td>11.363</td>\n",
       "      <td>83</td>\n",
       "      <td>3.149</td>\n",
       "      <td>1</td>\n",
       "      <td>21.096</td>\n",
       "      <td>3.981</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.514</td>\n",
       "      <td>6.148</td>\n",
       "      <td>1.978</td>\n",
       "      <td>23.966</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.410</td>\n",
       "      <td>3.847</td>\n",
       "      <td>6.840</td>\n",
       "      <td>0.712</td>\n",
       "      <td>1.763</td>\n",
       "      <td>0.548</td>\n",
       "      <td>9.233</td>\n",
       "      <td>0.269</td>\n",
       "      <td>4.788</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.527</td>\n",
       "      <td>2.909</td>\n",
       "      <td>1.167</td>\n",
       "      <td>9.327</td>\n",
       "      <td>10.876</td>\n",
       "      <td>10.234</td>\n",
       "      <td>2.593</td>\n",
       "      <td>0.180</td>\n",
       "      <td>poor</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.990</td>\n",
       "      <td>2</td>\n",
       "      <td>69950</td>\n",
       "      <td>2</td>\n",
       "      <td>68000</td>\n",
       "      <td>3</td>\n",
       "      <td>366.670</td>\n",
       "      <td>666.670</td>\n",
       "      <td>516.670</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5.550</td>\n",
       "      <td>20.540</td>\n",
       "      <td>2</td>\n",
       "      <td>69950</td>\n",
       "      <td>2</td>\n",
       "      <td>68000</td>\n",
       "      <td>10</td>\n",
       "      <td>877.780</td>\n",
       "      <td>1444.440</td>\n",
       "      <td>1161.110</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12.490</td>\n",
       "      <td>18.640</td>\n",
       "      <td>3</td>\n",
       "      <td>71550</td>\n",
       "      <td>3</td>\n",
       "      <td>73600</td>\n",
       "      <td>13</td>\n",
       "      <td>891.670</td>\n",
       "      <td>1458.330</td>\n",
       "      <td>1175.000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>13.720</td>\n",
       "      <td>15.320</td>\n",
       "      <td>4</td>\n",
       "      <td>142450</td>\n",
       "      <td>3</td>\n",
       "      <td>73600</td>\n",
       "      <td>21</td>\n",
       "      <td>975.000</td>\n",
       "      <td>1625.000</td>\n",
       "      <td>1300.000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>18.000</td>\n",
       "      <td>12.880</td>\n",
       "      <td>18</td>\n",
       "      <td>729427</td>\n",
       "      <td>18</td>\n",
       "      <td>787508</td>\n",
       "      <td>86</td>\n",
       "      <td>775.640</td>\n",
       "      <td>1294.870</td>\n",
       "      <td>1035.260</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>18.930</td>\n",
       "      <td>10.460</td>\n",
       "      <td>54</td>\n",
       "      <td>1626659</td>\n",
       "      <td>53</td>\n",
       "      <td>1994669</td>\n",
       "      <td>255</td>\n",
       "      <td>735.780</td>\n",
       "      <td>1232.760</td>\n",
       "      <td>984.270</td>\n",
       "      <td>23</td>\n",
       "      <td>64</td>\n",
       "      <td>78</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>11</td>\n",
       "      <td>2013-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  timestamp  full_sq  life_sq  floor  max_floor  material  build_year  \\\n",
       "0  20000 2014-03-21       28   17.000  3.000      4.000     2.000    1957.000   \n",
       "1  20001 2014-05-27       45   28.000  1.000      5.000     1.000    1967.000   \n",
       "2  20002 2014-01-20       63   36.000  1.000      4.000     2.000    1957.000   \n",
       "3  20003 2014-12-17       45   45.000  8.000     17.000     1.000         nan   \n",
       "4  20004 2013-03-20       29      nan 21.000        nan       nan         nan   \n",
       "\n",
       "   num_room  kitch_sq  state   product_type               sub_area  \\\n",
       "0     1.000     4.000  2.000     Investment         Akademicheskoe   \n",
       "1     2.000     5.000  2.000     Investment             Gol'janovo   \n",
       "2     2.000     7.000  2.000     Investment                  Sokol   \n",
       "3     1.000     1.000  1.000  OwnerOccupier    Poselenie Sosenskoe   \n",
       "4       nan       nan    nan  OwnerOccupier  Pokrovskoe Streshnevo   \n",
       "\n",
       "        area_m  raion_popul  green_zone_part  indust_part  children_preschool  \\\n",
       "0  5704502.190       106445            0.043        0.151                5506   \n",
       "1 14286990.830       157010            0.389        0.194                7751   \n",
       "2  3496889.653        57107            0.068        0.175                2982   \n",
       "3 66772450.690         9553            0.336        0.072                 656   \n",
       "4 13089795.790        53786            0.184        0.151                3051   \n",
       "\n",
       "   preschool_quota  preschool_education_centers_raion  children_school  \\\n",
       "0          926.000                                  6             5889   \n",
       "1         5041.000                                  6             8004   \n",
       "2         1744.000                                  4             3379   \n",
       "3              nan                                  0              629   \n",
       "4          922.000                                  2             3433   \n",
       "\n",
       "   school_quota  school_education_centers_raion  \\\n",
       "0      9501.000                               6   \n",
       "1     11081.000                               7   \n",
       "2      4960.000                               6   \n",
       "3           nan                               0   \n",
       "4      3577.000                               4   \n",
       "\n",
       "   school_education_centers_top_20_raion  hospital_beds_raion  \\\n",
       "0                                      0              830.000   \n",
       "1                                      0              125.000   \n",
       "2                                      0              100.000   \n",
       "3                                      0                  nan   \n",
       "4                                      0             2643.000   \n",
       "\n",
       "   healthcare_centers_raion  university_top_20_raion  sport_objects_raion  \\\n",
       "0                         4                        0                    7   \n",
       "1                         3                        0                    5   \n",
       "2                         0                        0                    5   \n",
       "3                         0                        0                    1   \n",
       "4                         4                        0                   10   \n",
       "\n",
       "   additional_education_raion culture_objects_top_25  \\\n",
       "0                           0                     no   \n",
       "1                           3                     no   \n",
       "2                          10                     no   \n",
       "3                           0                     no   \n",
       "4                           2                     no   \n",
       "\n",
       "   culture_objects_top_25_raion  shopping_centers_raion  office_raion  \\\n",
       "0                             0                       1            10   \n",
       "1                             0                       5             3   \n",
       "2                             0                       3             9   \n",
       "3                             0                       0             1   \n",
       "4                             0                       5             4   \n",
       "\n",
       "  thermal_power_plant_raion incineration_raion oil_chemistry_raion  \\\n",
       "0                       yes                 no                  no   \n",
       "1                        no                 no                  no   \n",
       "2                        no                 no                  no   \n",
       "3                        no                 no                  no   \n",
       "4                        no                 no                  no   \n",
       "\n",
       "  radiation_raion railroad_terminal_raion big_market_raion  \\\n",
       "0             yes                      no               no   \n",
       "1             yes                      no               no   \n",
       "2              no                      no               no   \n",
       "3              no                      no              yes   \n",
       "4             yes                      no               no   \n",
       "\n",
       "  nuclear_reactor_raion detention_facility_raion  full_all  male_f  female_f  \\\n",
       "0                   yes                       no   1362363  637906    724457   \n",
       "1                    no                       no     12327    5588      6739   \n",
       "2                    no                       no     57995   26205     31790   \n",
       "3                    no                       no     13890    6584      7307   \n",
       "4                    no                       no    178473   83803     94670   \n",
       "\n",
       "   young_all  young_male  young_female  work_all  work_male  work_female  \\\n",
       "0      12074        6198          5876     68518      34132        34386   \n",
       "1      16831        8637          8194     98260      47405        50855   \n",
       "2       6807        3590          3217     36496      18719        17777   \n",
       "3       1370         709           661      6127       3237         2890   \n",
       "4       6931        3341          3590     33149      16783        16366   \n",
       "\n",
       "   ekder_all  ekder_male  ekder_female  0_6_all  0_6_male  0_6_female  \\\n",
       "0      25853        8422         17431     5506      2861        2645   \n",
       "1      41919       12424         29495     7751      3941        3810   \n",
       "2      13804        4608          9196     2982      1549        1433   \n",
       "3       2056         583          1473      656       340         316   \n",
       "4      13706        4107          9599     3051      1510        1541   \n",
       "\n",
       "   7_14_all  7_14_male  7_14_female  0_17_all  0_17_male  0_17_female  \\\n",
       "0      5889       2990         2899     14297       7209         7088   \n",
       "1      8004       4152         3852     18912       9716         9196   \n",
       "2      3379       1804         1575      7887       4153         3734   \n",
       "3       629        325          305      1542        801          742   \n",
       "4      3433       1635         1798      7727       3751         3976   \n",
       "\n",
       "   16_29_all  16_29_male  16_29_female  0_13_all  0_13_male  0_13_female  \\\n",
       "0     291222      143474        147748     10653       5506         5147   \n",
       "1       2780        1351          1429     14694       7551         7143   \n",
       "2      12073        5873          6200      5981       3138         2843   \n",
       "3       3134        1753          1381      1207        623          584   \n",
       "4      44237       22136         22101      6046       2929         3117   \n",
       "\n",
       "   raion_build_count_with_material_info  build_count_block  build_count_wood  \\\n",
       "0                               374.000             81.000             0.000   \n",
       "1                               371.000             88.000             0.000   \n",
       "2                               335.000             17.000            42.000   \n",
       "3                                   nan                nan               nan   \n",
       "4                               273.000             17.000             5.000   \n",
       "\n",
       "   build_count_frame  build_count_brick  build_count_monolith  \\\n",
       "0              0.000            205.000                 9.000   \n",
       "1              0.000             68.000                 8.000   \n",
       "2             14.000            250.000                 5.000   \n",
       "3                nan                nan                   nan   \n",
       "4              0.000            155.000                58.000   \n",
       "\n",
       "   build_count_panel  build_count_foam  build_count_slag  build_count_mix  \\\n",
       "0             78.000             0.000             1.000            0.000   \n",
       "1            207.000             0.000             0.000            0.000   \n",
       "2              5.000             0.000             2.000            0.000   \n",
       "3                nan               nan               nan              nan   \n",
       "4             31.000             0.000             7.000            0.000   \n",
       "\n",
       "   raion_build_count_with_builddate_info  build_count_before_1920  \\\n",
       "0                                374.000                    0.000   \n",
       "1                                371.000                    0.000   \n",
       "2                                336.000                    0.000   \n",
       "3                                    nan                      nan   \n",
       "4                                271.000                    0.000   \n",
       "\n",
       "   build_count_1921-1945  build_count_1946-1970  build_count_1971-1995  \\\n",
       "0                  0.000                304.000                 21.000   \n",
       "1                  1.000                221.000                129.000   \n",
       "2                110.000                199.000                 10.000   \n",
       "3                    nan                    nan                    nan   \n",
       "4                 18.000                145.000                 37.000   \n",
       "\n",
       "   build_count_after_1995  ID_metro  metro_min_avto  metro_km_avto  \\\n",
       "0                  49.000        95           1.149          0.592   \n",
       "1                  20.000        20           2.506          1.408   \n",
       "2                  17.000        99           0.651          0.174   \n",
       "3                     nan        45           8.234          5.802   \n",
       "4                  71.000        64           3.517          2.519   \n",
       "\n",
       "   metro_min_walk  metro_km_walk  kindergarten_km  school_km  park_km  \\\n",
       "0           5.622          0.469            0.285      0.263    1.544   \n",
       "1          16.892          1.408            0.442      0.566    2.399   \n",
       "2           2.084          0.174            0.317      0.072    0.882   \n",
       "3          69.619          5.802            2.852      3.420    5.406   \n",
       "4          25.815          2.151            1.273      0.454    1.229   \n",
       "\n",
       "   green_zone_km  industrial_km  water_treatment_km  cemetery_km  \\\n",
       "0          0.440          0.435               7.173        1.990   \n",
       "1          0.973          0.065              16.766        1.388   \n",
       "2          0.170          0.853              20.228        2.992   \n",
       "3          0.193          0.309               5.305        1.018   \n",
       "4          0.703          0.301              20.282        2.932   \n",
       "\n",
       "   incineration_km  railroad_station_walk_km  railroad_station_walk_min  \\\n",
       "0           10.653                     2.466                     29.597   \n",
       "1           13.930                     3.991                     47.887   \n",
       "2            7.691                     1.185                     14.226   \n",
       "3           11.131                     9.689                    116.268   \n",
       "4            8.534                     2.464                     29.565   \n",
       "\n",
       "   ID_railroad_station_walk  railroad_station_avto_km  \\\n",
       "0                    42.000                     2.466   \n",
       "1                    18.000                     4.358   \n",
       "2                    40.000                     1.185   \n",
       "3                    47.000                     9.693   \n",
       "4                    20.000                     2.672   \n",
       "\n",
       "   railroad_station_avto_min  ID_railroad_station_avto  \\\n",
       "0                      3.305                        42   \n",
       "1                      6.149                        18   \n",
       "2                      1.623                        40   \n",
       "3                     13.781                        47   \n",
       "4                      4.972                        20   \n",
       "\n",
       "   public_transport_station_km  public_transport_station_min_walk  water_km  \\\n",
       "0                        0.065                              0.782     1.531   \n",
       "1                        0.193                              2.315     1.467   \n",
       "2                        0.084                              1.008     0.660   \n",
       "3                        0.844                             10.129     0.888   \n",
       "4                        0.083                              0.998     0.455   \n",
       "\n",
       "  water_1line  mkad_km  ttk_km  sadovoe_km  bulvar_ring_km  kremlin_km  \\\n",
       "0          no    9.408   1.769       4.729           5.919       6.640   \n",
       "1          no    3.279   7.491       9.638          10.381      12.179   \n",
       "2          no    6.171   5.549       8.132           8.934      10.154   \n",
       "3          no    4.586  17.704      20.670          21.834      22.568   \n",
       "4          no    3.500   8.598      11.217          12.015      13.238   \n",
       "\n",
       "   big_road1_km  ID_big_road1 big_road1_1line  big_road2_km  ID_big_road2  \\\n",
       "0         1.060            16              no         1.769             4   \n",
       "1         3.105            12              no         3.128            41   \n",
       "2         0.814            14              no         1.488            28   \n",
       "3         1.444            38              no         4.586             1   \n",
       "4         2.146            14              no         3.157            17   \n",
       "\n",
       "   railroad_km railroad_1line  zd_vokzaly_avto_km  ID_railroad_terminal  \\\n",
       "0        1.234             no               6.923                    32   \n",
       "1        0.945             no               9.907                    97   \n",
       "2        0.053            yes               7.906                    83   \n",
       "3        3.852             no              24.613                    32   \n",
       "4        0.584             no              11.363                    83   \n",
       "\n",
       "   bus_terminal_avto_km  ID_bus_terminal  oil_chemistry_km  \\\n",
       "0                 6.878               13            13.368   \n",
       "1                 1.337                7             6.755   \n",
       "2                 5.130                5            18.153   \n",
       "3                12.909                9            23.425   \n",
       "4                 3.149                1            21.096   \n",
       "\n",
       "   nuclear_reactor_km  radiation_km  power_transmission_line_km  \\\n",
       "0               0.754         0.520                       0.781   \n",
       "1              16.242         0.797                       1.713   \n",
       "2               1.983         2.814                       1.985   \n",
       "3              16.024         5.369                       1.921   \n",
       "4               3.981         0.423                       0.514   \n",
       "\n",
       "   thermal_power_plant_km  ts_km  big_market_km  market_shop_km  fitness_km  \\\n",
       "0                   1.067  5.414          7.936           0.998       1.017   \n",
       "1                   1.232  8.242         16.235           1.278       0.988   \n",
       "2                   3.374  5.060         18.689           2.527       0.833   \n",
       "3                  10.394  6.088          6.328          10.533       1.080   \n",
       "4                   6.148  1.978         23.966           0.856       0.410   \n",
       "\n",
       "   swim_pool_km  ice_rink_km  stadium_km  basketball_km  hospice_morgue_km  \\\n",
       "0         1.020        6.345       5.445          2.174              1.292   \n",
       "1         2.306        4.520       3.826          1.713              2.086   \n",
       "2         2.801        4.201       2.520          2.241              2.236   \n",
       "3         9.791        8.883      14.165          8.176              5.633   \n",
       "4         3.847        6.840       0.712          1.763              0.548   \n",
       "\n",
       "   detention_facility_km  public_healthcare_km  university_km  workplaces_km  \\\n",
       "0                 10.402                 1.762          1.872          0.263   \n",
       "1                  8.253                 0.471          2.678          1.280   \n",
       "2                  4.673                 2.631          0.929          0.072   \n",
       "3                 28.116                 5.090         10.987          7.098   \n",
       "4                  9.233                 0.269          4.788          0.454   \n",
       "\n",
       "   shopping_centers_km  office_km  additional_education_km  preschool_km  \\\n",
       "0                0.597      0.150                    0.894         0.263   \n",
       "1                0.408      0.871                    0.968         0.566   \n",
       "2                0.530      0.461                    0.465         0.481   \n",
       "3                4.909      4.267                    3.978         3.420   \n",
       "4                0.428      0.428                    0.143         0.527   \n",
       "\n",
       "   big_church_km  church_synagogue_km  mosque_km  theater_km  museum_km  \\\n",
       "0          1.057                1.062      4.520       2.878      0.975   \n",
       "1          1.583                0.635      9.293       7.431      6.620   \n",
       "2          1.102                0.609      8.155       7.418      7.414   \n",
       "3          4.601                0.921      4.263      13.726     12.858   \n",
       "4          2.909                1.167      9.327      10.876     10.234   \n",
       "\n",
       "   exhibition_km  catering_km  ecology  green_part_500  prom_part_500  \\\n",
       "0          2.310        0.066     poor           1.020          1.900   \n",
       "1          2.560        0.263     good           0.000         38.700   \n",
       "2          2.553        0.162     poor          14.220          0.000   \n",
       "3          9.831        0.855  no data          17.940          1.510   \n",
       "4          2.593        0.180     poor           0.000          8.990   \n",
       "\n",
       "   office_count_500  office_sqm_500  trc_count_500  trc_sqm_500  \\\n",
       "0                 1           33400              0            0   \n",
       "1                 0               0              1         3164   \n",
       "2                 4           67725              0            0   \n",
       "3                 0               0              0            0   \n",
       "4                 2           69950              2        68000   \n",
       "\n",
       "   cafe_count_500  cafe_sum_500_min_price_avg  cafe_sum_500_max_price_avg  \\\n",
       "0               6                    1000.000                    1583.330   \n",
       "1               2                     400.000                     750.000   \n",
       "2               6                     660.000                    1100.000   \n",
       "3               0                         nan                         nan   \n",
       "4               3                     366.670                     666.670   \n",
       "\n",
       "   cafe_avg_price_500  cafe_count_500_na_price  cafe_count_500_price_500  \\\n",
       "0            1291.670                        0                         0   \n",
       "1             575.000                        0                         1   \n",
       "2             880.000                        1                         1   \n",
       "3                 nan                        0                         0   \n",
       "4             516.670                        0                         2   \n",
       "\n",
       "   cafe_count_500_price_1000  cafe_count_500_price_1500  \\\n",
       "0                          1                          4   \n",
       "1                          1                          0   \n",
       "2                          2                          2   \n",
       "3                          0                          0   \n",
       "4                          1                          0   \n",
       "\n",
       "   cafe_count_500_price_2500  cafe_count_500_price_4000  \\\n",
       "0                          1                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "\n",
       "   cafe_count_500_price_high  big_church_count_500  church_count_500  \\\n",
       "0                          0                     0                 0   \n",
       "1                          0                     0                 0   \n",
       "2                          0                     0                 0   \n",
       "3                          0                     0                 0   \n",
       "4                          0                     0                 0   \n",
       "\n",
       "   mosque_count_500  leisure_count_500  sport_count_500  market_count_500  \\\n",
       "0                 0                  0                1                 1   \n",
       "1                 0                  0                0                 0   \n",
       "2                 0                  0                0                 0   \n",
       "3                 0                  0                0                 0   \n",
       "4                 0                  0                3                 1   \n",
       "\n",
       "   green_part_1000  prom_part_1000  office_count_1000  office_sqm_1000  \\\n",
       "0            5.750          11.510                  7            93706   \n",
       "1            0.060          43.300                  1             6600   \n",
       "2           22.550           1.410                  8           175525   \n",
       "3           23.340           3.110                  0                0   \n",
       "4            5.550          20.540                  2            69950   \n",
       "\n",
       "   trc_count_1000  trc_sqm_1000  cafe_count_1000  cafe_sum_1000_min_price_avg  \\\n",
       "0               1         22000               18                      938.890   \n",
       "1               2         23732                4                      700.000   \n",
       "2               3         74000               22                      700.000   \n",
       "3               0             0                1                      500.000   \n",
       "4               2         68000               10                      877.780   \n",
       "\n",
       "   cafe_sum_1000_max_price_avg  cafe_avg_price_1000  cafe_count_1000_na_price  \\\n",
       "0                     1527.780             1233.330                         0   \n",
       "1                     1125.000              912.500                         0   \n",
       "2                     1166.670              933.330                         1   \n",
       "3                     1000.000              750.000                         0   \n",
       "4                     1444.440             1161.110                         1   \n",
       "\n",
       "   cafe_count_1000_price_500  cafe_count_1000_price_1000  \\\n",
       "0                          3                           4   \n",
       "1                          1                           1   \n",
       "2                          9                           4   \n",
       "3                          0                           1   \n",
       "4                          3                           2   \n",
       "\n",
       "   cafe_count_1000_price_1500  cafe_count_1000_price_2500  \\\n",
       "0                           7                           3   \n",
       "1                           2                           0   \n",
       "2                           4                           4   \n",
       "3                           0                           0   \n",
       "4                           2                           1   \n",
       "\n",
       "   cafe_count_1000_price_4000  cafe_count_1000_price_high  \\\n",
       "0                           1                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           1                           0   \n",
       "\n",
       "   big_church_count_1000  church_count_1000  mosque_count_1000  \\\n",
       "0                      0                  0                  0   \n",
       "1                      0                  1                  0   \n",
       "2                      0                  2                  0   \n",
       "3                      0                  1                  0   \n",
       "4                      0                  0                  0   \n",
       "\n",
       "   leisure_count_1000  sport_count_1000  market_count_1000  green_part_1500  \\\n",
       "0                   1                 1                  1            4.200   \n",
       "1                   0                 1                  3            7.240   \n",
       "2                   0                 1                  0           28.880   \n",
       "3                   0                 0                  0           19.670   \n",
       "4                   0                 4                  1           12.490   \n",
       "\n",
       "   prom_part_1500  office_count_1500  office_sqm_1500  trc_count_1500  \\\n",
       "0          11.800                 10           140677               3   \n",
       "1          36.930                  3            11300               4   \n",
       "2           6.580                 13           557071               7   \n",
       "3           7.860                  0                0               0   \n",
       "4          18.640                  3            71550               3   \n",
       "\n",
       "   trc_sqm_1500  cafe_count_1500  cafe_sum_1500_min_price_avg  \\\n",
       "0         67940               46                      878.260   \n",
       "1         61032               17                      741.180   \n",
       "2        496872               63                      587.040   \n",
       "3             0                1                      500.000   \n",
       "4         73600               13                      891.670   \n",
       "\n",
       "   cafe_sum_1500_max_price_avg  cafe_avg_price_1500  cafe_count_1500_na_price  \\\n",
       "0                     1456.520             1167.390                         0   \n",
       "1                     1235.290              988.240                         0   \n",
       "2                      990.740              788.890                         9   \n",
       "3                     1000.000              750.000                         0   \n",
       "4                     1458.330             1175.000                         1   \n",
       "\n",
       "   cafe_count_1500_price_500  cafe_count_1500_price_1000  \\\n",
       "0                          8                          13   \n",
       "1                          2                           7   \n",
       "2                         24                          15   \n",
       "3                          0                           1   \n",
       "4                          4                           2   \n",
       "\n",
       "   cafe_count_1500_price_1500  cafe_count_1500_price_2500  \\\n",
       "0                          14                          10   \n",
       "1                           7                           1   \n",
       "2                          11                           4   \n",
       "3                           0                           0   \n",
       "4                           3                           2   \n",
       "\n",
       "   cafe_count_1500_price_4000  cafe_count_1500_price_high  \\\n",
       "0                           1                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           1                           0   \n",
       "\n",
       "   big_church_count_1500  church_count_1500  mosque_count_1500  \\\n",
       "0                      1                  1                  0   \n",
       "1                      0                  2                  0   \n",
       "2                      1                  4                  0   \n",
       "3                      0                  1                  0   \n",
       "4                      0                  1                  0   \n",
       "\n",
       "   leisure_count_1500  sport_count_1500  market_count_1500  green_part_2000  \\\n",
       "0                   1                 6                  1           13.050   \n",
       "1                   0                 8                  3           14.690   \n",
       "2                   0                 2                  1           23.740   \n",
       "3                   0                 1                  0           18.180   \n",
       "4                   0                 8                  2           13.720   \n",
       "\n",
       "   prom_part_2000  office_count_2000  office_sqm_2000  trc_count_2000  \\\n",
       "0           6.870                 16           247647               7   \n",
       "1          28.250                  5            86300               4   \n",
       "2           9.480                 20           640702              15   \n",
       "3           8.000                  0                0               0   \n",
       "4          15.320                  4           142450               3   \n",
       "\n",
       "   trc_sqm_2000  cafe_count_2000  cafe_sum_2000_min_price_avg  \\\n",
       "0        615440               90                      780.680   \n",
       "1         61032               27                      672.000   \n",
       "2        741083              108                      678.490   \n",
       "3             0                3                     1833.330   \n",
       "4         73600               21                      975.000   \n",
       "\n",
       "   cafe_sum_2000_max_price_avg  cafe_avg_price_2000  cafe_count_2000_na_price  \\\n",
       "0                     1295.450             1038.070                         2   \n",
       "1                     1120.000              896.000                         2   \n",
       "2                     1139.780              909.140                        15   \n",
       "3                     3000.000             2416.670                         0   \n",
       "4                     1625.000             1300.000                         1   \n",
       "\n",
       "   cafe_count_2000_price_500  cafe_count_2000_price_1000  \\\n",
       "0                         19                          27   \n",
       "1                          6                           9   \n",
       "2                         32                          29   \n",
       "3                          0                           1   \n",
       "4                          5                           6   \n",
       "\n",
       "   cafe_count_2000_price_1500  cafe_count_2000_price_2500  \\\n",
       "0                          29                          12   \n",
       "1                           9                           1   \n",
       "2                          22                           8   \n",
       "3                           0                           0   \n",
       "4                           3                           3   \n",
       "\n",
       "   cafe_count_2000_price_4000  cafe_count_2000_price_high  \\\n",
       "0                           1                           0   \n",
       "1                           0                           0   \n",
       "2                           2                           0   \n",
       "3                           2                           0   \n",
       "4                           3                           0   \n",
       "\n",
       "   big_church_count_2000  church_count_2000  mosque_count_2000  \\\n",
       "0                      2                  4                  0   \n",
       "1                      1                  3                  0   \n",
       "2                      3                  7                  0   \n",
       "3                      0                  3                  0   \n",
       "4                      0                  1                  0   \n",
       "\n",
       "   leisure_count_2000  sport_count_2000  market_count_2000  green_part_3000  \\\n",
       "0                   1                11                  1           13.010   \n",
       "1                   0                12                  4           25.030   \n",
       "2                   0                11                  3           15.610   \n",
       "3                   0                 1                  0           25.800   \n",
       "4                   0                15                  3           18.000   \n",
       "\n",
       "   prom_part_3000  office_count_3000  office_sqm_3000  trc_count_3000  \\\n",
       "0           4.480                 38           755124              16   \n",
       "1          18.360                  8           121139              12   \n",
       "2          12.570                 41          1023356              18   \n",
       "3           4.120                  0                0               0   \n",
       "4          12.880                 18           729427              18   \n",
       "\n",
       "   trc_sqm_3000  cafe_count_3000  cafe_sum_3000_min_price_avg  \\\n",
       "0        844740              183                      791.950   \n",
       "1        122066               50                      715.220   \n",
       "2        769783              159                      696.450   \n",
       "3             0                4                     1750.000   \n",
       "4        787508               86                      775.640   \n",
       "\n",
       "   cafe_sum_3000_max_price_avg  cafe_avg_price_3000  cafe_count_3000_na_price  \\\n",
       "0                     1321.840             1056.900                         9   \n",
       "1                     1206.520              960.870                         4   \n",
       "2                     1166.670              931.560                        18   \n",
       "3                     2875.000             2312.500                         0   \n",
       "4                     1294.870             1035.260                         8   \n",
       "\n",
       "   cafe_count_3000_price_500  cafe_count_3000_price_1000  \\\n",
       "0                         36                          61   \n",
       "1                         13                          17   \n",
       "2                         49                          42   \n",
       "3                          0                           1   \n",
       "4                         20                          25   \n",
       "\n",
       "   cafe_count_3000_price_1500  cafe_count_3000_price_2500  \\\n",
       "0                          51                          21   \n",
       "1                          11                           3   \n",
       "2                          33                          13   \n",
       "3                           0                           1   \n",
       "4                          21                           9   \n",
       "\n",
       "   cafe_count_3000_price_4000  cafe_count_3000_price_high  \\\n",
       "0                           4                           1   \n",
       "1                           2                           0   \n",
       "2                           4                           0   \n",
       "3                           2                           0   \n",
       "4                           3                           0   \n",
       "\n",
       "   big_church_count_3000  church_count_3000  mosque_count_3000  \\\n",
       "0                     10                 12                  0   \n",
       "1                      4                  8                  0   \n",
       "2                      3                  9                  0   \n",
       "3                      0                  5                  0   \n",
       "4                      2                  2                  0   \n",
       "\n",
       "   leisure_count_3000  sport_count_3000  market_count_3000  green_part_5000  \\\n",
       "0                   5                35                  1           11.060   \n",
       "1                   1                28                  5           41.250   \n",
       "2                   2                38                  9           18.730   \n",
       "3                   0                 1                  0           32.940   \n",
       "4                   1                29                  4           18.930   \n",
       "\n",
       "   prom_part_5000  office_count_5000  office_sqm_5000  trc_count_5000  \\\n",
       "0          12.240                153          3196866              43   \n",
       "1           9.640                 19           380612              20   \n",
       "2          12.640                 85          2099848              43   \n",
       "3           6.050                  1            85159               3   \n",
       "4          10.460                 54          1626659              53   \n",
       "\n",
       "   trc_sqm_5000  cafe_count_5000  cafe_sum_5000_min_price_avg  \\\n",
       "0       1986780              578                      825.050   \n",
       "1        719166              100                      650.000   \n",
       "2       1673500              308                      717.200   \n",
       "3         73000               14                     1176.920   \n",
       "4       1994669              255                      735.780   \n",
       "\n",
       "   cafe_sum_5000_max_price_avg  cafe_avg_price_5000  cafe_count_5000_na_price  \\\n",
       "0                     1366.420             1095.730                        39   \n",
       "1                     1101.060              875.530                         6   \n",
       "2                     1204.300              960.750                        29   \n",
       "3                     1884.620             1530.770                         1   \n",
       "4                     1232.760              984.270                        23   \n",
       "\n",
       "   cafe_count_5000_price_500  cafe_count_5000_price_1000  \\\n",
       "0                        129                         160   \n",
       "1                         32                          33   \n",
       "2                         87                          90   \n",
       "3                          1                           2   \n",
       "4                         64                          78   \n",
       "\n",
       "   cafe_count_5000_price_1500  cafe_count_5000_price_2500  \\\n",
       "0                         154                          74   \n",
       "1                          21                           6   \n",
       "2                          66                          27   \n",
       "3                           6                           2   \n",
       "4                          60                          24   \n",
       "\n",
       "   cafe_count_5000_price_4000  cafe_count_5000_price_high  \\\n",
       "0                          18                           4   \n",
       "1                           2                           0   \n",
       "2                           9                           0   \n",
       "3                           2                           0   \n",
       "4                           5                           1   \n",
       "\n",
       "   big_church_count_5000  church_count_5000  mosque_count_5000  \\\n",
       "0                     30                 51                  1   \n",
       "1                     10                 14                  0   \n",
       "2                     11                 25                  0   \n",
       "3                      1                 12                  1   \n",
       "4                     13                 18                  0   \n",
       "\n",
       "   leisure_count_5000  sport_count_5000  market_count_5000 year_month  \n",
       "0                  12                99                  9    2014-03  \n",
       "1                   2                50                  5    2014-05  \n",
       "2                   3                90                 14    2014-01  \n",
       "3                   0                 7                  0    2014-12  \n",
       "4                   1                77                 11    2013-03  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b24451a1-fb8c-4094-ad0b-0940469d07fc",
    "_execution_state": "idle",
    "_uuid": "687813c270cbfdedccc7a9e4ec9fbb78a99d54ed"
   },
   "outputs": [],
   "source": [
    "train_ID = train['id']\n",
    "test_ID = test['id']\n",
    "\n",
    "train.drop(\"id\", axis = 1, inplace = True)\n",
    "test.drop(\"id\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7d5829c4-b2f1-4ef3-8b02-11f02eb7aabf",
    "_execution_state": "idle",
    "_uuid": "228cb602f1c7a47d3c5250514cab57f7e7bc75e5"
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "637bd0fd-7508-41d1-b240-ea0e8598dddf",
    "_execution_state": "idle",
    "_uuid": "8903aa1a4a700aa2160edb3baf806f3800ae7d9a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x = train['life_sq'], y = train['price'])\n",
    "plt.ylabel('price', fontsize=13)\n",
    "plt.xlabel('life_sq', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "6c5780b2-d4a8-42d9-b902-c6a23eef7d99",
    "_execution_state": "idle",
    "_uuid": "583bb417102d7bebb4aaf14bcb1aebcae86443bb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove outlier for life sq\n",
    "train = train.drop(train[(train['life_sq']>300) & (train['price']<2e8)].index)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x = train['life_sq'], y = train['price'])\n",
    "plt.ylabel('price', fontsize=13)\n",
    "plt.xlabel('life_sq', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x = train['full_sq'], y = train['price'])\n",
    "plt.ylabel('price', fontsize=13)\n",
    "plt.xlabel('full_sq', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove outlier for full sq\n",
    "train = train.drop(train[(train['full_sq']>300) & (train['price']<2e8)].index)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x = train['full_sq'], y = train['price'])\n",
    "plt.ylabel('price', fontsize=13)\n",
    "plt.xlabel('full_sq', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "802df76d-0e0b-4868-ba16-91335568d2d7",
    "_execution_state": "idle",
    "_uuid": "827a86d65c6d176f4af55224b91b44a47966652d"
   },
   "source": [
    "## Features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "1bd3e9b9-2f42-4251-aadd-5ced84eb1a27",
    "_execution_state": "idle",
    "_uuid": "efc576211e4eed962f04cd94d901c667e6912528"
   },
   "outputs": [],
   "source": [
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "y_train = train.price.values\n",
    "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
    "all_data.drop(['price'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9ce95008-a3b9-43fa-bc4e-649ca0f43768",
    "_execution_state": "idle",
    "_uuid": "abe25f3032a0bed179d58d5911cb42d97b35841b"
   },
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "501b465f-8c80-4b93-81d0-a5d41e08d235",
    "_execution_state": "idle",
    "_uuid": "f97d25548ec8f6c02e2d1ee5a6df6c3d107fdf53"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hospital_beds_raion</th>\n",
       "      <td>47.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build_year</th>\n",
       "      <td>44.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>44.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cafe_avg_price_500</th>\n",
       "      <td>43.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cafe_sum_500_max_price_avg</th>\n",
       "      <td>43.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cafe_sum_500_min_price_avg</th>\n",
       "      <td>43.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kitch_sq</th>\n",
       "      <td>31.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_room</th>\n",
       "      <td>31.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_floor</th>\n",
       "      <td>31.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>material</th>\n",
       "      <td>31.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preschool_quota</th>\n",
       "      <td>21.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school_quota</th>\n",
       "      <td>21.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cafe_sum_1000_max_price_avg</th>\n",
       "      <td>21.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cafe_sum_1000_min_price_avg</th>\n",
       "      <td>21.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cafe_avg_price_1000</th>\n",
       "      <td>21.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life_sq</th>\n",
       "      <td>20.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build_count_1971-1995</th>\n",
       "      <td>16.387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raion_build_count_with_material_info</th>\n",
       "      <td>16.387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raion_build_count_with_builddate_info</th>\n",
       "      <td>16.387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build_count_wood</th>\n",
       "      <td>16.387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Missing Ratio\n",
       "hospital_beds_raion                           47.401\n",
       "build_year                                    44.637\n",
       "state                                         44.486\n",
       "cafe_avg_price_500                            43.579\n",
       "cafe_sum_500_max_price_avg                    43.579\n",
       "cafe_sum_500_min_price_avg                    43.579\n",
       "kitch_sq                                      31.402\n",
       "num_room                                      31.402\n",
       "max_floor                                     31.402\n",
       "material                                      31.402\n",
       "preschool_quota                               21.959\n",
       "school_quota                                  21.949\n",
       "cafe_sum_1000_max_price_avg                   21.407\n",
       "cafe_sum_1000_min_price_avg                   21.407\n",
       "cafe_avg_price_1000                           21.407\n",
       "life_sq                                       20.948\n",
       "build_count_1971-1995                         16.387\n",
       "raion_build_count_with_material_info          16.387\n",
       "raion_build_count_with_builddate_info         16.387\n",
       "build_count_wood                              16.387"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "1c80610d-8f19-43c8-bd54-7d786b0dca49",
    "_execution_state": "idle",
    "_uuid": "2eb6e1361884db6a4f65afc3b158fcbe85c2392e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Percent missing data by feature')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(15, 12))\n",
    "plt.xticks(rotation='90')\n",
    "sns.barplot(x=all_data_na.index, y=all_data_na)\n",
    "plt.xlabel('Features', fontsize=15)\n",
    "plt.ylabel('Percent of missing values', fontsize=15)\n",
    "plt.title('Percent missing data by feature', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"year_month\"] = all_data[\"year_month\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['year'] = all_data.timestamp.dt.year\n",
    "all_data['month'] = all_data.timestamp.dt.month\n",
    "all_data.drop(columns=['timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014.000        919\n",
       "2015.000        824\n",
       "0.000           530\n",
       "2013.000        464\n",
       "1970.000        418\n",
       "1969.000        407\n",
       "1968.000        389\n",
       "1967.000        384\n",
       "1965.000        378\n",
       "2016.000        374\n",
       "1.000           368\n",
       "1972.000        360\n",
       "1974.000        357\n",
       "1971.000        352\n",
       "1966.000        348\n",
       "1960.000        344\n",
       "1962.000        338\n",
       "1973.000        333\n",
       "1963.000        325\n",
       "1964.000        315\n",
       "1975.000        309\n",
       "1961.000        297\n",
       "1976.000        263\n",
       "1977.000        260\n",
       "2006.000        242\n",
       "1978.000        235\n",
       "1979.000        235\n",
       "2008.000        234\n",
       "2012.000        233\n",
       "1980.000        226\n",
       "2004.000        220\n",
       "2007.000        219\n",
       "2002.000        214\n",
       "1959.000        208\n",
       "2003.000        193\n",
       "1981.000        189\n",
       "1982.000        189\n",
       "1983.000        185\n",
       "1958.000        179\n",
       "1985.000        178\n",
       "2001.000        177\n",
       "2005.000        176\n",
       "2009.000        176\n",
       "1987.000        171\n",
       "1984.000        169\n",
       "2011.000        162\n",
       "1996.000        161\n",
       "1994.000        160\n",
       "1988.000        155\n",
       "1989.000        155\n",
       "2017.000        154\n",
       "1995.000        149\n",
       "1998.000        141\n",
       "1992.000        139\n",
       "1997.000        139\n",
       "2010.000        132\n",
       "1986.000        131\n",
       "2000.000        130\n",
       "1990.000        129\n",
       "1999.000        124\n",
       "1957.000        119\n",
       "1993.000        115\n",
       "1991.000         93\n",
       "1955.000         52\n",
       "1956.000         48\n",
       "1952.000         45\n",
       "1954.000         36\n",
       "1953.000         24\n",
       "1951.000         23\n",
       "1950.000         22\n",
       "1917.000         16\n",
       "1940.000         14\n",
       "1934.000         13\n",
       "1928.000         12\n",
       "1929.000         12\n",
       "1935.000         11\n",
       "1937.000         10\n",
       "1927.000         10\n",
       "1938.000          9\n",
       "1926.000          8\n",
       "1932.000          8\n",
       "1933.000          7\n",
       "1939.000          7\n",
       "1931.000          6\n",
       "1930.000          6\n",
       "1915.000          5\n",
       "1910.000          5\n",
       "1890.000          5\n",
       "1936.000          5\n",
       "1912.000          5\n",
       "1947.000          4\n",
       "1924.000          3\n",
       "1949.000          3\n",
       "1914.000          3\n",
       "1941.000          2\n",
       "3.000             2\n",
       "1900.000          2\n",
       "1907.000          2\n",
       "1946.000          2\n",
       "1896.000          2\n",
       "1943.000          2\n",
       "1860.000          2\n",
       "20.000            1\n",
       "4965.000          1\n",
       "1925.000          1\n",
       "1905.000          1\n",
       "1904.000          1\n",
       "1876.000          1\n",
       "71.000            1\n",
       "1886.000          1\n",
       "1906.000          1\n",
       "1920.000          1\n",
       "1691.000          1\n",
       "215.000           1\n",
       "20052009.000      1\n",
       "1948.000          1\n",
       "1895.000          1\n",
       "2018.000          1\n",
       "1911.000          1\n",
       "Name: build_year, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.build_year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.loc[all_data.build_year > 2018, 'build_year'] = np.NaN\n",
    "all_data.loc[all_data.build_year < 1800, 'build_year'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014.000    919\n",
       "2015.000    824\n",
       "2013.000    464\n",
       "1970.000    418\n",
       "1969.000    407\n",
       "1968.000    389\n",
       "1967.000    384\n",
       "1965.000    378\n",
       "2016.000    374\n",
       "1972.000    360\n",
       "1974.000    357\n",
       "1971.000    352\n",
       "1966.000    348\n",
       "1960.000    344\n",
       "1962.000    338\n",
       "1973.000    333\n",
       "1963.000    325\n",
       "1964.000    315\n",
       "1975.000    309\n",
       "1961.000    297\n",
       "1976.000    263\n",
       "1977.000    260\n",
       "2006.000    242\n",
       "1979.000    235\n",
       "1978.000    235\n",
       "2008.000    234\n",
       "2012.000    233\n",
       "1980.000    226\n",
       "2004.000    220\n",
       "2007.000    219\n",
       "2002.000    214\n",
       "1959.000    208\n",
       "2003.000    193\n",
       "1981.000    189\n",
       "1982.000    189\n",
       "1983.000    185\n",
       "1958.000    179\n",
       "1985.000    178\n",
       "2001.000    177\n",
       "2005.000    176\n",
       "2009.000    176\n",
       "1987.000    171\n",
       "1984.000    169\n",
       "2011.000    162\n",
       "1996.000    161\n",
       "1994.000    160\n",
       "1989.000    155\n",
       "1988.000    155\n",
       "2017.000    154\n",
       "1995.000    149\n",
       "1998.000    141\n",
       "1992.000    139\n",
       "1997.000    139\n",
       "2010.000    132\n",
       "1986.000    131\n",
       "2000.000    130\n",
       "1990.000    129\n",
       "1999.000    124\n",
       "1957.000    119\n",
       "1993.000    115\n",
       "1991.000     93\n",
       "1955.000     52\n",
       "1956.000     48\n",
       "1952.000     45\n",
       "1954.000     36\n",
       "1953.000     24\n",
       "1951.000     23\n",
       "1950.000     22\n",
       "1917.000     16\n",
       "1940.000     14\n",
       "1934.000     13\n",
       "1929.000     12\n",
       "1928.000     12\n",
       "1935.000     11\n",
       "1937.000     10\n",
       "1927.000     10\n",
       "1938.000      9\n",
       "1926.000      8\n",
       "1932.000      8\n",
       "1933.000      7\n",
       "1939.000      7\n",
       "1930.000      6\n",
       "1931.000      6\n",
       "1912.000      5\n",
       "1936.000      5\n",
       "1890.000      5\n",
       "1910.000      5\n",
       "1915.000      5\n",
       "1947.000      4\n",
       "1949.000      3\n",
       "1924.000      3\n",
       "1914.000      3\n",
       "1946.000      2\n",
       "1907.000      2\n",
       "1943.000      2\n",
       "1941.000      2\n",
       "1900.000      2\n",
       "1896.000      2\n",
       "1860.000      2\n",
       "1920.000      1\n",
       "1925.000      1\n",
       "1905.000      1\n",
       "1904.000      1\n",
       "1876.000      1\n",
       "1886.000      1\n",
       "1911.000      1\n",
       "2018.000      1\n",
       "1895.000      1\n",
       "1948.000      1\n",
       "1906.000      1\n",
       "Name: build_year, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.build_year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = ['max_floor', 'material', 'build_year']\n",
    "for column in all_data.columns:\n",
    "    if 'avg' in column or 'count' in column \\\n",
    "    or 'quota' in column:\n",
    "        all_data[column] = all_data.groupby([\"ID_bus_terminal\"])[column].apply(\n",
    "            lambda x: x.fillna(np.nanmean(x)))\n",
    "        all_data[column] = all_data.groupby([\"ID_metro\"])[column].apply(\n",
    "            lambda x: x.fillna(np.nanmean(x)))\n",
    "        all_data[column] = all_data.groupby([\"sub_area\"])[column].apply(\n",
    "            lambda x: x.fillna(np.nanmean(x)))\n",
    "        all_data[column] = all_data.groupby([\"ID_railroad_station_walk\"])[column].apply(\n",
    "            lambda x: x.fillna(np.nanmean(x)))\n",
    "        all_data[column] = all_data.groupby([\"ID_big_road1\"])[column].apply(\n",
    "            lambda x: x.fillna(np.nanmean(x)))\n",
    "        all_data[column] = all_data.groupby([\"ID_railroad_terminal\"])[column].apply(\n",
    "            lambda x: x.fillna(np.nanmean(x)))\n",
    "        \n",
    "for column in all_data.columns:\n",
    "    if column in columns_list:\n",
    "        all_data[column] = all_data.groupby([\"ID_bus_terminal\"])[column].apply(\n",
    "            lambda x: x.fillna(np.nanmedian(x)))\n",
    "        all_data[column] = all_data.groupby([\"ID_metro\"])[column].apply(\n",
    "            lambda x: x.fillna(np.nanmedian(x)))\n",
    "        all_data[column] = all_data.groupby([\"sub_area\"])[column].apply(\n",
    "            lambda x: x.fillna(np.nanmedian(x)))\n",
    "        all_data[column] = all_data.groupby([\"ID_railroad_station_walk\"])[column].apply(\n",
    "            lambda x: x.fillna(np.nanmedian(x)))\n",
    "        all_data[column] = all_data.groupby([\"ID_big_road1\"])[column].apply(\n",
    "            lambda x: x.fillna(np.nanmedian(x)))\n",
    "        all_data[column] = all_data.groupby([\"ID_railroad_terminal\"])[column].apply(\n",
    "            lambda x: x.fillna(np.nanmedian(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"state\"] = all_data.groupby([\"build_year\"])[\"state\"].transform(\n",
    "    lambda x: x.fillna(np.nanmedian(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_based_on_area = ['hospital_beds_raion', 'build_year']\n",
    "\n",
    "all_data[\"hospital_beds_raion\"] = all_data.groupby([\"sub_area\"])[\"hospital_beds_raion\"].transform(\n",
    "    lambda x: x.fillna(np.nanmean(x)))\n",
    "all_data[\"hospital_beds_raion\"] = all_data.groupby([\"ID_bus_terminal\"])[\"hospital_beds_raion\"].apply(\n",
    "    lambda x: x.fillna(np.nanmean(x)))\n",
    "all_data[\"hospital_beds_raion\"] = all_data.groupby([\"ID_metro\"])[\"hospital_beds_raion\"].transform(\n",
    "    lambda x: x.fillna(np.nanmean(x)))\n",
    "all_data[\"hospital_beds_raion\"] = all_data.groupby([\"ID_railroad_station_walk\"])[\"hospital_beds_raion\"].apply(\n",
    "    lambda x: x.fillna(np.nanmean(x)))\n",
    "all_data[\"hospital_beds_raion\"] = all_data.groupby([\"ID_big_road1\"])[\"hospital_beds_raion\"].apply(\n",
    "    lambda x: x.fillna(np.nanmean(x)))\n",
    "all_data[\"hospital_beds_raion\"] = all_data.groupby([\"ID_railroad_terminal\"])[\"hospital_beds_raion\"].apply(\n",
    "    lambda x: x.fillna(np.nanmean(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"num_room\"] = all_data.groupby(pd.cut(all_data[\"life_sq\"], [0, 20, 40, 60, 80, 100, 130, 1000]))[\"num_room\"].apply(\n",
    "    lambda x: x.fillna(np.nanmedian(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"num_room\"] = all_data.groupby(pd.cut(all_data[\"full_sq\"], [0, 20, 40, 60, 80, 100, 130, 1000]))[\"num_room\"].apply(\n",
    "    lambda x: x.fillna(np.nanmedian(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"life_sq\"] = all_data.groupby(pd.cut(all_data[\"full_sq\"], [0, 10, 20, 30, 40, 50, 60, 70, 80, 100,120, 140, 160, 200, 300, 1000]))[\"num_room\"].apply(\n",
    "    lambda x: x.fillna(np.nanmedian(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"kitch_sq\"] = all_data.groupby(pd.cut(all_data[\"life_sq\"], [0, 20, 40, 60, 80, 100, 130, 1000]))[\"kitch_sq\"].apply(\n",
    "    lambda x: x.fillna(np.nanmedian(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "0adf05cf-ce60-4169-805c-ca776e60e85a",
    "_execution_state": "idle",
    "_uuid": "b091fa2ebef19425019e2e550410d0376b9e9fac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prom_part_5000</th>\n",
       "      <td>0.584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floor</th>\n",
       "      <td>0.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>railroad_station_walk_min</th>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>railroad_station_walk_km</th>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metro_min_walk</th>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Missing Ratio\n",
       "prom_part_5000                     0.584\n",
       "floor                              0.548\n",
       "railroad_station_walk_min          0.082\n",
       "railroad_station_walk_km           0.082\n",
       "metro_min_walk                     0.082"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check remaining missing values\n",
    "all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "a52dc2f9-ca02-4024-987a-165ce630b356",
    "_execution_state": "idle",
    "_uuid": "cc7557817a4442e799e4e4c84dd1efd8bd08867a"
   },
   "outputs": [],
   "source": [
    "# Transforming some numerical variables\n",
    "cat_features = ['material', 'state', 'ID_metro', 'ID_railroad_station_walk', 'ID_railroad_station_avto',\n",
    "'ID_big_road1', 'big_road1_1line', 'ID_big_road2', 'ID_railroad_terminal', 'ID_bus_terminal']\n",
    "for feature in cat_features:\n",
    "    all_data[feature] = all_data[feature].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "81c97efb-4f76-4e87-861a-10a60ab5c84b",
    "_execution_state": "idle",
    "_uuid": "fdb5ddf0a49a3c6df303c569c9f3509c79ac8b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape all_data: (30457, 292)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "cols = ['product_type', 'sub_area', 'material', 'state', 'ID_metro', 'ID_railroad_station_walk', 'ID_railroad_station_avto',\n",
    "'ID_big_road1', 'big_road1_1line', 'ID_big_road2', 'ID_railroad_terminal', 'ID_bus_terminal']\n",
    "\n",
    "\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(all_data[c].values)) \n",
    "    all_data[c] = lbl.transform(list(all_data[c].values))\n",
    "      \n",
    "print('Shape all_data: {}'.format(all_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "91c73aad-82d1-4301-b540-b2f69dc13902",
    "_execution_state": "idle",
    "_uuid": "aa36d6e3253e354b46d9c9c6f2e8a4089c76be16"
   },
   "source": [
    "**Skewed features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "c5972a73-7e86-4164-a9d6-58432dae1933",
    "_execution_state": "idle",
    "_uuid": "53c471c7008c66590f257e70866f8a3037813f13"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kitch_sq</th>\n",
       "      <td>80.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mosque_count_500</th>\n",
       "      <td>14.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leisure_count_500</th>\n",
       "      <td>10.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build_count_foam</th>\n",
       "      <td>9.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public_transport_station_min_walk</th>\n",
       "      <td>9.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public_transport_station_km</th>\n",
       "      <td>9.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cafe_count_1000_price_high</th>\n",
       "      <td>8.481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kindergarten_km</th>\n",
       "      <td>7.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preschool_km</th>\n",
       "      <td>7.464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school_km</th>\n",
       "      <td>7.450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Skew\n",
       "kitch_sq                          80.843\n",
       "mosque_count_500                  14.192\n",
       "leisure_count_500                 10.203\n",
       "build_count_foam                   9.877\n",
       "public_transport_station_min_walk  9.472\n",
       "public_transport_station_km        9.472\n",
       "cafe_count_1000_price_high         8.481\n",
       "kindergarten_km                    7.936\n",
       "preschool_km                       7.464\n",
       "school_km                          7.450"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9f110087-b707-4073-a1df-0a0a9d6ccbd3",
    "_execution_state": "idle",
    "_uuid": "cf63bdc9f4f80d81f1bfa14f89d65ff104d45e5b"
   },
   "source": [
    "**Box Cox Transformation of skewed features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "d8ebce87-c55d-46c6-8f06-8b34116d7370",
    "_execution_state": "idle",
    "_uuid": "969fdff338ef46f064d8f855782c96d322a264b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 279 skewed numerical features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    all_data[feat] = boxcox1p(all_data[feat], lam)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "c8e63516-e4e2-4f36-a60e-1c8316392c60",
    "_execution_state": "idle",
    "_uuid": "acd44e283867425257ffd1fb2f4893cdbff43f67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30457, 353)\n"
     ]
    }
   ],
   "source": [
    "all_data.fillna(0, inplace=True)\n",
    "all_data = pd.get_dummies(all_data)\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_cell_guid": "0a75646f-1974-40ad-a085-ff7bc08454a5",
    "_execution_state": "idle",
    "_uuid": "89e464095544a53177d5a009b914ba4c660072a7"
   },
   "outputs": [],
   "source": [
    "train = all_data[:ntrain]\n",
    "test = all_data[ntrain:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "461af83d-a928-4645-8512-5e4dbcaf7be0",
    "_execution_state": "idle",
    "_uuid": "10aab4cee97832560e2627a490e01e80c0ffb814"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "135e8ac5-ce46-4a5f-b205-13f827ef33b8",
    "_execution_state": "idle",
    "_uuid": "fc664fbe27561a3697d0210921107b0e14b7d211"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "f396260b-e182-4a87-9a2a-b92b9375ea6f",
    "_execution_state": "idle",
    "_uuid": "5c12551d092a6c5cf32d86398b054da7af3047b8"
   },
   "outputs": [],
   "source": [
    "# Validation function\n",
    "n_folds = 5\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "\n",
    "def metric(y_pred, y):\n",
    "    return mean_absolute_error(y_pred, y)\n",
    "\n",
    "my_scorer = make_scorer(metric, greater_is_better=False)\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True).get_n_splits(train.values)\n",
    "    rmse= -cross_val_score(model, train.values, y_train, scoring=my_scorer, cv = kf)\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn =  KNeighborsClassifier(n_neighbors=15, weights='distance', leaf_size=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN score: 2864443.4758 (129349.4387)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(knn)\n",
    "print(\"KNN score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "_cell_guid": "03f45cb7-0a40-45ea-94e8-64fd7ff1e8f6",
    "_execution_state": "idle",
    "_uuid": "2a50c954cb771d350c3092c3658486ba4d22aba5"
   },
   "outputs": [],
   "source": [
    "lasso =  Lasso(alpha=0.005, max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "_cell_guid": "2d0cc958-1654-425c-90ed-1ceb9edd7186",
    "_execution_state": "idle",
    "_uuid": "7d994349237b9304b0d17719e1af077e69288229"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso score: 1798894.4275 (39703.9536)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2c826f7b-ac66-421c-a7ae-29dfdd765bdb",
    "_execution_state": "idle",
    "_uuid": "30e9756cf63991715b48e8c53bc57906fc76f380"
   },
   "source": [
    "### Elastic Net Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "_cell_guid": "e635cc7e-caeb-4f8b-ae78-c41f8eb0be59",
    "_execution_state": "idle",
    "_uuid": "b614cf1bdee86a3b1cbdde05298f9f7ae023799b"
   },
   "outputs": [],
   "source": [
    "ENet = ElasticNet(alpha=0.005, l1_ratio=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "_cell_guid": "7cf6faaf-d69a-4268-b192-a9e60d207c28",
    "_execution_state": "idle",
    "_uuid": "b6d299b9d4a0cdb23ddd8459b3935da2948016d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet score: 1788393.4870 (33359.2710)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(ENet)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7aae5316-4e32-4203-bff5-3b38c1f657c3",
    "_execution_state": "idle",
    "_uuid": "0775061bb477242f1332a048778e879ca540a216"
   },
   "source": [
    "### Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "_cell_guid": "805343d9-0af6-43a2-a351-c0b25c62fcf0",
    "_execution_state": "idle",
    "_uuid": "3199c83513d93407c818ce1ed43c6c52e7f5a8c6"
   },
   "outputs": [],
   "source": [
    "KRR = KernelRidge(alpha=0.4, kernel='polynomial', degree=2, coef0=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "_cell_guid": "a1195106-2170-47f2-86a7-c4f3be683aa8",
    "_execution_state": "idle",
    "_uuid": "437dc093e88d661a369539520af1b4c37d1a0c1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Ridge score: 1666153.5875 (46294.1258)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(KRR)\n",
    "print(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 353)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 353)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           11328       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           2112        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           2080        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           2112        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           4160        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           2080        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           2112        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 64)           4160        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           4160        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 417)          0           input_1[0][0]                    \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            418         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 34,722\n",
      "Trainable params: 34,722\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Concatenate, BatchNormalization,\\\n",
    "    Dropout, Conv1D, Embedding, Reshape, Flatten, LSTM, LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "activation = 'relu'\n",
    "def create_model():\n",
    "    # keras.backend.clear_session()\n",
    "    \n",
    "    input_all = Input(shape=(353, ))\n",
    "    \n",
    "    drop = Dropout(0.05)(input_all)\n",
    "    dense = Dense(32, activation=activation)(drop)\n",
    "    dense = Dense(64, activation=activation)(dense)\n",
    "    dense = Dense(32, activation=activation)(dense)\n",
    "    dense = Dense(64, activation=activation)(dense)\n",
    "    dense = Dense(64, activation=activation)(dense)\n",
    "    dense = Dense(32, activation=activation)(dense)\n",
    "    dense = Dense(64, activation=activation)(dense)\n",
    "    dense = Dense(64, activation=activation)(dense)\n",
    "    dense = Dense(64, activation=activation)(dense)\n",
    "    dense = Concatenate()([input_all, dense])\n",
    "    dense = Dense(1)(dense)\n",
    "    model = Model(inputs=input_all, outputs=dense)\n",
    "    model.compile(loss='mean_absolute_error', optimizer=Adam())\n",
    "    return model\n",
    "\n",
    "create_model().summary()\n",
    "class NNClassifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        self.model = create_model()\n",
    "        save_model_name = f'nn_2'\n",
    "        batch_size = 512\n",
    "        \n",
    "        model_checkpoint = ModelCheckpoint(save_model_name, monitor='val_loss',\n",
    "                                           save_best_only=True)\n",
    "        self.model.fit(X, y, verbose=1, epochs=600,\n",
    "                 validation_split=0.1,  callbacks=[model_checkpoint],\n",
    "                       batch_size=batch_size)\n",
    "        self.model.load_weights(filepath=save_model_name)\n",
    "        \n",
    "    def predict(self, X, y=None):\n",
    "#         dtest = lgb.Dataset(X)\n",
    "#         dtest.save_binary('test.lgb')\n",
    "        return self.model.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14389 samples, validate on 1599 samples\n",
      "Epoch 1/600\n",
      "14389/14389 [==============================] - 1s 65us/step - loss: 7116062.4968 - val_loss: 7250173.0575\n",
      "Epoch 2/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 7044895.2057 - val_loss: 6770613.3058\n",
      "Epoch 3/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 4124807.7659 - val_loss: 2896383.0563\n",
      "Epoch 4/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2669623.4741 - val_loss: 2700459.7722\n",
      "Epoch 5/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2624580.9385 - val_loss: 2703428.2217\n",
      "Epoch 6/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2617625.9883 - val_loss: 2697436.9021\n",
      "Epoch 7/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2616463.9413 - val_loss: 2698637.5120\n",
      "Epoch 8/600\n",
      "14389/14389 [==============================] - 0s 9us/step - loss: 2618258.7985 - val_loss: 2697192.7992\n",
      "Epoch 9/600\n",
      "14389/14389 [==============================] - 0s 8us/step - loss: 2612385.2110 - val_loss: 2692033.7270\n",
      "Epoch 10/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2612152.6419 - val_loss: 2690658.5791\n",
      "Epoch 11/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 2609797.2204 - val_loss: 2687248.3133\n",
      "Epoch 12/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2603020.8523 - val_loss: 2685403.9801\n",
      "Epoch 13/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2600331.6602 - val_loss: 2683891.5167\n",
      "Epoch 14/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2598023.2544 - val_loss: 2681002.9811\n",
      "Epoch 15/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2596135.2640 - val_loss: 2682007.3118\n",
      "Epoch 16/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2592828.2080 - val_loss: 2675294.5597\n",
      "Epoch 17/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2588168.5691 - val_loss: 2673956.0174\n",
      "Epoch 18/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2589098.2013 - val_loss: 2670928.6817\n",
      "Epoch 19/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2585741.6014 - val_loss: 2667796.3485\n",
      "Epoch 20/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2580858.1302 - val_loss: 2680258.4443\n",
      "Epoch 21/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2583463.7119 - val_loss: 2657253.0849\n",
      "Epoch 22/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2574815.6043 - val_loss: 2653622.7689\n",
      "Epoch 23/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2572938.9271 - val_loss: 2660623.5452\n",
      "Epoch 24/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2565082.6005 - val_loss: 2643524.5189\n",
      "Epoch 25/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2562673.3653 - val_loss: 2639703.8813\n",
      "Epoch 26/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2556504.8846 - val_loss: 2632829.4656\n",
      "Epoch 27/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2544995.7900 - val_loss: 2638844.8211\n",
      "Epoch 28/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2558733.4210 - val_loss: 2645129.7022\n",
      "Epoch 29/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2541343.0063 - val_loss: 2612535.1332\n",
      "Epoch 30/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2533119.0781 - val_loss: 2611307.0233\n",
      "Epoch 31/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2516702.9233 - val_loss: 2593388.6567\n",
      "Epoch 32/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2506189.8999 - val_loss: 2578416.4285\n",
      "Epoch 33/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2498714.4253 - val_loss: 2561661.4339\n",
      "Epoch 34/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2489444.3234 - val_loss: 2542876.4376\n",
      "Epoch 35/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2476112.3520 - val_loss: 2522376.4845\n",
      "Epoch 36/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2456184.5957 - val_loss: 2510888.7167\n",
      "Epoch 37/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2432854.5124 - val_loss: 2470816.5159\n",
      "Epoch 38/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2402890.7354 - val_loss: 2446856.3824\n",
      "Epoch 39/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2381634.0246 - val_loss: 2426754.7708\n",
      "Epoch 40/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2362402.9119 - val_loss: 2372585.7609\n",
      "Epoch 41/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2337591.2204 - val_loss: 2344321.7725\n",
      "Epoch 42/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2308126.4545 - val_loss: 2303192.7813\n",
      "Epoch 43/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2285042.1816 - val_loss: 2261465.2969\n",
      "Epoch 44/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2266931.4806 - val_loss: 2295865.8535\n",
      "Epoch 45/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2267091.1479 - val_loss: 2209751.7566\n",
      "Epoch 46/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2236060.4205 - val_loss: 2225656.7567\n",
      "Epoch 47/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2216419.3896 - val_loss: 2172773.4265\n",
      "Epoch 48/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2206664.1742 - val_loss: 2168012.6620\n",
      "Epoch 49/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2193213.4753 - val_loss: 2116860.7875\n",
      "Epoch 50/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2152424.5294 - val_loss: 2091509.2451\n",
      "Epoch 51/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2136826.9862 - val_loss: 2077544.6583\n",
      "Epoch 52/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2119943.6632 - val_loss: 2072670.3576\n",
      "Epoch 53/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2109464.3217 - val_loss: 2048735.9194\n",
      "Epoch 54/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2097928.5246 - val_loss: 2034338.5695\n",
      "Epoch 55/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2072840.1280 - val_loss: 2013130.1704\n",
      "Epoch 56/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 2070533.5319 - val_loss: 2005092.8064\n",
      "Epoch 57/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2044205.5352 - val_loss: 1968672.0622\n",
      "Epoch 58/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2041860.8222 - val_loss: 1980349.9493\n",
      "Epoch 59/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2007915.2754 - val_loss: 2064908.2835\n",
      "Epoch 60/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2008910.8079 - val_loss: 2236810.3102\n",
      "Epoch 61/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 2030915.9906 - val_loss: 1893941.8457\n",
      "Epoch 62/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1995733.0148 - val_loss: 1935134.8990\n",
      "Epoch 63/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1980988.1224 - val_loss: 1867758.1966\n",
      "Epoch 64/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1982292.8343 - val_loss: 1946000.3719\n",
      "Epoch 65/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1969575.0676 - val_loss: 1981370.7902\n",
      "Epoch 66/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1956955.4809 - val_loss: 1890951.7253\n",
      "Epoch 67/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1954322.9245 - val_loss: 1889373.6460\n",
      "Epoch 68/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1931551.5410 - val_loss: 2015527.6656\n",
      "Epoch 69/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1942662.7089 - val_loss: 1882321.7576\n",
      "Epoch 70/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14389/14389 [==============================] - 0s 7us/step - loss: 1921569.5469 - val_loss: 1878277.5412\n",
      "Epoch 71/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1922289.3798 - val_loss: 2007520.0092\n",
      "Epoch 72/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1942261.4514 - val_loss: 1847171.2466\n",
      "Epoch 73/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1919228.4821 - val_loss: 1860033.4810\n",
      "Epoch 74/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1929779.7663 - val_loss: 1898742.0755\n",
      "Epoch 75/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1897528.1074 - val_loss: 2011799.7240\n",
      "Epoch 76/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1913777.9659 - val_loss: 1936640.4271\n",
      "Epoch 77/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1887212.4328 - val_loss: 1815678.6114\n",
      "Epoch 78/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1881271.0467 - val_loss: 1829194.9863\n",
      "Epoch 79/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1893039.0500 - val_loss: 1839454.6904\n",
      "Epoch 80/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1885490.4663 - val_loss: 1807830.5220\n",
      "Epoch 81/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1874483.6694 - val_loss: 1935418.5779\n",
      "Epoch 82/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1855561.8608 - val_loss: 1906514.2692\n",
      "Epoch 83/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1873108.3420 - val_loss: 1776398.4406\n",
      "Epoch 84/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1863882.5310 - val_loss: 1975366.5471\n",
      "Epoch 85/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1865310.6554 - val_loss: 1818103.2763\n",
      "Epoch 86/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1876575.2733 - val_loss: 1833878.8546\n",
      "Epoch 87/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1878984.5720 - val_loss: 2011143.4762\n",
      "Epoch 88/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1831851.5378 - val_loss: 1883661.4292\n",
      "Epoch 89/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1840665.9928 - val_loss: 1888202.5102\n",
      "Epoch 90/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1846384.1657 - val_loss: 1839421.9392\n",
      "Epoch 91/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1825015.7839 - val_loss: 2004309.8160\n",
      "Epoch 92/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1847145.7895 - val_loss: 1930220.6879\n",
      "Epoch 93/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1829617.8836 - val_loss: 1933748.5544\n",
      "Epoch 94/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1850874.5356 - val_loss: 1865336.2344\n",
      "Epoch 95/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1817947.5805 - val_loss: 1859807.1954\n",
      "Epoch 96/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1821292.4013 - val_loss: 1824183.0825\n",
      "Epoch 97/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1830308.0463 - val_loss: 1805056.9608\n",
      "Epoch 98/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1820542.4800 - val_loss: 1817973.6833\n",
      "Epoch 99/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1833930.0843 - val_loss: 1889387.3261\n",
      "Epoch 100/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1813021.3108 - val_loss: 1836390.3669\n",
      "Epoch 101/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1810785.3585 - val_loss: 1890338.1811\n",
      "Epoch 102/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1816358.0502 - val_loss: 1908189.1303\n",
      "Epoch 103/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1835388.4085 - val_loss: 1932551.5562\n",
      "Epoch 104/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1827636.7634 - val_loss: 1899247.7384\n",
      "Epoch 105/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1796701.9864 - val_loss: 1993758.2143\n",
      "Epoch 106/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1807451.1788 - val_loss: 1884680.6161\n",
      "Epoch 107/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1813237.2947 - val_loss: 1834159.1777\n",
      "Epoch 108/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1781026.2362 - val_loss: 1822553.2450\n",
      "Epoch 109/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1782979.6739 - val_loss: 1908892.6884\n",
      "Epoch 110/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1770150.8443 - val_loss: 1788073.0099\n",
      "Epoch 111/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1779725.6055 - val_loss: 1824678.9147\n",
      "Epoch 112/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1777062.6207 - val_loss: 1779600.7505\n",
      "Epoch 113/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1784059.7383 - val_loss: 1735786.0937\n",
      "Epoch 114/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1798509.2023 - val_loss: 1704442.6766\n",
      "Epoch 115/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1779541.3903 - val_loss: 1745680.7049\n",
      "Epoch 116/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1770042.6710 - val_loss: 1704042.2858\n",
      "Epoch 117/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1765097.3344 - val_loss: 1751478.6942\n",
      "Epoch 118/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1759039.1714 - val_loss: 1837396.9923\n",
      "Epoch 119/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1768492.7383 - val_loss: 1922927.8578\n",
      "Epoch 120/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1767996.6577 - val_loss: 1705675.8060\n",
      "Epoch 121/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1771573.9839 - val_loss: 1756834.5997\n",
      "Epoch 122/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1739617.1256 - val_loss: 1903640.1643\n",
      "Epoch 123/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1781936.8842 - val_loss: 1824088.5403\n",
      "Epoch 124/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1747086.2171 - val_loss: 1941389.0890\n",
      "Epoch 125/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1752149.6745 - val_loss: 1811028.6020\n",
      "Epoch 126/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1743842.8472 - val_loss: 1791114.4326\n",
      "Epoch 127/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1743873.5749 - val_loss: 1739870.5680\n",
      "Epoch 128/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1744970.7422 - val_loss: 1664144.1974\n",
      "Epoch 129/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1761941.8879 - val_loss: 1695484.8297\n",
      "Epoch 130/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1723393.3593 - val_loss: 1730928.0794\n",
      "Epoch 131/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1745718.8913 - val_loss: 1767003.6339\n",
      "Epoch 132/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1713958.1152 - val_loss: 1806792.4825\n",
      "Epoch 133/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1729860.1486 - val_loss: 1900412.4982\n",
      "Epoch 134/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1731560.8090 - val_loss: 1796213.6044\n",
      "Epoch 135/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1730388.0207 - val_loss: 1930233.5818\n",
      "Epoch 136/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1730253.8821 - val_loss: 1821587.6417\n",
      "Epoch 137/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1720987.6718 - val_loss: 1814892.4871\n",
      "Epoch 138/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1736251.4970 - val_loss: 1725367.3625\n",
      "Epoch 139/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1729627.4633 - val_loss: 1752002.6377\n",
      "Epoch 140/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1706668.1741 - val_loss: 1840646.6056\n",
      "Epoch 141/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1704298.4029 - val_loss: 1838894.5802\n",
      "Epoch 142/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1722886.1786 - val_loss: 1788352.5426\n",
      "Epoch 143/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1716971.3641 - val_loss: 1968155.3702\n",
      "Epoch 144/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1723485.7943 - val_loss: 1820587.5434\n",
      "Epoch 145/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1715608.9942 - val_loss: 1853718.9464\n",
      "Epoch 146/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1711978.9628 - val_loss: 1749751.7867\n",
      "Epoch 147/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1703455.6138 - val_loss: 1719512.3379\n",
      "Epoch 148/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1700460.7392 - val_loss: 1772404.6640\n",
      "Epoch 149/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1719549.7475 - val_loss: 1771208.2753\n",
      "Epoch 150/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1702568.2463 - val_loss: 1707134.5708\n",
      "Epoch 151/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1683612.3628 - val_loss: 1780638.7087\n",
      "Epoch 152/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1736717.6066 - val_loss: 1622767.9577\n",
      "Epoch 153/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1733437.5950 - val_loss: 1820872.5375\n",
      "Epoch 154/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1683369.2121 - val_loss: 1738651.6812\n",
      "Epoch 155/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1682092.8243 - val_loss: 1785509.1343\n",
      "Epoch 156/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1679718.7949 - val_loss: 1839451.5948\n",
      "Epoch 157/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1683103.4830 - val_loss: 1712449.5517\n",
      "Epoch 158/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1680412.7086 - val_loss: 1812364.8890\n",
      "Epoch 159/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1690508.4428 - val_loss: 1660017.4615\n",
      "Epoch 160/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1675203.1973 - val_loss: 1846896.2726\n",
      "Epoch 161/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1688404.8114 - val_loss: 1652834.8175\n",
      "Epoch 162/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1681208.5445 - val_loss: 1758448.8458\n",
      "Epoch 163/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1687467.9708 - val_loss: 1812872.0741\n",
      "Epoch 164/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1696909.6244 - val_loss: 1709639.0066\n",
      "Epoch 165/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1673054.4970 - val_loss: 1782015.6376\n",
      "Epoch 166/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1658677.0626 - val_loss: 1742387.6108\n",
      "Epoch 167/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1662061.2288 - val_loss: 1826322.1724\n",
      "Epoch 168/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1669613.0785 - val_loss: 1653005.3500\n",
      "Epoch 169/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1664537.2377 - val_loss: 1725654.6248\n",
      "Epoch 170/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1647167.2305 - val_loss: 1808475.6473\n",
      "Epoch 171/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1657834.0214 - val_loss: 1728667.8460\n",
      "Epoch 172/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1652931.6828 - val_loss: 1851027.9057\n",
      "Epoch 173/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1651109.2229 - val_loss: 1678891.7573\n",
      "Epoch 174/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1651356.5495 - val_loss: 1856494.9403\n",
      "Epoch 175/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1654645.8483 - val_loss: 1748071.2251\n",
      "Epoch 176/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1649080.1075 - val_loss: 1682079.5609\n",
      "Epoch 177/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1633194.1351 - val_loss: 1728848.0951\n",
      "Epoch 178/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1657364.7149 - val_loss: 1675960.4042\n",
      "Epoch 179/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1642244.6802 - val_loss: 1720167.9653\n",
      "Epoch 180/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1642786.4508 - val_loss: 1753397.4336\n",
      "Epoch 181/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1640860.2815 - val_loss: 1825636.1583\n",
      "Epoch 182/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1645551.0904 - val_loss: 1882831.2710\n",
      "Epoch 183/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1651178.1976 - val_loss: 1764890.3603\n",
      "Epoch 184/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1640490.0127 - val_loss: 1893922.3171\n",
      "Epoch 185/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1651744.6546 - val_loss: 1807172.6260\n",
      "Epoch 186/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1631577.0623 - val_loss: 1720972.2544\n",
      "Epoch 187/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1618401.7187 - val_loss: 2015300.8959\n",
      "Epoch 188/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1652745.0882 - val_loss: 1694499.9309\n",
      "Epoch 189/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1624339.7869 - val_loss: 1787482.8859\n",
      "Epoch 190/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1629474.2279 - val_loss: 1777957.4585\n",
      "Epoch 191/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1628057.0723 - val_loss: 1971047.1984\n",
      "Epoch 192/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1648797.9191 - val_loss: 1756990.1965\n",
      "Epoch 193/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1614823.3375 - val_loss: 1803854.4984\n",
      "Epoch 194/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1624313.6640 - val_loss: 1734050.5669\n",
      "Epoch 195/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1628114.8145 - val_loss: 1589567.8219\n",
      "Epoch 196/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1627458.8976 - val_loss: 1924836.1843\n",
      "Epoch 197/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1620706.5733 - val_loss: 1819892.9668\n",
      "Epoch 198/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1627511.9905 - val_loss: 1724686.4295\n",
      "Epoch 199/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1614317.6478 - val_loss: 1766347.9317\n",
      "Epoch 200/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1625489.7943 - val_loss: 1736151.7699\n",
      "Epoch 201/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1611684.6178 - val_loss: 1910285.3820\n",
      "Epoch 202/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1626056.0309 - val_loss: 1693721.2235\n",
      "Epoch 203/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1609858.0690 - val_loss: 1734750.6922\n",
      "Epoch 204/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1601841.7211 - val_loss: 1736932.6920\n",
      "Epoch 205/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1586734.3461 - val_loss: 1743164.3157\n",
      "Epoch 206/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1598468.8482 - val_loss: 1859642.6159\n",
      "Epoch 207/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1594369.4934 - val_loss: 1787427.7143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1599728.7050 - val_loss: 1696492.4282\n",
      "Epoch 209/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1580383.3534 - val_loss: 1866255.4096\n",
      "Epoch 210/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1586796.9814 - val_loss: 1941362.3791\n",
      "Epoch 211/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1617853.5247 - val_loss: 1699271.0231\n",
      "Epoch 212/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1582432.6343 - val_loss: 1808650.3467\n",
      "Epoch 213/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1589074.7609 - val_loss: 2018948.3118\n",
      "Epoch 214/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1598076.3440 - val_loss: 1575449.6025\n",
      "Epoch 215/600\n",
      "14389/14389 [==============================] - 0s 8us/step - loss: 1614706.0739 - val_loss: 1596029.5326\n",
      "Epoch 216/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1660073.0862 - val_loss: 1672151.9923\n",
      "Epoch 217/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1602229.1356 - val_loss: 1588107.6395\n",
      "Epoch 218/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1576142.6958 - val_loss: 1740054.5894\n",
      "Epoch 219/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1573350.4789 - val_loss: 1724650.8836\n",
      "Epoch 220/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1572401.6469 - val_loss: 1776880.5589\n",
      "Epoch 221/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1573785.1980 - val_loss: 1546032.1658\n",
      "Epoch 222/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1585981.0607 - val_loss: 1717385.8740\n",
      "Epoch 223/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1581315.7237 - val_loss: 1697433.9249\n",
      "Epoch 224/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1552262.2197 - val_loss: 1596815.3551\n",
      "Epoch 225/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1580223.0700 - val_loss: 1759299.4619\n",
      "Epoch 226/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1585481.8009 - val_loss: 1583425.5864\n",
      "Epoch 227/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1603430.3141 - val_loss: 1758015.7194\n",
      "Epoch 228/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1564017.9217 - val_loss: 2066732.5035\n",
      "Epoch 229/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1566926.0374 - val_loss: 1930753.6409\n",
      "Epoch 230/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1555404.6711 - val_loss: 1895099.0564\n",
      "Epoch 231/600\n",
      "14389/14389 [==============================] - 0s 8us/step - loss: 1561207.8222 - val_loss: 1627428.6178\n",
      "Epoch 232/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1549193.1794 - val_loss: 1690023.7547\n",
      "Epoch 233/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1533507.2640 - val_loss: 1863674.6148\n",
      "Epoch 234/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1539454.5278 - val_loss: 1755214.3816\n",
      "Epoch 235/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1538891.1250 - val_loss: 1707669.6631\n",
      "Epoch 236/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1552199.3111 - val_loss: 1799425.5126\n",
      "Epoch 237/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1537578.9913 - val_loss: 2072675.6682\n",
      "Epoch 238/600\n",
      "14389/14389 [==============================] - 0s 8us/step - loss: 1623484.7287 - val_loss: 1860296.1939\n",
      "Epoch 239/600\n",
      "14389/14389 [==============================] - 0s 8us/step - loss: 1541464.9826 - val_loss: 1985125.1319\n",
      "Epoch 240/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1578393.8357 - val_loss: 1873610.9122\n",
      "Epoch 241/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1535427.3959 - val_loss: 1785099.4959\n",
      "Epoch 242/600\n",
      "14389/14389 [==============================] - 0s 9us/step - loss: 1541982.8832 - val_loss: 1587060.8320\n",
      "Epoch 243/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1562953.1023 - val_loss: 1689505.7727\n",
      "Epoch 244/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1562806.8474 - val_loss: 1962386.9190\n",
      "Epoch 245/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1541281.3423 - val_loss: 1560722.9206\n",
      "Epoch 246/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1501266.6575 - val_loss: 1711402.8250\n",
      "Epoch 247/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1517915.8322 - val_loss: 1737635.8041\n",
      "Epoch 248/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1502325.1970 - val_loss: 1868961.6887\n",
      "Epoch 249/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1517026.3641 - val_loss: 1705193.9424\n",
      "Epoch 250/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1525474.3974 - val_loss: 1644131.7774\n",
      "Epoch 251/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1506958.9978 - val_loss: 1643627.7197\n",
      "Epoch 252/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1518534.4059 - val_loss: 1763409.9924\n",
      "Epoch 253/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1505767.8136 - val_loss: 1652343.3457\n",
      "Epoch 254/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1496519.9136 - val_loss: 1573930.8027\n",
      "Epoch 255/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1513116.8704 - val_loss: 2022232.6545\n",
      "Epoch 256/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1564086.3244 - val_loss: 1478720.9223\n",
      "Epoch 257/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1566997.1017 - val_loss: 1620728.7839\n",
      "Epoch 258/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1517202.6377 - val_loss: 1650598.9258\n",
      "Epoch 259/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1500622.6391 - val_loss: 1637524.7474\n",
      "Epoch 260/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1524386.1595 - val_loss: 1587934.7972\n",
      "Epoch 261/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1493900.7110 - val_loss: 1565305.3164\n",
      "Epoch 262/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1522732.3231 - val_loss: 1842610.3219\n",
      "Epoch 263/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1511128.1507 - val_loss: 1666336.4506\n",
      "Epoch 264/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1483336.9335 - val_loss: 1545273.1062\n",
      "Epoch 265/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1513550.1552 - val_loss: 1983747.7591\n",
      "Epoch 266/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1486066.6804 - val_loss: 1717675.6856\n",
      "Epoch 267/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1489930.4458 - val_loss: 1715747.6177\n",
      "Epoch 268/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1502655.7160 - val_loss: 1797602.4500\n",
      "Epoch 269/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1465875.6373 - val_loss: 1815295.6358\n",
      "Epoch 270/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1473492.8226 - val_loss: 1771399.5301\n",
      "Epoch 271/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1493978.2673 - val_loss: 1653245.2266\n",
      "Epoch 272/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1472844.7898 - val_loss: 1642571.2628\n",
      "Epoch 273/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1508463.9648 - val_loss: 1976794.1178\n",
      "Epoch 274/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1479008.5839 - val_loss: 1768963.7576\n",
      "Epoch 275/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1481886.9374 - val_loss: 1801211.8250\n",
      "Epoch 276/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1470355.2436 - val_loss: 2028610.1534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1509718.5713 - val_loss: 1643903.1211\n",
      "Epoch 278/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1476142.0859 - val_loss: 1720492.4002\n",
      "Epoch 279/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1472072.9864 - val_loss: 1817747.6715\n",
      "Epoch 280/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1475059.4727 - val_loss: 2054445.7647\n",
      "Epoch 281/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1489536.3401 - val_loss: 1728862.9808\n",
      "Epoch 282/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1455464.0150 - val_loss: 1661622.8164\n",
      "Epoch 283/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1452576.5058 - val_loss: 1838697.5188\n",
      "Epoch 284/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1483563.4709 - val_loss: 1893678.4154\n",
      "Epoch 285/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1472546.7730 - val_loss: 2064758.6432\n",
      "Epoch 286/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1478242.3028 - val_loss: 1859117.0479\n",
      "Epoch 287/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1462928.7229 - val_loss: 1504166.0551\n",
      "Epoch 288/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1510987.4013 - val_loss: 1834692.5906\n",
      "Epoch 289/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1462593.8149 - val_loss: 1719617.8713\n",
      "Epoch 290/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1486434.7409 - val_loss: 2263169.1771\n",
      "Epoch 291/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1511278.7815 - val_loss: 1669314.5705\n",
      "Epoch 292/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1516624.8207 - val_loss: 2050817.0386\n",
      "Epoch 293/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1526361.5830 - val_loss: 1768508.8983\n",
      "Epoch 294/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1458234.3023 - val_loss: 1463012.0381\n",
      "Epoch 295/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1487516.2594 - val_loss: 1650564.8375\n",
      "Epoch 296/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1478280.2670 - val_loss: 1622746.2063\n",
      "Epoch 297/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1486156.5495 - val_loss: 1898345.9108\n",
      "Epoch 298/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1497542.3800 - val_loss: 1697866.0371\n",
      "Epoch 299/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1469589.1919 - val_loss: 1545155.2315\n",
      "Epoch 300/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1457952.9775 - val_loss: 1583216.1148\n",
      "Epoch 301/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1490307.6143 - val_loss: 1608128.8573\n",
      "Epoch 302/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1483866.1466 - val_loss: 1821678.7584\n",
      "Epoch 303/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1488020.5937 - val_loss: 1731352.1145\n",
      "Epoch 304/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1462162.5411 - val_loss: 1922694.8119\n",
      "Epoch 305/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1443092.7855 - val_loss: 1747389.8199\n",
      "Epoch 306/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1435705.1569 - val_loss: 1594246.3750\n",
      "Epoch 307/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1460997.1682 - val_loss: 1658702.5116\n",
      "Epoch 308/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1463936.9429 - val_loss: 1602419.0933\n",
      "Epoch 309/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1504115.9052 - val_loss: 1768951.8666\n",
      "Epoch 310/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1459201.7351 - val_loss: 1631028.6521\n",
      "Epoch 311/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1466107.0160 - val_loss: 1737857.8390\n",
      "Epoch 312/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1445660.8919 - val_loss: 1842931.8334\n",
      "Epoch 313/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1503162.9967 - val_loss: 1903346.2695\n",
      "Epoch 314/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1475858.6043 - val_loss: 1512693.0453\n",
      "Epoch 315/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1463251.8751 - val_loss: 1883973.1284\n",
      "Epoch 316/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1466624.2114 - val_loss: 1882844.2749\n",
      "Epoch 317/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1480813.7888 - val_loss: 2205010.1423\n",
      "Epoch 318/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1476671.9772 - val_loss: 1874322.8505\n",
      "Epoch 319/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1434360.1483 - val_loss: 1747515.2331\n",
      "Epoch 320/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1431602.7384 - val_loss: 1803030.4805\n",
      "Epoch 321/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1441842.3642 - val_loss: 1444967.7106\n",
      "Epoch 322/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1499478.7184 - val_loss: 1471092.7243\n",
      "Epoch 323/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1472462.0653 - val_loss: 1743884.1287\n",
      "Epoch 324/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1440452.8663 - val_loss: 1787285.1437\n",
      "Epoch 325/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1458983.4855 - val_loss: 1913929.1318\n",
      "Epoch 326/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1459105.4609 - val_loss: 1537214.3985\n",
      "Epoch 327/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1452607.5014 - val_loss: 1919191.7759\n",
      "Epoch 328/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1445539.5766 - val_loss: 1948822.0238\n",
      "Epoch 329/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1454762.1203 - val_loss: 1826092.4728\n",
      "Epoch 330/600\n",
      "14389/14389 [==============================] - 0s 8us/step - loss: 1431088.4382 - val_loss: 1792888.4143\n",
      "Epoch 331/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1443943.5830 - val_loss: 1853690.8750\n",
      "Epoch 332/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1438454.8435 - val_loss: 1810080.0209\n",
      "Epoch 333/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1437427.0577 - val_loss: 1580684.4658\n",
      "Epoch 334/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1477792.4935 - val_loss: 2052490.3550\n",
      "Epoch 335/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1444918.3458 - val_loss: 1706160.1640\n",
      "Epoch 336/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1451456.0067 - val_loss: 1822335.5058\n",
      "Epoch 337/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1454529.8732 - val_loss: 1903600.7767\n",
      "Epoch 338/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1459910.6175 - val_loss: 1597622.2213\n",
      "Epoch 339/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1440512.6506 - val_loss: 1593416.9573\n",
      "Epoch 340/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1422810.3016 - val_loss: 1809356.8798\n",
      "Epoch 341/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1432455.5645 - val_loss: 2179166.4831\n",
      "Epoch 342/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1491246.6011 - val_loss: 1799193.7376\n",
      "Epoch 343/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1427221.1063 - val_loss: 1622548.3503\n",
      "Epoch 344/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1427716.5731 - val_loss: 1806458.7876\n",
      "Epoch 345/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1460039.9150 - val_loss: 1833871.6104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1463901.8134 - val_loss: 1959976.8673\n",
      "Epoch 347/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1454471.2606 - val_loss: 1780590.1061\n",
      "Epoch 348/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1465854.0236 - val_loss: 1937137.4432\n",
      "Epoch 349/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1437183.6887 - val_loss: 1924703.6007\n",
      "Epoch 350/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1438960.1514 - val_loss: 1931528.9846\n",
      "Epoch 351/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1457313.7447 - val_loss: 2055308.6844\n",
      "Epoch 352/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1432241.8853 - val_loss: 1719744.1504\n",
      "Epoch 353/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1416610.0107 - val_loss: 1720975.6094\n",
      "Epoch 354/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1452647.4114 - val_loss: 1498255.6599\n",
      "Epoch 355/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1455228.1838 - val_loss: 2031188.4780\n",
      "Epoch 356/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1433430.8361 - val_loss: 1694493.3761\n",
      "Epoch 357/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1426924.6207 - val_loss: 1886386.8050\n",
      "Epoch 358/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1422208.7548 - val_loss: 1892290.5694\n",
      "Epoch 359/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1435998.0375 - val_loss: 1873079.4128\n",
      "Epoch 360/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1416215.7800 - val_loss: 1657148.8332\n",
      "Epoch 361/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1436247.0939 - val_loss: 1949952.9186\n",
      "Epoch 362/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1446637.7084 - val_loss: 1950152.3448\n",
      "Epoch 363/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1452312.2720 - val_loss: 1762806.9856\n",
      "Epoch 364/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1420734.6611 - val_loss: 1764360.2468\n",
      "Epoch 365/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1423928.1445 - val_loss: 1850148.3428\n",
      "Epoch 366/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1418936.8243 - val_loss: 1756828.3145\n",
      "Epoch 367/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1428416.8689 - val_loss: 1509922.2710\n",
      "Epoch 368/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1429607.5323 - val_loss: 1655442.0418\n",
      "Epoch 369/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1427244.2270 - val_loss: 1653147.7253\n",
      "Epoch 370/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1420967.8342 - val_loss: 1928795.5360\n",
      "Epoch 371/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1424108.3336 - val_loss: 1804532.3733\n",
      "Epoch 372/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1419490.3464 - val_loss: 1630836.4608\n",
      "Epoch 373/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1414086.7320 - val_loss: 1856758.9763\n",
      "Epoch 374/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1415535.3167 - val_loss: 1589608.8860\n",
      "Epoch 375/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1425025.8477 - val_loss: 1739498.6223\n",
      "Epoch 376/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1420427.8869 - val_loss: 1855851.7774\n",
      "Epoch 377/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1409392.2980 - val_loss: 1750278.0362\n",
      "Epoch 378/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1454266.3122 - val_loss: 1712643.8644\n",
      "Epoch 379/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1436254.1196 - val_loss: 1876837.2528\n",
      "Epoch 380/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1434051.3761 - val_loss: 1655036.1589\n",
      "Epoch 381/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1437963.4222 - val_loss: 1899369.6062\n",
      "Epoch 382/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1436462.1587 - val_loss: 1622851.1826\n",
      "Epoch 383/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1416256.7841 - val_loss: 1903677.1654\n",
      "Epoch 384/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1433938.5632 - val_loss: 1743033.9748\n",
      "Epoch 385/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1419813.8933 - val_loss: 1567552.6298\n",
      "Epoch 386/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1421069.6014 - val_loss: 1944583.2641\n",
      "Epoch 387/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1418230.2316 - val_loss: 1837930.1689\n",
      "Epoch 388/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1413697.6515 - val_loss: 1931048.1443\n",
      "Epoch 389/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1437941.3691 - val_loss: 1510322.1160\n",
      "Epoch 390/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1428660.6231 - val_loss: 1894544.2990\n",
      "Epoch 391/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1431455.1931 - val_loss: 1912733.6865\n",
      "Epoch 392/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1418401.4604 - val_loss: 1896149.3268\n",
      "Epoch 393/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1414753.2114 - val_loss: 1778159.9042\n",
      "Epoch 394/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1411480.0786 - val_loss: 1482460.4142\n",
      "Epoch 395/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1432883.5564 - val_loss: 1681413.9741\n",
      "Epoch 396/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1412691.3180 - val_loss: 1722572.7070\n",
      "Epoch 397/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1421072.5995 - val_loss: 1692757.2264\n",
      "Epoch 398/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1410175.0603 - val_loss: 1745082.9208\n",
      "Epoch 399/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1406784.8802 - val_loss: 1826841.1957\n",
      "Epoch 400/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1399020.0992 - val_loss: 1666878.9937\n",
      "Epoch 401/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1473069.1478 - val_loss: 1815774.8495\n",
      "Epoch 402/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1420439.1341 - val_loss: 1711646.1155\n",
      "Epoch 403/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1405985.2441 - val_loss: 1895693.2995\n",
      "Epoch 404/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1424655.2746 - val_loss: 1835358.9644\n",
      "Epoch 405/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1414435.7295 - val_loss: 2054780.2975\n",
      "Epoch 406/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1442469.3178 - val_loss: 1736174.5290\n",
      "Epoch 407/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1416997.8591 - val_loss: 1542180.6150\n",
      "Epoch 408/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1447693.7207 - val_loss: 1910924.7052\n",
      "Epoch 409/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1414590.2696 - val_loss: 1867585.5894\n",
      "Epoch 410/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1403727.0336 - val_loss: 2012480.0406\n",
      "Epoch 411/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1430950.0696 - val_loss: 1886169.4665\n",
      "Epoch 412/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1423332.9072 - val_loss: 1533927.0646\n",
      "Epoch 413/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1420557.0758 - val_loss: 1611552.8312\n",
      "Epoch 414/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1422631.4646 - val_loss: 1929192.7732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1427287.9954 - val_loss: 1642405.6234\n",
      "Epoch 416/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1404497.0465 - val_loss: 1567875.1918\n",
      "Epoch 417/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1418493.3180 - val_loss: 1780913.2997\n",
      "Epoch 418/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1429297.4350 - val_loss: 1541404.9384\n",
      "Epoch 419/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1464398.1633 - val_loss: 1550553.3848\n",
      "Epoch 420/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1441562.9706 - val_loss: 1722886.3561\n",
      "Epoch 421/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1414471.2689 - val_loss: 1590174.7881\n",
      "Epoch 422/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1407181.4404 - val_loss: 1992314.4962\n",
      "Epoch 423/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1444192.0219 - val_loss: 1815832.8118\n",
      "Epoch 424/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1399601.7237 - val_loss: 1830150.4135\n",
      "Epoch 425/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1415620.6565 - val_loss: 1637927.2507\n",
      "Epoch 426/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1411702.2724 - val_loss: 1628065.9761\n",
      "Epoch 427/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1405995.5047 - val_loss: 1923308.8711\n",
      "Epoch 428/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1401291.3622 - val_loss: 1899971.9937\n",
      "Epoch 429/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1423139.1834 - val_loss: 1703601.0895\n",
      "Epoch 430/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1414877.2873 - val_loss: 1860404.1238\n",
      "Epoch 431/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1411309.6199 - val_loss: 1654558.4242\n",
      "Epoch 432/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1402006.3546 - val_loss: 1777383.5711\n",
      "Epoch 433/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1409698.0758 - val_loss: 1762702.8406\n",
      "Epoch 434/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1398075.5489 - val_loss: 1540864.1328\n",
      "Epoch 435/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1423788.4204 - val_loss: 1839189.4532\n",
      "Epoch 436/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1418530.1332 - val_loss: 1652181.8057\n",
      "Epoch 437/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1420697.6847 - val_loss: 1831964.2688\n",
      "Epoch 438/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1415520.0228 - val_loss: 1858328.2421\n",
      "Epoch 439/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1420054.4434 - val_loss: 1868618.7086\n",
      "Epoch 440/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1406454.3023 - val_loss: 1740695.7246\n",
      "Epoch 441/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1421750.1325 - val_loss: 1530486.7718\n",
      "Epoch 442/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1427874.1927 - val_loss: 1717339.6284\n",
      "Epoch 443/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1412429.2250 - val_loss: 1723826.3303\n",
      "Epoch 444/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1390724.5334 - val_loss: 1686581.4193\n",
      "Epoch 445/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1404091.1330 - val_loss: 1889335.8872\n",
      "Epoch 446/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1400630.9242 - val_loss: 1848763.7859\n",
      "Epoch 447/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1404531.4760 - val_loss: 1726008.7145\n",
      "Epoch 448/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1413019.4172 - val_loss: 1596621.7477\n",
      "Epoch 449/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1417870.3287 - val_loss: 1610914.6209\n",
      "Epoch 450/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1419420.4313 - val_loss: 2015013.3146\n",
      "Epoch 451/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1433745.3645 - val_loss: 1586320.1523\n",
      "Epoch 452/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1416144.5714 - val_loss: 1667788.9878\n",
      "Epoch 453/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1391027.6210 - val_loss: 1606485.1413\n",
      "Epoch 454/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1392213.1738 - val_loss: 1618064.6025\n",
      "Epoch 455/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1391041.7422 - val_loss: 1753955.4710\n",
      "Epoch 456/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1398688.5999 - val_loss: 1803758.8132\n",
      "Epoch 457/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1401241.4460 - val_loss: 1683403.7583\n",
      "Epoch 458/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1395999.5209 - val_loss: 1624640.1406\n",
      "Epoch 459/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1426424.5352 - val_loss: 1876622.4084\n",
      "Epoch 460/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1396728.4490 - val_loss: 1668712.8447\n",
      "Epoch 461/600\n",
      "14389/14389 [==============================] - 0s 8us/step - loss: 1392332.5695 - val_loss: 1681517.2206\n",
      "Epoch 462/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1422035.3765 - val_loss: 1783379.7645\n",
      "Epoch 463/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1404618.3496 - val_loss: 2012728.3530\n",
      "Epoch 464/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1406782.6339 - val_loss: 1865893.6221\n",
      "Epoch 465/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1413286.2275 - val_loss: 1741398.3056\n",
      "Epoch 466/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1425181.1824 - val_loss: 1844127.2519\n",
      "Epoch 467/600\n",
      "14389/14389 [==============================] - 0s 8us/step - loss: 1402849.6556 - val_loss: 1984824.0675\n",
      "Epoch 468/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1398861.2488 - val_loss: 1848166.0490\n",
      "Epoch 469/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1404028.2284 - val_loss: 1965417.4456\n",
      "Epoch 470/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1398646.8268 - val_loss: 1733177.0437\n",
      "Epoch 471/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1402515.6539 - val_loss: 1780859.7042\n",
      "Epoch 472/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1391063.6946 - val_loss: 1480632.6180\n",
      "Epoch 473/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1457159.1955 - val_loss: 1680763.0454\n",
      "Epoch 474/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1403184.7473 - val_loss: 1790542.5405\n",
      "Epoch 475/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1391518.1901 - val_loss: 1660499.3687\n",
      "Epoch 476/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1419072.4322 - val_loss: 1684393.1241\n",
      "Epoch 477/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1380457.6796 - val_loss: 1801452.9984\n",
      "Epoch 478/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1393831.3755 - val_loss: 1772564.4951\n",
      "Epoch 479/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1404532.2583 - val_loss: 1962764.7702\n",
      "Epoch 480/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1391296.1712 - val_loss: 1784712.2036\n",
      "Epoch 481/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1396988.7130 - val_loss: 1886725.8814\n",
      "Epoch 482/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1405778.1218 - val_loss: 2024158.1525\n",
      "Epoch 483/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1426334.8605 - val_loss: 1553357.2767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 484/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1389366.8069 - val_loss: 1604453.9317\n",
      "Epoch 485/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1390440.8444 - val_loss: 1798665.2476\n",
      "Epoch 486/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1396000.7739 - val_loss: 2085156.2760\n",
      "Epoch 487/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1419075.0823 - val_loss: 1674028.5027\n",
      "Epoch 488/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1404843.3959 - val_loss: 1858080.5692\n",
      "Epoch 489/600\n",
      "14389/14389 [==============================] - 0s 8us/step - loss: 1396988.1204 - val_loss: 1676117.1515\n",
      "Epoch 490/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1386716.0624 - val_loss: 1661989.6542\n",
      "Epoch 491/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1392800.9250 - val_loss: 1711663.7530\n",
      "Epoch 492/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1389166.9929 - val_loss: 1824641.9964\n",
      "Epoch 493/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1393828.5713 - val_loss: 1686819.9207\n",
      "Epoch 494/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1408529.0332 - val_loss: 1730507.1660\n",
      "Epoch 495/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1388964.4754 - val_loss: 1620553.6869\n",
      "Epoch 496/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1400386.4964 - val_loss: 1754043.4365\n",
      "Epoch 497/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1396637.0307 - val_loss: 1836907.3213\n",
      "Epoch 498/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1399678.8381 - val_loss: 1839302.3378\n",
      "Epoch 499/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1410862.5912 - val_loss: 1590186.8596\n",
      "Epoch 500/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1414316.8947 - val_loss: 1994219.0124\n",
      "Epoch 501/600\n",
      "14389/14389 [==============================] - 0s 8us/step - loss: 1411173.2876 - val_loss: 1595393.5567\n",
      "Epoch 502/600\n",
      "14389/14389 [==============================] - 0s 8us/step - loss: 1392713.4225 - val_loss: 1563603.5410\n",
      "Epoch 503/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1458795.1482 - val_loss: 2038792.4141\n",
      "Epoch 504/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1411158.4503 - val_loss: 1654480.5476\n",
      "Epoch 505/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1391560.7609 - val_loss: 1762420.5910\n",
      "Epoch 506/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1387628.5941 - val_loss: 1628298.4978\n",
      "Epoch 507/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1427350.5795 - val_loss: 2105024.5868\n",
      "Epoch 508/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1428410.4111 - val_loss: 1727267.7778\n",
      "Epoch 509/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1391363.3304 - val_loss: 1821893.2344\n",
      "Epoch 510/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1397758.0514 - val_loss: 1782576.3913\n",
      "Epoch 511/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1384838.5779 - val_loss: 1810760.0719\n",
      "Epoch 512/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1388423.3536 - val_loss: 1694632.0067\n",
      "Epoch 513/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1412680.8115 - val_loss: 1904448.9676\n",
      "Epoch 514/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1413367.1167 - val_loss: 1844449.3983\n",
      "Epoch 515/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1383292.4174 - val_loss: 1616071.9836\n",
      "Epoch 516/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1382933.7067 - val_loss: 1994554.1933\n",
      "Epoch 517/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1391640.7761 - val_loss: 1698944.4799\n",
      "Epoch 518/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1391345.2241 - val_loss: 2038716.0383\n",
      "Epoch 519/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1393213.7394 - val_loss: 2017858.6114\n",
      "Epoch 520/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1414130.1464 - val_loss: 1593691.7578\n",
      "Epoch 521/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1394233.1460 - val_loss: 1661445.8336\n",
      "Epoch 522/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1384154.8938 - val_loss: 1900128.8576\n",
      "Epoch 523/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1396465.0264 - val_loss: 1688814.3104\n",
      "Epoch 524/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1385543.8371 - val_loss: 1624328.0472\n",
      "Epoch 525/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1394166.9263 - val_loss: 1769778.9081\n",
      "Epoch 526/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1385116.8646 - val_loss: 1934171.7573\n",
      "Epoch 527/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1394177.5273 - val_loss: 1858029.5593\n",
      "Epoch 528/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1391595.1320 - val_loss: 1640065.3497\n",
      "Epoch 529/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1385266.7042 - val_loss: 1762097.2168\n",
      "Epoch 530/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1391742.7745 - val_loss: 1640520.1842\n",
      "Epoch 531/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1381787.1783 - val_loss: 1911448.3770\n",
      "Epoch 532/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1398458.8439 - val_loss: 1537915.1904\n",
      "Epoch 533/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1399670.8412 - val_loss: 1959940.5023\n",
      "Epoch 534/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1400115.7858 - val_loss: 1655868.8290\n",
      "Epoch 535/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1419604.3585 - val_loss: 1897108.7853\n",
      "Epoch 536/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1388309.4448 - val_loss: 1665747.8595\n",
      "Epoch 537/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1400897.4017 - val_loss: 1751881.5668\n",
      "Epoch 538/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1388547.1874 - val_loss: 1527757.3856\n",
      "Epoch 539/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1393314.8089 - val_loss: 1562723.5056\n",
      "Epoch 540/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1397209.7919 - val_loss: 1771706.2004\n",
      "Epoch 541/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1370945.7742 - val_loss: 2057991.1912\n",
      "Epoch 542/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1428624.7719 - val_loss: 1932595.1511\n",
      "Epoch 543/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1399976.8328 - val_loss: 1689918.8007\n",
      "Epoch 544/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1380808.3856 - val_loss: 1784785.7118\n",
      "Epoch 545/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1392206.8351 - val_loss: 1747997.7620\n",
      "Epoch 546/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1382433.3131 - val_loss: 1812435.7432\n",
      "Epoch 547/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1400211.8706 - val_loss: 1686212.0110\n",
      "Epoch 548/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1375406.2585 - val_loss: 1678391.0165\n",
      "Epoch 549/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1385702.8770 - val_loss: 1551382.1939\n",
      "Epoch 550/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1387231.2656 - val_loss: 1740643.3326\n",
      "Epoch 551/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1376459.5653 - val_loss: 1585571.9761\n",
      "Epoch 552/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1393031.4919 - val_loss: 1858407.2998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 553/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1373374.4879 - val_loss: 1651370.3905\n",
      "Epoch 554/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1392242.9262 - val_loss: 1793076.9898\n",
      "Epoch 555/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1410887.5801 - val_loss: 1604538.7000\n",
      "Epoch 556/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1382959.3590 - val_loss: 1462780.8691\n",
      "Epoch 557/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1394226.4119 - val_loss: 1758978.1453\n",
      "Epoch 558/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1378901.5007 - val_loss: 1558197.9817\n",
      "Epoch 559/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1406679.8008 - val_loss: 1653044.1918\n",
      "Epoch 560/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1381536.5553 - val_loss: 1886074.2765\n",
      "Epoch 561/600\n",
      "14389/14389 [==============================] - 0s 6us/step - loss: 1398857.7647 - val_loss: 1670344.3265\n",
      "Epoch 562/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1380858.8466 - val_loss: 1729846.3028\n",
      "Epoch 563/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1372927.9455 - val_loss: 1600208.8153\n",
      "Epoch 564/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1402452.4055 - val_loss: 1681664.6132\n",
      "Epoch 565/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1398963.2872 - val_loss: 1568033.3631\n",
      "Epoch 566/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1426336.6262 - val_loss: 1850822.1197\n",
      "Epoch 567/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1408905.2594 - val_loss: 1760095.6845\n",
      "Epoch 568/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1408949.7128 - val_loss: 1626988.5002\n",
      "Epoch 569/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1383000.3024 - val_loss: 1938582.1342\n",
      "Epoch 570/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1397730.3173 - val_loss: 1592163.3399\n",
      "Epoch 571/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1383964.0348 - val_loss: 2123178.3058\n",
      "Epoch 572/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1403164.0448 - val_loss: 1781507.6152\n",
      "Epoch 573/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1399946.3227 - val_loss: 1768643.7231\n",
      "Epoch 574/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1379581.9362 - val_loss: 1757799.0013\n",
      "Epoch 575/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1385453.4955 - val_loss: 1646654.2092\n",
      "Epoch 576/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1385165.0214 - val_loss: 1923489.6194\n",
      "Epoch 577/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1405858.5288 - val_loss: 1434229.1579\n",
      "Epoch 578/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1393961.9635 - val_loss: 1863977.2369\n",
      "Epoch 579/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1385829.1650 - val_loss: 1823174.8401\n",
      "Epoch 580/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1359914.9596 - val_loss: 1715752.0069\n",
      "Epoch 581/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1372367.8076 - val_loss: 2035249.9221\n",
      "Epoch 582/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1411954.6075 - val_loss: 1658399.2405\n",
      "Epoch 583/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1380916.1934 - val_loss: 1803101.8109\n",
      "Epoch 584/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1398946.1835 - val_loss: 1630261.4018\n",
      "Epoch 585/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1377064.0000 - val_loss: 1632116.1930\n",
      "Epoch 586/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1377384.8312 - val_loss: 1767359.6896\n",
      "Epoch 587/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1377421.8852 - val_loss: 1902776.2856\n",
      "Epoch 588/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1399199.7277 - val_loss: 1546144.1179\n",
      "Epoch 589/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1383298.7557 - val_loss: 1761949.9469\n",
      "Epoch 590/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1379048.2718 - val_loss: 1745848.6739\n",
      "Epoch 591/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1360564.5219 - val_loss: 1709153.3820\n",
      "Epoch 592/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1394611.4287 - val_loss: 1768481.7462\n",
      "Epoch 593/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1407645.9701 - val_loss: 1752091.7287\n",
      "Epoch 594/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1366547.9263 - val_loss: 1828622.7286\n",
      "Epoch 595/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1404030.4991 - val_loss: 1511115.8111\n",
      "Epoch 596/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1402865.4854 - val_loss: 1703913.0954\n",
      "Epoch 597/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1370753.8668 - val_loss: 1732920.9167\n",
      "Epoch 598/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1382753.8134 - val_loss: 1503176.0726\n",
      "Epoch 599/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1386050.3887 - val_loss: 1750439.9691\n",
      "Epoch 600/600\n",
      "14389/14389 [==============================] - 0s 7us/step - loss: 1364243.7158 - val_loss: 1662290.9021\n",
      "Train on 14390 samples, validate on 1599 samples\n",
      "Epoch 1/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 7109795.2329 - val_loss: 7250123.6413\n",
      "Epoch 2/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 7026907.1830 - val_loss: 6675767.0228\n",
      "Epoch 3/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 3939942.6972 - val_loss: 2931783.2602\n",
      "Epoch 4/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2652370.6298 - val_loss: 2703861.5700\n",
      "Epoch 5/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2615935.0274 - val_loss: 2705552.4303\n",
      "Epoch 6/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2613774.4474 - val_loss: 2699448.0461\n",
      "Epoch 7/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2610678.8641 - val_loss: 2701868.0560\n",
      "Epoch 8/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2605974.7223 - val_loss: 2696008.7381\n",
      "Epoch 9/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2606972.9564 - val_loss: 2695977.2095\n",
      "Epoch 10/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2603648.5332 - val_loss: 2695138.7556\n",
      "Epoch 11/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2601978.5396 - val_loss: 2690006.4497\n",
      "Epoch 12/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2600164.0872 - val_loss: 2686774.0711\n",
      "Epoch 13/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2593510.9206 - val_loss: 2684533.8751\n",
      "Epoch 14/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2588515.2359 - val_loss: 2682016.7822\n",
      "Epoch 15/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2590850.2676 - val_loss: 2678524.8827\n",
      "Epoch 16/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2584521.1919 - val_loss: 2686870.5188\n",
      "Epoch 17/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2585178.1294 - val_loss: 2677614.3468\n",
      "Epoch 18/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2579716.0774 - val_loss: 2669706.7303\n",
      "Epoch 19/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2573491.7719 - val_loss: 2665583.4508\n",
      "Epoch 20/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2571383.5353 - val_loss: 2661950.7675\n",
      "Epoch 21/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2565627.5747 - val_loss: 2666031.0941\n",
      "Epoch 22/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2573148.7239 - val_loss: 2678233.3316\n",
      "Epoch 23/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2559945.4342 - val_loss: 2656613.0186\n",
      "Epoch 24/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2552563.5211 - val_loss: 2651463.2226\n",
      "Epoch 25/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2554217.2196 - val_loss: 2641270.9736\n",
      "Epoch 26/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2547369.4250 - val_loss: 2631464.4481\n",
      "Epoch 27/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2536120.4200 - val_loss: 2625340.7179\n",
      "Epoch 28/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2534149.0978 - val_loss: 2619061.1357\n",
      "Epoch 29/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2522454.6959 - val_loss: 2612384.5017\n",
      "Epoch 30/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2513882.1586 - val_loss: 2594580.8301\n",
      "Epoch 31/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2507865.4311 - val_loss: 2581144.0746\n",
      "Epoch 32/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2490554.7605 - val_loss: 2566843.3987\n",
      "Epoch 33/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2478380.5286 - val_loss: 2545685.5210\n",
      "Epoch 34/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2458355.8586 - val_loss: 2524902.4459\n",
      "Epoch 35/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2438841.7923 - val_loss: 2499976.6083\n",
      "Epoch 36/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2423305.8986 - val_loss: 2468820.7075\n",
      "Epoch 37/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2396399.4265 - val_loss: 2426434.8752\n",
      "Epoch 38/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2366562.8659 - val_loss: 2437640.3513\n",
      "Epoch 39/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2359504.0770 - val_loss: 2371745.2634\n",
      "Epoch 40/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2321219.7647 - val_loss: 2323404.3013\n",
      "Epoch 41/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2291917.6343 - val_loss: 2283516.7280\n",
      "Epoch 42/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2278129.0048 - val_loss: 2249573.8182\n",
      "Epoch 43/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2252944.0502 - val_loss: 2221756.4285\n",
      "Epoch 44/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2213121.0331 - val_loss: 2211779.4161\n",
      "Epoch 45/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2197508.3867 - val_loss: 2182155.7153\n",
      "Epoch 46/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2174538.4054 - val_loss: 2115575.5032\n",
      "Epoch 47/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2165087.6469 - val_loss: 2215540.7087\n",
      "Epoch 48/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 2162351.4697 - val_loss: 2076966.4020\n",
      "Epoch 49/600\n",
      "14390/14390 [==============================] - 0s 9us/step - loss: 2111072.7293 - val_loss: 2048614.8350\n",
      "Epoch 50/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2111600.5928 - val_loss: 2171066.6678\n",
      "Epoch 51/600\n",
      "14390/14390 [==============================] - 0s 9us/step - loss: 2095071.8851 - val_loss: 2045876.8471\n",
      "Epoch 52/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2065888.0897 - val_loss: 2008002.9949\n",
      "Epoch 53/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2068037.1790 - val_loss: 1960649.0870\n",
      "Epoch 54/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2075404.7411 - val_loss: 2038912.5583\n",
      "Epoch 55/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 2028105.5112 - val_loss: 1991338.7664\n",
      "Epoch 56/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2020150.4668 - val_loss: 2087495.4851\n",
      "Epoch 57/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2026152.1444 - val_loss: 1985124.4539\n",
      "Epoch 58/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2007935.1448 - val_loss: 1932326.7745\n",
      "Epoch 59/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1991985.7096 - val_loss: 1979640.5105\n",
      "Epoch 60/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1967899.6349 - val_loss: 1902349.9163\n",
      "Epoch 61/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1973289.2129 - val_loss: 1872708.9113\n",
      "Epoch 62/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1961579.4236 - val_loss: 1928843.7779\n",
      "Epoch 63/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1938124.0385 - val_loss: 1981832.4802\n",
      "Epoch 64/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1940515.1861 - val_loss: 1867352.1347\n",
      "Epoch 65/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1953354.1235 - val_loss: 2224339.8992\n",
      "Epoch 66/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1966780.5064 - val_loss: 1869821.7583\n",
      "Epoch 67/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1923232.2702 - val_loss: 1904671.8960\n",
      "Epoch 68/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1937205.6642 - val_loss: 1887141.7040\n",
      "Epoch 69/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1905606.4817 - val_loss: 1944874.9332\n",
      "Epoch 70/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1894814.3875 - val_loss: 2084754.4167\n",
      "Epoch 71/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1901015.5232 - val_loss: 1948788.3830\n",
      "Epoch 72/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1868459.2993 - val_loss: 1979897.9711\n",
      "Epoch 73/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1873582.1353 - val_loss: 1997923.4178\n",
      "Epoch 74/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1886897.2087 - val_loss: 1862024.0746\n",
      "Epoch 75/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1890519.4039 - val_loss: 1863911.8781\n",
      "Epoch 76/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1869913.1095 - val_loss: 1835595.0751\n",
      "Epoch 77/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1871196.9136 - val_loss: 1901339.2059\n",
      "Epoch 78/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1847912.9506 - val_loss: 1979334.2361\n",
      "Epoch 79/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1873860.7226 - val_loss: 1892990.5383\n",
      "Epoch 80/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1866012.8133 - val_loss: 1823201.9710\n",
      "Epoch 81/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1854569.2144 - val_loss: 1918945.3786\n",
      "Epoch 82/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1852290.9024 - val_loss: 1849610.5256\n",
      "Epoch 83/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1847035.8354 - val_loss: 1934214.5324\n",
      "Epoch 84/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1838341.4218 - val_loss: 1959803.2745\n",
      "Epoch 85/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1826202.6795 - val_loss: 1993082.7290\n",
      "Epoch 86/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1831145.2898 - val_loss: 1865630.6744\n",
      "Epoch 87/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1832517.6149 - val_loss: 1911914.3383\n",
      "Epoch 88/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1812563.7164 - val_loss: 1811168.4216\n",
      "Epoch 89/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1838765.8059 - val_loss: 2094250.0527\n",
      "Epoch 90/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14390/14390 [==============================] - 0s 7us/step - loss: 1832274.2098 - val_loss: 1815938.8307\n",
      "Epoch 91/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1828750.3995 - val_loss: 1956171.0002\n",
      "Epoch 92/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1813103.5398 - val_loss: 1761355.4003\n",
      "Epoch 93/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1796407.2962 - val_loss: 1871801.4241\n",
      "Epoch 94/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1793857.7157 - val_loss: 1840499.7610\n",
      "Epoch 95/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1799189.7762 - val_loss: 1940785.3837\n",
      "Epoch 96/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1783305.4322 - val_loss: 1883655.8273\n",
      "Epoch 97/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1789682.5217 - val_loss: 1842600.9832\n",
      "Epoch 98/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1777229.8418 - val_loss: 1840711.3354\n",
      "Epoch 99/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1785825.6112 - val_loss: 1741994.5885\n",
      "Epoch 100/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1779956.6567 - val_loss: 1683633.3189\n",
      "Epoch 101/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1777085.8478 - val_loss: 1760419.0341\n",
      "Epoch 102/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1757903.2571 - val_loss: 1740537.1111\n",
      "Epoch 103/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1778178.0103 - val_loss: 1838136.6453\n",
      "Epoch 104/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1778571.8350 - val_loss: 1714426.3361\n",
      "Epoch 105/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1786590.6315 - val_loss: 1837267.3584\n",
      "Epoch 106/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1751330.9309 - val_loss: 1874748.3297\n",
      "Epoch 107/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1760885.1674 - val_loss: 1875678.7928\n",
      "Epoch 108/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1749703.3667 - val_loss: 2022460.4339\n",
      "Epoch 109/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1757922.6160 - val_loss: 1755526.9830\n",
      "Epoch 110/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1737234.1254 - val_loss: 1727595.1571\n",
      "Epoch 111/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1753392.2813 - val_loss: 1803742.2594\n",
      "Epoch 112/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1765429.8021 - val_loss: 1734168.5969\n",
      "Epoch 113/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1731791.8388 - val_loss: 1894578.7512\n",
      "Epoch 114/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1734856.4875 - val_loss: 1859807.5206\n",
      "Epoch 115/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1746756.1598 - val_loss: 2204337.1093\n",
      "Epoch 116/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1808622.5834 - val_loss: 2104954.3391\n",
      "Epoch 117/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1759516.9734 - val_loss: 1989855.3296\n",
      "Epoch 118/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1736022.4756 - val_loss: 1858963.5600\n",
      "Epoch 119/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1732523.2781 - val_loss: 1807382.9095\n",
      "Epoch 120/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1732414.2888 - val_loss: 1874944.4326\n",
      "Epoch 121/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1728917.3559 - val_loss: 1696608.0689\n",
      "Epoch 122/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1724996.3902 - val_loss: 1746705.9608\n",
      "Epoch 123/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1704386.6159 - val_loss: 1889872.8487\n",
      "Epoch 124/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1715827.6638 - val_loss: 1829667.7040\n",
      "Epoch 125/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1706921.0945 - val_loss: 1757653.9128\n",
      "Epoch 126/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1698279.8576 - val_loss: 1848712.9894\n",
      "Epoch 127/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1704931.7736 - val_loss: 1985261.4683\n",
      "Epoch 128/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1714382.7306 - val_loss: 1848368.8553\n",
      "Epoch 129/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1679230.0318 - val_loss: 1878559.8922\n",
      "Epoch 130/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1714249.5111 - val_loss: 1861581.5187\n",
      "Epoch 131/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1694900.3699 - val_loss: 1873148.2759\n",
      "Epoch 132/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1726813.9598 - val_loss: 1962785.4045\n",
      "Epoch 133/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1724374.1827 - val_loss: 1743943.9095\n",
      "Epoch 134/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1688352.8121 - val_loss: 2033809.4599\n",
      "Epoch 135/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1714602.4369 - val_loss: 1895179.4955\n",
      "Epoch 136/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1686986.9627 - val_loss: 1773305.8186\n",
      "Epoch 137/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1703926.7167 - val_loss: 1770564.2328\n",
      "Epoch 138/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1685890.0504 - val_loss: 2041248.9404\n",
      "Epoch 139/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1729276.2109 - val_loss: 1923966.0192\n",
      "Epoch 140/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1689354.1803 - val_loss: 1775571.9139\n",
      "Epoch 141/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1700948.7800 - val_loss: 2007535.9547\n",
      "Epoch 142/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1677143.9820 - val_loss: 1747637.7252\n",
      "Epoch 143/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1678302.3638 - val_loss: 1879376.9178\n",
      "Epoch 144/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1684884.7143 - val_loss: 1823081.7720\n",
      "Epoch 145/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1674446.4738 - val_loss: 1750574.6771\n",
      "Epoch 146/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1671849.0765 - val_loss: 1836477.7067\n",
      "Epoch 147/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1661808.8884 - val_loss: 1898655.9513\n",
      "Epoch 148/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1683408.8602 - val_loss: 1897458.8632\n",
      "Epoch 149/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1679860.8946 - val_loss: 1760102.4134\n",
      "Epoch 150/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1667434.1047 - val_loss: 1844385.8481\n",
      "Epoch 151/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1684024.2960 - val_loss: 1750928.4605\n",
      "Epoch 152/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1651704.6765 - val_loss: 1684332.8743\n",
      "Epoch 153/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1666833.3385 - val_loss: 1902936.2733\n",
      "Epoch 154/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1678100.7808 - val_loss: 1873748.3270\n",
      "Epoch 155/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1646670.4550 - val_loss: 1768628.6411\n",
      "Epoch 156/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1676143.2446 - val_loss: 1666180.7859\n",
      "Epoch 157/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1694808.5392 - val_loss: 1652488.2842\n",
      "Epoch 158/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1654473.4021 - val_loss: 1714355.8732\n",
      "Epoch 159/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14390/14390 [==============================] - 0s 6us/step - loss: 1647541.9575 - val_loss: 1891157.5641\n",
      "Epoch 160/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1647342.0210 - val_loss: 1938939.1685\n",
      "Epoch 161/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1664672.8515 - val_loss: 1744989.6185\n",
      "Epoch 162/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1647465.2493 - val_loss: 1691354.2279\n",
      "Epoch 163/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1635654.3222 - val_loss: 1630350.8195\n",
      "Epoch 164/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1650411.1005 - val_loss: 1743120.2487\n",
      "Epoch 165/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1636427.4721 - val_loss: 1736324.6116\n",
      "Epoch 166/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1619516.4720 - val_loss: 1777421.9938\n",
      "Epoch 167/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1638581.3806 - val_loss: 1705301.6009\n",
      "Epoch 168/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1628079.0707 - val_loss: 1718640.2682\n",
      "Epoch 169/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1634084.0829 - val_loss: 1923504.2484\n",
      "Epoch 170/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1645152.1450 - val_loss: 1694091.0549\n",
      "Epoch 171/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1622620.1398 - val_loss: 1684414.7824\n",
      "Epoch 172/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1622597.3894 - val_loss: 1944363.4376\n",
      "Epoch 173/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1625242.5468 - val_loss: 1624600.0763\n",
      "Epoch 174/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1653596.3143 - val_loss: 1876164.3325\n",
      "Epoch 175/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1642427.3301 - val_loss: 1830003.6518\n",
      "Epoch 176/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1626045.1038 - val_loss: 1953626.0677\n",
      "Epoch 177/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1642196.5120 - val_loss: 1670358.6928\n",
      "Epoch 178/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1622430.2122 - val_loss: 1797850.6182\n",
      "Epoch 179/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1609166.7915 - val_loss: 1737701.0855\n",
      "Epoch 180/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1606005.3635 - val_loss: 1751039.1871\n",
      "Epoch 181/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1611796.5052 - val_loss: 2081031.1789\n",
      "Epoch 182/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1625036.2331 - val_loss: 1674037.5159\n",
      "Epoch 183/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1630873.0173 - val_loss: 1953066.6164\n",
      "Epoch 184/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1632327.9321 - val_loss: 1585027.1023\n",
      "Epoch 185/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1617216.0238 - val_loss: 1746523.8598\n",
      "Epoch 186/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1593576.6139 - val_loss: 1718972.7312\n",
      "Epoch 187/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1605766.9037 - val_loss: 1628646.6206\n",
      "Epoch 188/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1604542.5636 - val_loss: 1906698.1656\n",
      "Epoch 189/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1590320.2401 - val_loss: 1715271.1538\n",
      "Epoch 190/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1593749.6845 - val_loss: 1672607.9110\n",
      "Epoch 191/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1604975.0132 - val_loss: 1959295.6597\n",
      "Epoch 192/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1618037.6964 - val_loss: 1787057.5438\n",
      "Epoch 193/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1586690.8122 - val_loss: 1766620.0726\n",
      "Epoch 194/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1594350.5179 - val_loss: 1601327.1519\n",
      "Epoch 195/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1612328.0688 - val_loss: 1762660.0535\n",
      "Epoch 196/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1588689.8409 - val_loss: 1786247.1627\n",
      "Epoch 197/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1588282.5828 - val_loss: 1794783.1732\n",
      "Epoch 198/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1589704.8115 - val_loss: 1745341.1291\n",
      "Epoch 199/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1582454.9175 - val_loss: 1862834.4527\n",
      "Epoch 200/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1597776.1688 - val_loss: 1648145.3027\n",
      "Epoch 201/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1565074.1039 - val_loss: 1760968.2734\n",
      "Epoch 202/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1569934.5401 - val_loss: 1710421.2937\n",
      "Epoch 203/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1570636.9477 - val_loss: 1584108.4013\n",
      "Epoch 204/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1582779.9727 - val_loss: 1604507.8243\n",
      "Epoch 205/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1563630.3740 - val_loss: 1896971.6936\n",
      "Epoch 206/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1577381.3322 - val_loss: 1800636.9205\n",
      "Epoch 207/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1563012.9435 - val_loss: 1927597.0368\n",
      "Epoch 208/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1580156.6659 - val_loss: 1614405.4411\n",
      "Epoch 209/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1561341.1554 - val_loss: 1788557.0791\n",
      "Epoch 210/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1553846.9310 - val_loss: 1707136.7183\n",
      "Epoch 211/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1557782.4235 - val_loss: 1998364.1245\n",
      "Epoch 212/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1608297.5261 - val_loss: 2034850.9841\n",
      "Epoch 213/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1590905.5253 - val_loss: 1757294.9154\n",
      "Epoch 214/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1542227.6169 - val_loss: 1584418.6314\n",
      "Epoch 215/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1554803.9548 - val_loss: 1787090.2516\n",
      "Epoch 216/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1577189.1036 - val_loss: 2247885.7733\n",
      "Epoch 217/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1633356.7732 - val_loss: 1686039.0561\n",
      "Epoch 218/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1554988.8416 - val_loss: 1792630.4547\n",
      "Epoch 219/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1534855.2661 - val_loss: 1798932.4295\n",
      "Epoch 220/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1563914.0303 - val_loss: 1627008.4482\n",
      "Epoch 221/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1556735.3829 - val_loss: 1552203.3977\n",
      "Epoch 222/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1566372.2428 - val_loss: 1775038.5689\n",
      "Epoch 223/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1547893.2960 - val_loss: 1702566.4325\n",
      "Epoch 224/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1520915.1079 - val_loss: 1801350.0969\n",
      "Epoch 225/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1549354.0913 - val_loss: 1757152.9028\n",
      "Epoch 226/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1528360.4414 - val_loss: 1632856.9255\n",
      "Epoch 227/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1525395.4162 - val_loss: 1766000.8308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1529117.2970 - val_loss: 1735631.7367\n",
      "Epoch 229/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1530254.4544 - val_loss: 1818379.4714\n",
      "Epoch 230/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1517353.3540 - val_loss: 1839764.4331\n",
      "Epoch 231/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1505997.1369 - val_loss: 1798433.9103\n",
      "Epoch 232/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1522432.8888 - val_loss: 1886074.4930\n",
      "Epoch 233/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1510914.7331 - val_loss: 1578565.2690\n",
      "Epoch 234/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1527042.6485 - val_loss: 1725982.2411\n",
      "Epoch 235/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1518797.7675 - val_loss: 1677875.3515\n",
      "Epoch 236/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1522289.4363 - val_loss: 1825260.7778\n",
      "Epoch 237/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1526632.9481 - val_loss: 1682605.4174\n",
      "Epoch 238/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1521391.7024 - val_loss: 1829315.5999\n",
      "Epoch 239/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1514929.6668 - val_loss: 1712953.1152\n",
      "Epoch 240/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1555544.0439 - val_loss: 1902604.2573\n",
      "Epoch 241/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1523536.6695 - val_loss: 1870927.9623\n",
      "Epoch 242/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1509963.5040 - val_loss: 1622984.4237\n",
      "Epoch 243/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1500104.5208 - val_loss: 1713812.3894\n",
      "Epoch 244/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1501867.5560 - val_loss: 1572454.6532\n",
      "Epoch 245/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1508105.1508 - val_loss: 1622763.0449\n",
      "Epoch 246/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1519188.4755 - val_loss: 1864911.3217\n",
      "Epoch 247/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1506261.1622 - val_loss: 1770513.4006\n",
      "Epoch 248/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1493883.2829 - val_loss: 2165242.8455\n",
      "Epoch 249/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1562160.8393 - val_loss: 1715349.7427\n",
      "Epoch 250/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1495606.1183 - val_loss: 1590636.4990\n",
      "Epoch 251/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1510901.8399 - val_loss: 1777860.8117\n",
      "Epoch 252/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1481410.5330 - val_loss: 1666575.7486\n",
      "Epoch 253/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1492364.3163 - val_loss: 2035544.8422\n",
      "Epoch 254/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1476012.4533 - val_loss: 1720812.2294\n",
      "Epoch 255/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1485306.2125 - val_loss: 1738522.0874\n",
      "Epoch 256/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1486693.3092 - val_loss: 1570059.3076\n",
      "Epoch 257/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1491707.5474 - val_loss: 1854397.4442\n",
      "Epoch 258/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1491104.1131 - val_loss: 1668580.4434\n",
      "Epoch 259/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1520039.8100 - val_loss: 1697478.8078\n",
      "Epoch 260/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1501973.7794 - val_loss: 1756500.3999\n",
      "Epoch 261/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1465231.8500 - val_loss: 2082723.7160\n",
      "Epoch 262/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1508220.8687 - val_loss: 1575921.7390\n",
      "Epoch 263/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1461004.7327 - val_loss: 1643297.7656\n",
      "Epoch 264/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1465724.0854 - val_loss: 1896536.7770\n",
      "Epoch 265/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1457005.1437 - val_loss: 1747163.1674\n",
      "Epoch 266/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1471326.2866 - val_loss: 1804129.6488\n",
      "Epoch 267/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1458249.0808 - val_loss: 1578464.8185\n",
      "Epoch 268/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1496181.8845 - val_loss: 1619018.4243\n",
      "Epoch 269/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1477788.8364 - val_loss: 1746105.7270\n",
      "Epoch 270/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1446122.9196 - val_loss: 1988645.9120\n",
      "Epoch 271/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1527609.6513 - val_loss: 1603926.7742\n",
      "Epoch 272/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1451850.3706 - val_loss: 1514678.4638\n",
      "Epoch 273/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1478295.3708 - val_loss: 1843440.9798\n",
      "Epoch 274/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1456056.4935 - val_loss: 1900064.7376\n",
      "Epoch 275/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1456044.9947 - val_loss: 1755065.9432\n",
      "Epoch 276/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1451223.7430 - val_loss: 1524526.0876\n",
      "Epoch 277/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1448588.8489 - val_loss: 1590955.7496\n",
      "Epoch 278/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1455990.3646 - val_loss: 1573949.4306\n",
      "Epoch 279/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1454835.9073 - val_loss: 1755764.3659\n",
      "Epoch 280/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1429157.2747 - val_loss: 1965093.5527\n",
      "Epoch 281/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1449656.3638 - val_loss: 1823963.2843\n",
      "Epoch 282/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1465935.4260 - val_loss: 1560713.8085\n",
      "Epoch 283/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1489471.5062 - val_loss: 1976939.2143\n",
      "Epoch 284/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1469771.8282 - val_loss: 1754889.0655\n",
      "Epoch 285/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1447010.1293 - val_loss: 1646370.0198\n",
      "Epoch 286/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1439423.7399 - val_loss: 1561844.5441\n",
      "Epoch 287/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1458722.0938 - val_loss: 1756051.5245\n",
      "Epoch 288/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1447471.0448 - val_loss: 1728888.2538\n",
      "Epoch 289/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1449749.2597 - val_loss: 1825842.7314\n",
      "Epoch 290/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1460045.7491 - val_loss: 1911673.4418\n",
      "Epoch 291/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1456011.1355 - val_loss: 1570572.4224\n",
      "Epoch 292/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1443060.6272 - val_loss: 1835093.9644\n",
      "Epoch 293/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1435358.4923 - val_loss: 1867734.7928\n",
      "Epoch 294/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1452826.9503 - val_loss: 1658741.3860\n",
      "Epoch 295/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1435575.8320 - val_loss: 1476964.6298\n",
      "Epoch 296/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1461230.0705 - val_loss: 1887381.7153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1457123.0555 - val_loss: 1935103.9722\n",
      "Epoch 298/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1460839.7554 - val_loss: 1868558.4712\n",
      "Epoch 299/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1451280.2634 - val_loss: 1652112.1267\n",
      "Epoch 300/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1436997.5937 - val_loss: 1553266.9697\n",
      "Epoch 301/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1448879.8955 - val_loss: 1999046.9153\n",
      "Epoch 302/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1450696.1152 - val_loss: 1588525.4677\n",
      "Epoch 303/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1461338.6145 - val_loss: 1913104.7731\n",
      "Epoch 304/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1449024.5737 - val_loss: 1980890.2059\n",
      "Epoch 305/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1463495.3228 - val_loss: 1966777.7012\n",
      "Epoch 306/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1456042.4197 - val_loss: 1586624.2785\n",
      "Epoch 307/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1418381.2205 - val_loss: 1706998.9766\n",
      "Epoch 308/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1433064.9431 - val_loss: 1529153.1606\n",
      "Epoch 309/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1441586.2119 - val_loss: 1836027.1556\n",
      "Epoch 310/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1419079.7778 - val_loss: 1787641.4897\n",
      "Epoch 311/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1418503.3792 - val_loss: 1606553.7437\n",
      "Epoch 312/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1428361.6318 - val_loss: 1646950.3920\n",
      "Epoch 313/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1442983.1650 - val_loss: 1590390.9282\n",
      "Epoch 314/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1463561.0095 - val_loss: 1839765.9960\n",
      "Epoch 315/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1438781.5218 - val_loss: 1807407.0674\n",
      "Epoch 316/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1429840.3701 - val_loss: 1570053.9851\n",
      "Epoch 317/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1440999.5966 - val_loss: 1874348.9200\n",
      "Epoch 318/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1451447.6375 - val_loss: 2016939.2561\n",
      "Epoch 319/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1465979.3880 - val_loss: 1695949.6488\n",
      "Epoch 320/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1422241.1374 - val_loss: 1692950.7546\n",
      "Epoch 321/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1421807.3827 - val_loss: 1967117.9765\n",
      "Epoch 322/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1424873.3308 - val_loss: 1696690.0611\n",
      "Epoch 323/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1422323.6447 - val_loss: 1909860.5833\n",
      "Epoch 324/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1441476.0477 - val_loss: 1503539.6116\n",
      "Epoch 325/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1482075.6127 - val_loss: 1857182.5998\n",
      "Epoch 326/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1456293.5684 - val_loss: 1898761.3059\n",
      "Epoch 327/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1425149.5471 - val_loss: 1742727.7349\n",
      "Epoch 328/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1409635.6505 - val_loss: 1697093.4816\n",
      "Epoch 329/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1409461.8628 - val_loss: 1619819.2086\n",
      "Epoch 330/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1428291.4089 - val_loss: 1589608.6158\n",
      "Epoch 331/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1420139.1522 - val_loss: 1854696.9658\n",
      "Epoch 332/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1454902.2155 - val_loss: 1812547.7101\n",
      "Epoch 333/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1426217.7350 - val_loss: 1761569.8343\n",
      "Epoch 334/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1413599.7709 - val_loss: 1736409.5780\n",
      "Epoch 335/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1412876.2047 - val_loss: 1573081.7366\n",
      "Epoch 336/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1432034.0674 - val_loss: 1838003.3440\n",
      "Epoch 337/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1403859.1888 - val_loss: 1603461.6696\n",
      "Epoch 338/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1423239.2174 - val_loss: 1771554.4834\n",
      "Epoch 339/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1470285.5118 - val_loss: 1861134.2546\n",
      "Epoch 340/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1424662.5846 - val_loss: 1643488.0424\n",
      "Epoch 341/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1413007.9722 - val_loss: 1724144.2859\n",
      "Epoch 342/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1417575.3450 - val_loss: 1953538.2601\n",
      "Epoch 343/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1428245.1409 - val_loss: 1880546.6737\n",
      "Epoch 344/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1453349.0809 - val_loss: 1890491.4685\n",
      "Epoch 345/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1414964.6043 - val_loss: 1485420.3679\n",
      "Epoch 346/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1418695.6664 - val_loss: 1774149.5113\n",
      "Epoch 347/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1414964.9762 - val_loss: 2027561.6956\n",
      "Epoch 348/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1451715.1257 - val_loss: 1840414.9007\n",
      "Epoch 349/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1429889.9262 - val_loss: 1981642.2090\n",
      "Epoch 350/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1419570.6861 - val_loss: 1670498.5704\n",
      "Epoch 351/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1405852.7979 - val_loss: 1576870.5151\n",
      "Epoch 352/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1422273.1461 - val_loss: 1677630.0452\n",
      "Epoch 353/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1393692.5969 - val_loss: 1540985.9550\n",
      "Epoch 354/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1414674.5734 - val_loss: 1736860.7981\n",
      "Epoch 355/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1396313.5867 - val_loss: 1931332.2898\n",
      "Epoch 356/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1407835.7048 - val_loss: 1745796.1452\n",
      "Epoch 357/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1424764.0695 - val_loss: 1677825.9450\n",
      "Epoch 358/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1427009.0574 - val_loss: 1884619.1363\n",
      "Epoch 359/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1451182.0509 - val_loss: 1974287.0665\n",
      "Epoch 360/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1473383.1633 - val_loss: 1953439.4078\n",
      "Epoch 361/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1427877.1270 - val_loss: 1661180.2471\n",
      "Epoch 362/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1406931.6585 - val_loss: 1851061.3773\n",
      "Epoch 363/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1433915.5558 - val_loss: 1759761.6076\n",
      "Epoch 364/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1426779.0448 - val_loss: 1825419.9849\n",
      "Epoch 365/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1400832.0499 - val_loss: 1681850.4925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 366/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1387888.6188 - val_loss: 1653998.2271\n",
      "Epoch 367/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1413338.7075 - val_loss: 1989973.3942\n",
      "Epoch 368/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1429769.8367 - val_loss: 1859297.5432\n",
      "Epoch 369/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1414139.7003 - val_loss: 1776540.3279\n",
      "Epoch 370/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1393412.9811 - val_loss: 1766343.8061\n",
      "Epoch 371/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1406413.5115 - val_loss: 1554467.5339\n",
      "Epoch 372/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1416157.3192 - val_loss: 1708712.7782\n",
      "Epoch 373/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1391607.6252 - val_loss: 1763411.3962\n",
      "Epoch 374/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1393758.7224 - val_loss: 1751607.1163\n",
      "Epoch 375/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1409299.1520 - val_loss: 1972283.1379\n",
      "Epoch 376/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1410580.0603 - val_loss: 1473763.6879\n",
      "Epoch 377/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1469829.5816 - val_loss: 1747858.8404\n",
      "Epoch 378/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1405326.5950 - val_loss: 1767031.9955\n",
      "Epoch 379/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1419470.4046 - val_loss: 1798613.0543\n",
      "Epoch 380/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1385906.2804 - val_loss: 1686853.1738\n",
      "Epoch 381/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1411424.3446 - val_loss: 1575000.4260\n",
      "Epoch 382/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1387925.8241 - val_loss: 1713651.0134\n",
      "Epoch 383/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1411170.7203 - val_loss: 1497703.8039\n",
      "Epoch 384/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1414710.4151 - val_loss: 1531252.9379\n",
      "Epoch 385/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1402620.6951 - val_loss: 1747241.0912\n",
      "Epoch 386/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1406545.1370 - val_loss: 1807828.2634\n",
      "Epoch 387/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1389907.5936 - val_loss: 1866282.6233\n",
      "Epoch 388/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1446846.2893 - val_loss: 1947344.6191\n",
      "Epoch 389/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1397134.8028 - val_loss: 1732188.9908\n",
      "Epoch 390/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1401782.8404 - val_loss: 1693640.8737\n",
      "Epoch 391/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1393759.5324 - val_loss: 1768375.7719\n",
      "Epoch 392/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1425652.9691 - val_loss: 1598851.7036\n",
      "Epoch 393/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1399388.3869 - val_loss: 1599718.4558\n",
      "Epoch 394/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1388064.9638 - val_loss: 2032439.2961\n",
      "Epoch 395/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1444620.2548 - val_loss: 1884498.8496\n",
      "Epoch 396/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1376969.3610 - val_loss: 1714571.0568\n",
      "Epoch 397/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1391258.1841 - val_loss: 1874486.3695\n",
      "Epoch 398/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1385718.0965 - val_loss: 1716800.7126\n",
      "Epoch 399/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1384823.2391 - val_loss: 1699381.0187\n",
      "Epoch 400/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1388699.1970 - val_loss: 1719897.8575\n",
      "Epoch 401/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1395854.4888 - val_loss: 1776401.3709\n",
      "Epoch 402/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1381515.9381 - val_loss: 1719139.9390\n",
      "Epoch 403/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1399698.3409 - val_loss: 1485485.0378\n",
      "Epoch 404/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1426958.8103 - val_loss: 1811214.0792\n",
      "Epoch 405/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1382929.5552 - val_loss: 1643420.7419\n",
      "Epoch 406/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1388548.1055 - val_loss: 1751412.8342\n",
      "Epoch 407/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1395649.6774 - val_loss: 1951914.5409\n",
      "Epoch 408/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1417384.2869 - val_loss: 1637219.0028\n",
      "Epoch 409/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1399112.9265 - val_loss: 1889327.8010\n",
      "Epoch 410/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1416074.1568 - val_loss: 1820728.9271\n",
      "Epoch 411/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1372012.4584 - val_loss: 2027103.8165\n",
      "Epoch 412/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1438108.3899 - val_loss: 1632151.1761\n",
      "Epoch 413/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1432298.6400 - val_loss: 1569915.5872\n",
      "Epoch 414/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1384630.4713 - val_loss: 1712405.9205\n",
      "Epoch 415/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1381761.1431 - val_loss: 1674544.9963\n",
      "Epoch 416/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1400583.6531 - val_loss: 1785855.1424\n",
      "Epoch 417/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1377441.8647 - val_loss: 1847876.8408\n",
      "Epoch 418/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1421756.8269 - val_loss: 1726973.3319\n",
      "Epoch 419/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1396368.8216 - val_loss: 1562631.2069\n",
      "Epoch 420/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1391529.8352 - val_loss: 1941709.6804\n",
      "Epoch 421/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1385107.3880 - val_loss: 1533628.0975\n",
      "Epoch 422/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1381048.8501 - val_loss: 1603172.6545\n",
      "Epoch 423/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1381052.8312 - val_loss: 1817166.2652\n",
      "Epoch 424/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1401388.5107 - val_loss: 1602480.4403\n",
      "Epoch 425/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1383890.3018 - val_loss: 1758194.7875\n",
      "Epoch 426/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1382340.1597 - val_loss: 1929001.2761\n",
      "Epoch 427/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1377698.6518 - val_loss: 1818907.1343\n",
      "Epoch 428/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1388908.4632 - val_loss: 1565649.5467\n",
      "Epoch 429/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1378903.6816 - val_loss: 2000593.4729\n",
      "Epoch 430/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1398734.9850 - val_loss: 1586331.4061\n",
      "Epoch 431/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1423016.1561 - val_loss: 1975079.2199\n",
      "Epoch 432/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1390788.3625 - val_loss: 1500169.9059\n",
      "Epoch 433/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1386480.2642 - val_loss: 1754416.4780\n",
      "Epoch 434/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1386417.4976 - val_loss: 1670231.0758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 435/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1371846.0360 - val_loss: 1794675.2097\n",
      "Epoch 436/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1406795.9403 - val_loss: 1519787.5646\n",
      "Epoch 437/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1422176.2693 - val_loss: 1620133.8540\n",
      "Epoch 438/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1378622.9467 - val_loss: 1722119.2753\n",
      "Epoch 439/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1369266.9698 - val_loss: 1915436.8960\n",
      "Epoch 440/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1404091.7958 - val_loss: 1686136.5839\n",
      "Epoch 441/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1375787.7263 - val_loss: 1581483.1868\n",
      "Epoch 442/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1407635.2239 - val_loss: 1959375.4548\n",
      "Epoch 443/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1372561.6054 - val_loss: 1633736.6334\n",
      "Epoch 444/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1367198.7549 - val_loss: 1812141.2588\n",
      "Epoch 445/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1366901.4886 - val_loss: 1742792.9590\n",
      "Epoch 446/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1373149.0770 - val_loss: 1601462.8142\n",
      "Epoch 447/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1375672.0712 - val_loss: 2054344.9260\n",
      "Epoch 448/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1443673.8957 - val_loss: 1730981.8913\n",
      "Epoch 449/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1392188.6119 - val_loss: 1669897.7982\n",
      "Epoch 450/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1375565.1858 - val_loss: 1750530.6613\n",
      "Epoch 451/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1373708.6451 - val_loss: 1771599.7517\n",
      "Epoch 452/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1369749.0752 - val_loss: 1867116.3275\n",
      "Epoch 453/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1390586.4296 - val_loss: 1907475.7204\n",
      "Epoch 454/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1374904.8567 - val_loss: 1586169.9542\n",
      "Epoch 455/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1379606.3996 - val_loss: 1723217.4175\n",
      "Epoch 456/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1376210.2214 - val_loss: 1696762.2115\n",
      "Epoch 457/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1385940.2796 - val_loss: 1767113.5333\n",
      "Epoch 458/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1383405.5071 - val_loss: 1889963.6507\n",
      "Epoch 459/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1397157.0227 - val_loss: 1653387.6462\n",
      "Epoch 460/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1378450.3011 - val_loss: 1938774.4326\n",
      "Epoch 461/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1383078.1976 - val_loss: 2020819.7666\n",
      "Epoch 462/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1429362.7820 - val_loss: 1545267.6506\n",
      "Epoch 463/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1411702.9850 - val_loss: 1557433.3922\n",
      "Epoch 464/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1374381.1237 - val_loss: 1691375.3497\n",
      "Epoch 465/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1351505.4910 - val_loss: 1862181.7960\n",
      "Epoch 466/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1377308.4430 - val_loss: 1570335.9891\n",
      "Epoch 467/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1418641.7876 - val_loss: 1576899.0711\n",
      "Epoch 468/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1420922.7203 - val_loss: 1532691.9611\n",
      "Epoch 469/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1385776.8671 - val_loss: 1541172.1219\n",
      "Epoch 470/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1406471.4238 - val_loss: 1429623.1393\n",
      "Epoch 471/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1386018.0313 - val_loss: 1768882.6205\n",
      "Epoch 472/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1359820.9861 - val_loss: 1872353.1098\n",
      "Epoch 473/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1378910.2376 - val_loss: 1706125.6854\n",
      "Epoch 474/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1393653.8778 - val_loss: 1953729.0975\n",
      "Epoch 475/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1388935.2362 - val_loss: 1723523.5696\n",
      "Epoch 476/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1385913.6334 - val_loss: 1833128.3897\n",
      "Epoch 477/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1351083.0433 - val_loss: 1775773.5366\n",
      "Epoch 478/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1370055.5530 - val_loss: 1848848.1178\n",
      "Epoch 479/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1377487.6691 - val_loss: 1643276.1457\n",
      "Epoch 480/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1364848.6216 - val_loss: 1564734.5785\n",
      "Epoch 481/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1384272.1160 - val_loss: 1986135.6700\n",
      "Epoch 482/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1396205.4289 - val_loss: 1708405.3554\n",
      "Epoch 483/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1378269.1749 - val_loss: 1612821.5123\n",
      "Epoch 484/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1398564.6199 - val_loss: 1734249.3161\n",
      "Epoch 485/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1364536.1289 - val_loss: 1980702.6086\n",
      "Epoch 486/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1380335.8009 - val_loss: 1813828.1918\n",
      "Epoch 487/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1384588.5099 - val_loss: 1546718.9486\n",
      "Epoch 488/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1409628.9472 - val_loss: 1643045.7497\n",
      "Epoch 489/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1362694.5333 - val_loss: 1621844.4289\n",
      "Epoch 490/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1361412.0677 - val_loss: 1926259.5601\n",
      "Epoch 491/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1406629.8618 - val_loss: 1883971.8560\n",
      "Epoch 492/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1404973.8596 - val_loss: 1830607.0770\n",
      "Epoch 493/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1362097.2735 - val_loss: 1754057.1896\n",
      "Epoch 494/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1393965.3337 - val_loss: 1833437.3861\n",
      "Epoch 495/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1370021.5133 - val_loss: 1794080.7624\n",
      "Epoch 496/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1394479.5751 - val_loss: 1680901.7074\n",
      "Epoch 497/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1367406.5678 - val_loss: 1757822.4590\n",
      "Epoch 498/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1353369.9589 - val_loss: 1528131.2001\n",
      "Epoch 499/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1378264.9549 - val_loss: 1603641.2113\n",
      "Epoch 500/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1364331.6814 - val_loss: 1658726.2639\n",
      "Epoch 501/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1357204.5591 - val_loss: 1504995.3393\n",
      "Epoch 502/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1363059.3319 - val_loss: 1695291.7718\n",
      "Epoch 503/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1382289.7828 - val_loss: 1888785.1324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1383479.8095 - val_loss: 1601987.5041\n",
      "Epoch 505/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1397067.9509 - val_loss: 1656993.4109\n",
      "Epoch 506/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1371043.8441 - val_loss: 1802544.0412\n",
      "Epoch 507/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1376271.5679 - val_loss: 1642209.7208\n",
      "Epoch 508/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1359655.4456 - val_loss: 1627837.5299\n",
      "Epoch 509/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1368120.7970 - val_loss: 1663029.9788\n",
      "Epoch 510/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1370695.3580 - val_loss: 1704234.8741\n",
      "Epoch 511/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1374320.1911 - val_loss: 1437174.9962\n",
      "Epoch 512/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1394879.4040 - val_loss: 1545105.4795\n",
      "Epoch 513/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1373091.0684 - val_loss: 1883277.4429\n",
      "Epoch 514/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1433682.1493 - val_loss: 1706704.6123\n",
      "Epoch 515/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1381388.4556 - val_loss: 1667488.0800\n",
      "Epoch 516/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1365568.9040 - val_loss: 1813190.2964\n",
      "Epoch 517/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1375427.4813 - val_loss: 1781241.1696\n",
      "Epoch 518/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1358888.9047 - val_loss: 1846336.8390\n",
      "Epoch 519/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1358768.9979 - val_loss: 1481685.8728\n",
      "Epoch 520/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1402671.3516 - val_loss: 1861367.0467\n",
      "Epoch 521/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1367061.1771 - val_loss: 1767727.1717\n",
      "Epoch 522/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1347549.7767 - val_loss: 1785837.1696\n",
      "Epoch 523/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1361183.4937 - val_loss: 1707612.1079\n",
      "Epoch 524/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1334977.8258 - val_loss: 1617866.2353\n",
      "Epoch 525/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1361042.8826 - val_loss: 1858206.4197\n",
      "Epoch 526/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1405424.9976 - val_loss: 2102324.1142\n",
      "Epoch 527/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1480820.0896 - val_loss: 1533777.9268\n",
      "Epoch 528/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1405017.0123 - val_loss: 1784517.8458\n",
      "Epoch 529/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1358834.2938 - val_loss: 1657356.2833\n",
      "Epoch 530/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1366570.6886 - val_loss: 1897427.2998\n",
      "Epoch 531/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1374897.9446 - val_loss: 1606296.2108\n",
      "Epoch 532/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1365676.0274 - val_loss: 1832258.8074\n",
      "Epoch 533/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1368865.6389 - val_loss: 1704738.6223\n",
      "Epoch 534/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1353531.5951 - val_loss: 1786898.4930\n",
      "Epoch 535/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1375479.7009 - val_loss: 1569986.8850\n",
      "Epoch 536/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1390063.7716 - val_loss: 1593315.3749\n",
      "Epoch 537/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1351937.5566 - val_loss: 1755256.7842\n",
      "Epoch 538/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1360539.2096 - val_loss: 1823148.5485\n",
      "Epoch 539/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1396810.5151 - val_loss: 1870346.2130\n",
      "Epoch 540/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1359861.4957 - val_loss: 1991111.3067\n",
      "Epoch 541/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1389633.9380 - val_loss: 1783140.4644\n",
      "Epoch 542/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1366487.9904 - val_loss: 1477223.4384\n",
      "Epoch 543/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1394396.5318 - val_loss: 1626058.7187\n",
      "Epoch 544/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1371366.6678 - val_loss: 1594865.8694\n",
      "Epoch 545/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1359159.8228 - val_loss: 1671739.8179\n",
      "Epoch 546/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1361580.7794 - val_loss: 1885566.2861\n",
      "Epoch 547/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1355859.8862 - val_loss: 1479386.2590\n",
      "Epoch 548/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1397429.8034 - val_loss: 1496334.8845\n",
      "Epoch 549/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1420575.2329 - val_loss: 1795137.5515\n",
      "Epoch 550/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1417895.1018 - val_loss: 1852687.1869\n",
      "Epoch 551/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1410008.0187 - val_loss: 1757627.6779\n",
      "Epoch 552/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1358819.3097 - val_loss: 1840284.6824\n",
      "Epoch 553/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1369226.9015 - val_loss: 1965601.1709\n",
      "Epoch 554/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1384341.8533 - val_loss: 1733507.2312\n",
      "Epoch 555/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1347372.0951 - val_loss: 1607195.7305\n",
      "Epoch 556/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1374924.7636 - val_loss: 1487242.5962\n",
      "Epoch 557/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1362024.2723 - val_loss: 1948512.6995\n",
      "Epoch 558/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1365798.3674 - val_loss: 1744267.6351\n",
      "Epoch 559/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1341039.1406 - val_loss: 1544204.2582\n",
      "Epoch 560/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1376182.1264 - val_loss: 1793465.2848\n",
      "Epoch 561/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1357852.2796 - val_loss: 1895565.4672\n",
      "Epoch 562/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1361308.7768 - val_loss: 2042903.5536\n",
      "Epoch 563/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1413558.7336 - val_loss: 1880751.6427\n",
      "Epoch 564/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1465124.6657 - val_loss: 1444722.0427\n",
      "Epoch 565/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1402058.8730 - val_loss: 1464204.6234\n",
      "Epoch 566/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1391575.4644 - val_loss: 1972918.0546\n",
      "Epoch 567/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1365341.6197 - val_loss: 1672377.8648\n",
      "Epoch 568/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1348233.0106 - val_loss: 1772776.0440\n",
      "Epoch 569/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1359221.4639 - val_loss: 1837502.4304\n",
      "Epoch 570/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1350119.8771 - val_loss: 1835864.9350\n",
      "Epoch 571/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1380665.2582 - val_loss: 1836586.9962\n",
      "Epoch 572/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1360099.2599 - val_loss: 1723244.1781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 573/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1353375.4524 - val_loss: 1658871.6447\n",
      "Epoch 574/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1339629.1827 - val_loss: 1923880.1816\n",
      "Epoch 575/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1349765.7533 - val_loss: 1915013.0120\n",
      "Epoch 576/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1360935.6564 - val_loss: 1583621.9824\n",
      "Epoch 577/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1383502.6133 - val_loss: 1831117.6407\n",
      "Epoch 578/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1381798.2724 - val_loss: 2065152.5819\n",
      "Epoch 579/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1396086.4222 - val_loss: 1849581.0728\n",
      "Epoch 580/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1361041.1399 - val_loss: 1889100.3155\n",
      "Epoch 581/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1349007.4366 - val_loss: 2055781.3523\n",
      "Epoch 582/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1411087.0072 - val_loss: 1610720.5853\n",
      "Epoch 583/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1350710.5962 - val_loss: 1974334.6959\n",
      "Epoch 584/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1346369.9534 - val_loss: 1751779.1042\n",
      "Epoch 585/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1389370.3806 - val_loss: 1720439.2248\n",
      "Epoch 586/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1356686.9224 - val_loss: 1862409.8353\n",
      "Epoch 587/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1347467.0426 - val_loss: 1704289.1929\n",
      "Epoch 588/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1356809.7024 - val_loss: 1690725.6367\n",
      "Epoch 589/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1341980.5508 - val_loss: 1683920.0288\n",
      "Epoch 590/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1350926.1315 - val_loss: 1589958.3236\n",
      "Epoch 591/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1357087.0491 - val_loss: 1742856.4747\n",
      "Epoch 592/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1366828.6260 - val_loss: 1882448.3877\n",
      "Epoch 593/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1364289.0209 - val_loss: 1717092.0722\n",
      "Epoch 594/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1348600.6643 - val_loss: 1696957.9905\n",
      "Epoch 595/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1337039.2778 - val_loss: 1745609.3909\n",
      "Epoch 596/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1358794.7692 - val_loss: 1873889.8358\n",
      "Epoch 597/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1373046.5653 - val_loss: 1926857.8065\n",
      "Epoch 598/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1355634.9188 - val_loss: 1763856.2180\n",
      "Epoch 599/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1385774.7212 - val_loss: 1604615.1636\n",
      "Epoch 600/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1380914.3667 - val_loss: 1945180.7775\n",
      "Train on 14390 samples, validate on 1599 samples\n",
      "Epoch 1/600\n",
      "14390/14390 [==============================] - 0s 24us/step - loss: 7123561.6604 - val_loss: 7251557.0550\n",
      "Epoch 2/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 7107730.2974 - val_loss: 7131705.9221\n",
      "Epoch 3/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 5212098.1418 - val_loss: 3000975.4268\n",
      "Epoch 4/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2705372.5497 - val_loss: 2715683.9836\n",
      "Epoch 5/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2627778.2456 - val_loss: 2703058.5602\n",
      "Epoch 6/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2629033.9393 - val_loss: 2701984.9454\n",
      "Epoch 7/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2625215.9340 - val_loss: 2699286.8871\n",
      "Epoch 8/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2622852.6229 - val_loss: 2699417.4676\n",
      "Epoch 9/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2618970.6819 - val_loss: 2696170.5314\n",
      "Epoch 10/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2617369.9345 - val_loss: 2693485.4104\n",
      "Epoch 11/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2612634.3129 - val_loss: 2693662.6413\n",
      "Epoch 12/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2610642.8661 - val_loss: 2689456.8422\n",
      "Epoch 13/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2606442.8939 - val_loss: 2687687.1709\n",
      "Epoch 14/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2605670.6346 - val_loss: 2682961.0083\n",
      "Epoch 15/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2603439.9487 - val_loss: 2686141.6218\n",
      "Epoch 16/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2598342.5650 - val_loss: 2678649.4748\n",
      "Epoch 17/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2597568.8865 - val_loss: 2673957.2797\n",
      "Epoch 18/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2592692.5392 - val_loss: 2670812.2781\n",
      "Epoch 19/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2588710.0419 - val_loss: 2672940.2348\n",
      "Epoch 20/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2589500.1824 - val_loss: 2664751.3160\n",
      "Epoch 21/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2582772.4986 - val_loss: 2660101.5277\n",
      "Epoch 22/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2578356.1544 - val_loss: 2656032.4955\n",
      "Epoch 23/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2573475.9918 - val_loss: 2651571.3574\n",
      "Epoch 24/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2569358.8089 - val_loss: 2648156.7028\n",
      "Epoch 25/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2567319.6045 - val_loss: 2640457.7613\n",
      "Epoch 26/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2563166.0415 - val_loss: 2641374.1978\n",
      "Epoch 27/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2558104.7314 - val_loss: 2645827.9992\n",
      "Epoch 28/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2555892.8433 - val_loss: 2662707.4382\n",
      "Epoch 29/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2555726.2062 - val_loss: 2611992.2369\n",
      "Epoch 30/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2536079.6846 - val_loss: 2602116.9276\n",
      "Epoch 31/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2523862.5319 - val_loss: 2589922.7627\n",
      "Epoch 32/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2511810.6889 - val_loss: 2578918.4601\n",
      "Epoch 33/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2502668.0988 - val_loss: 2568201.0869\n",
      "Epoch 34/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2495782.6520 - val_loss: 2542808.7795\n",
      "Epoch 35/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2471219.1347 - val_loss: 2519950.7458\n",
      "Epoch 36/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2450409.2107 - val_loss: 2495359.6570\n",
      "Epoch 37/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2429861.0021 - val_loss: 2469424.3726\n",
      "Epoch 38/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2411168.3813 - val_loss: 2437733.5471\n",
      "Epoch 39/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2372241.2014 - val_loss: 2391434.0816\n",
      "Epoch 40/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2353107.4390 - val_loss: 2356485.4825\n",
      "Epoch 41/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2323097.4323 - val_loss: 2336379.5388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2304413.2891 - val_loss: 2279870.5715\n",
      "Epoch 43/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 2279478.9864 - val_loss: 2372745.0874\n",
      "Epoch 44/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2264091.8170 - val_loss: 2225149.2689\n",
      "Epoch 45/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2240156.3175 - val_loss: 2228725.6703\n",
      "Epoch 46/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2231761.6238 - val_loss: 2182193.8476\n",
      "Epoch 47/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2203903.7792 - val_loss: 2138252.4588\n",
      "Epoch 48/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2188608.3797 - val_loss: 2146177.4577\n",
      "Epoch 49/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2163090.2505 - val_loss: 2110126.1291\n",
      "Epoch 50/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2152058.4866 - val_loss: 2081914.0076\n",
      "Epoch 51/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2134045.3417 - val_loss: 2118260.8754\n",
      "Epoch 52/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2103972.3353 - val_loss: 2042597.1951\n",
      "Epoch 53/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2103008.6824 - val_loss: 2016930.7290\n",
      "Epoch 54/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2088419.4390 - val_loss: 2113071.2855\n",
      "Epoch 55/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2079686.7293 - val_loss: 2105242.3058\n",
      "Epoch 56/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2068258.0458 - val_loss: 1971184.7748\n",
      "Epoch 57/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2040866.2718 - val_loss: 2009871.8023\n",
      "Epoch 58/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2036963.1507 - val_loss: 1927462.3849\n",
      "Epoch 59/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2019057.5412 - val_loss: 2009850.0503\n",
      "Epoch 60/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1993784.8326 - val_loss: 1913148.2086\n",
      "Epoch 61/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2005842.6215 - val_loss: 1934442.1922\n",
      "Epoch 62/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1975329.8094 - val_loss: 1892633.8766\n",
      "Epoch 63/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1995193.8066 - val_loss: 1912362.5760\n",
      "Epoch 64/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1968512.7962 - val_loss: 2001027.4296\n",
      "Epoch 65/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1941904.8812 - val_loss: 2049105.9625\n",
      "Epoch 66/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1976374.9352 - val_loss: 1956294.1888\n",
      "Epoch 67/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1935549.3795 - val_loss: 1906281.3953\n",
      "Epoch 68/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1928586.8929 - val_loss: 2075918.4379\n",
      "Epoch 69/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1927993.0709 - val_loss: 1827774.3932\n",
      "Epoch 70/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1926510.2215 - val_loss: 2183262.2805\n",
      "Epoch 71/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1930293.1149 - val_loss: 1844642.5906\n",
      "Epoch 72/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1922881.1326 - val_loss: 1813452.8664\n",
      "Epoch 73/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1913385.5573 - val_loss: 1984215.8666\n",
      "Epoch 74/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1926128.0745 - val_loss: 1852026.7398\n",
      "Epoch 75/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1894528.7399 - val_loss: 1801421.9174\n",
      "Epoch 76/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1914820.5898 - val_loss: 1878005.3223\n",
      "Epoch 77/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1932936.5958 - val_loss: 2002100.5212\n",
      "Epoch 78/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1890561.8100 - val_loss: 1902407.3119\n",
      "Epoch 79/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1877153.0572 - val_loss: 1809399.9453\n",
      "Epoch 80/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1868634.4483 - val_loss: 1883196.7293\n",
      "Epoch 81/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1880422.3577 - val_loss: 1974924.4160\n",
      "Epoch 82/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1862884.1741 - val_loss: 1850576.2418\n",
      "Epoch 83/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1865798.6267 - val_loss: 1820031.3097\n",
      "Epoch 84/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1845541.0189 - val_loss: 1860523.4196\n",
      "Epoch 85/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1841875.4900 - val_loss: 1880974.6105\n",
      "Epoch 86/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1855889.4884 - val_loss: 1907973.8081\n",
      "Epoch 87/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1859316.4666 - val_loss: 2113677.4287\n",
      "Epoch 88/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1886810.7498 - val_loss: 1812768.6707\n",
      "Epoch 89/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1844692.8494 - val_loss: 1873574.0532\n",
      "Epoch 90/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1830457.9070 - val_loss: 1912126.8806\n",
      "Epoch 91/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1847806.7590 - val_loss: 2049855.3144\n",
      "Epoch 92/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1855314.7099 - val_loss: 1797960.0633\n",
      "Epoch 93/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1825351.6831 - val_loss: 1933106.6107\n",
      "Epoch 94/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1827768.9879 - val_loss: 1901230.7073\n",
      "Epoch 95/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1824175.0465 - val_loss: 1876542.1447\n",
      "Epoch 96/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1827975.9778 - val_loss: 1842219.4171\n",
      "Epoch 97/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1811616.4231 - val_loss: 1819836.9860\n",
      "Epoch 98/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1799049.2829 - val_loss: 1732869.6406\n",
      "Epoch 99/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1819051.7357 - val_loss: 1768251.4670\n",
      "Epoch 100/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1809209.3386 - val_loss: 1819466.5056\n",
      "Epoch 101/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1779608.2024 - val_loss: 1774351.8807\n",
      "Epoch 102/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1785827.6212 - val_loss: 1825530.5342\n",
      "Epoch 103/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1786473.8168 - val_loss: 1721078.8107\n",
      "Epoch 104/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1811952.4490 - val_loss: 1790017.2216\n",
      "Epoch 105/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1779814.0660 - val_loss: 1875081.6678\n",
      "Epoch 106/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1793497.3976 - val_loss: 2024823.0951\n",
      "Epoch 107/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1776648.2726 - val_loss: 1825835.0676\n",
      "Epoch 108/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1768197.2238 - val_loss: 1932928.8243\n",
      "Epoch 109/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1775944.2040 - val_loss: 1883407.1685\n",
      "Epoch 110/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1780512.4197 - val_loss: 1766805.1137\n",
      "Epoch 111/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1767134.9014 - val_loss: 1707967.1182\n",
      "Epoch 112/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1790685.5233 - val_loss: 1819310.1467\n",
      "Epoch 113/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1761789.6740 - val_loss: 1731821.7184\n",
      "Epoch 114/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1759516.6198 - val_loss: 1830533.1812\n",
      "Epoch 115/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1754116.0157 - val_loss: 1721416.1529\n",
      "Epoch 116/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1749871.3584 - val_loss: 1902712.1246\n",
      "Epoch 117/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1744004.0686 - val_loss: 1804901.7777\n",
      "Epoch 118/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1748846.2561 - val_loss: 1843952.8211\n",
      "Epoch 119/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1732394.7996 - val_loss: 1807073.0614\n",
      "Epoch 120/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1733355.7235 - val_loss: 2066586.8191\n",
      "Epoch 121/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1761778.0019 - val_loss: 1888133.4672\n",
      "Epoch 122/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1736211.2323 - val_loss: 1966926.8881\n",
      "Epoch 123/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1750084.6758 - val_loss: 1794749.3410\n",
      "Epoch 124/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1723043.1242 - val_loss: 1789227.1677\n",
      "Epoch 125/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1742423.3694 - val_loss: 1879354.8957\n",
      "Epoch 126/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1734782.7538 - val_loss: 1676510.3582\n",
      "Epoch 127/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1728965.0852 - val_loss: 1693911.7328\n",
      "Epoch 128/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1724275.8705 - val_loss: 1859108.2212\n",
      "Epoch 129/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1717593.9816 - val_loss: 1910417.3311\n",
      "Epoch 130/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1715804.0686 - val_loss: 1782373.4552\n",
      "Epoch 131/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1721497.0594 - val_loss: 1923084.3947\n",
      "Epoch 132/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1726504.2316 - val_loss: 1750273.2810\n",
      "Epoch 133/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1707402.5185 - val_loss: 1827638.8232\n",
      "Epoch 134/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1708279.1784 - val_loss: 1675661.4386\n",
      "Epoch 135/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1718541.6733 - val_loss: 1647888.0476\n",
      "Epoch 136/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1724566.6304 - val_loss: 1859941.7482\n",
      "Epoch 137/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1699714.6867 - val_loss: 1714740.1146\n",
      "Epoch 138/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1703309.4155 - val_loss: 1723208.2856\n",
      "Epoch 139/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1713622.4893 - val_loss: 1678990.4211\n",
      "Epoch 140/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1714785.1851 - val_loss: 1786678.1044\n",
      "Epoch 141/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1683507.8642 - val_loss: 1985253.1725\n",
      "Epoch 142/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1704616.2611 - val_loss: 1726725.1317\n",
      "Epoch 143/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1690335.3798 - val_loss: 1634057.0921\n",
      "Epoch 144/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1729995.9857 - val_loss: 1692103.7526\n",
      "Epoch 145/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1697768.4903 - val_loss: 1812484.0332\n",
      "Epoch 146/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1702203.5100 - val_loss: 1871827.4434\n",
      "Epoch 147/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1693565.5470 - val_loss: 1857335.2023\n",
      "Epoch 148/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1675341.4272 - val_loss: 1784405.1206\n",
      "Epoch 149/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1677224.5132 - val_loss: 1666667.8261\n",
      "Epoch 150/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1694238.6314 - val_loss: 1732550.1720\n",
      "Epoch 151/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1675724.5507 - val_loss: 1885377.9902\n",
      "Epoch 152/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1701997.9290 - val_loss: 1687047.0627\n",
      "Epoch 153/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1674563.7381 - val_loss: 1853811.9464\n",
      "Epoch 154/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1674315.0842 - val_loss: 2035644.2329\n",
      "Epoch 155/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1675512.4449 - val_loss: 1737245.6583\n",
      "Epoch 156/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1684377.8868 - val_loss: 1735330.3875\n",
      "Epoch 157/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1664997.6416 - val_loss: 2010903.1726\n",
      "Epoch 158/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1685575.5243 - val_loss: 2130303.4214\n",
      "Epoch 159/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1723496.5359 - val_loss: 1825132.6374\n",
      "Epoch 160/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1661180.0781 - val_loss: 1737832.1929\n",
      "Epoch 161/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1667277.2262 - val_loss: 1828555.7712\n",
      "Epoch 162/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1664693.4482 - val_loss: 1726463.1182\n",
      "Epoch 163/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1663101.8494 - val_loss: 1884432.3518\n",
      "Epoch 164/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1675115.2205 - val_loss: 1763089.5529\n",
      "Epoch 165/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1656163.8524 - val_loss: 1704503.8269\n",
      "Epoch 166/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1658623.1322 - val_loss: 1659694.1270\n",
      "Epoch 167/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1649730.1539 - val_loss: 1771630.9192\n",
      "Epoch 168/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1651847.7625 - val_loss: 1638566.7812\n",
      "Epoch 169/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1646145.4503 - val_loss: 1830082.1932\n",
      "Epoch 170/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1658220.6659 - val_loss: 1896536.0673\n",
      "Epoch 171/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1655441.0359 - val_loss: 1724630.5059\n",
      "Epoch 172/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1647267.4590 - val_loss: 1659162.7452\n",
      "Epoch 173/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1643004.5399 - val_loss: 1720062.9389\n",
      "Epoch 174/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1646842.9287 - val_loss: 1681641.4576\n",
      "Epoch 175/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1629253.1646 - val_loss: 1679879.9705\n",
      "Epoch 176/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1630159.7748 - val_loss: 1701956.3907\n",
      "Epoch 177/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1630490.6717 - val_loss: 1883404.3323\n",
      "Epoch 178/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1620226.1308 - val_loss: 1595146.2802\n",
      "Epoch 179/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1651590.3789 - val_loss: 1797403.0247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1652475.6546 - val_loss: 1593309.3712\n",
      "Epoch 181/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1653249.8773 - val_loss: 1824500.6033\n",
      "Epoch 182/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1646507.3698 - val_loss: 1911028.3127\n",
      "Epoch 183/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1632497.5094 - val_loss: 1646693.7236\n",
      "Epoch 184/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1629393.4721 - val_loss: 1629182.0804\n",
      "Epoch 185/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1641312.8966 - val_loss: 1785763.9633\n",
      "Epoch 186/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1621277.9824 - val_loss: 1725303.3055\n",
      "Epoch 187/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1620595.6526 - val_loss: 1722874.1682\n",
      "Epoch 188/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1641827.0315 - val_loss: 1715735.5350\n",
      "Epoch 189/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1620477.2102 - val_loss: 1795391.3206\n",
      "Epoch 190/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1612348.7489 - val_loss: 1690100.1037\n",
      "Epoch 191/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1603986.9663 - val_loss: 1599224.9945\n",
      "Epoch 192/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1628576.2007 - val_loss: 1938455.4299\n",
      "Epoch 193/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1609886.6222 - val_loss: 1638236.4496\n",
      "Epoch 194/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1612597.6760 - val_loss: 1667333.3378\n",
      "Epoch 195/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1608839.9009 - val_loss: 1983895.3856\n",
      "Epoch 196/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1613872.9129 - val_loss: 1786166.6679\n",
      "Epoch 197/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1598015.0039 - val_loss: 1606941.2230\n",
      "Epoch 198/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1623368.6259 - val_loss: 1934546.5303\n",
      "Epoch 199/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1623050.8400 - val_loss: 1679397.9198\n",
      "Epoch 200/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1602709.2057 - val_loss: 1660737.9514\n",
      "Epoch 201/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1592881.5729 - val_loss: 1653791.0612\n",
      "Epoch 202/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1600224.9818 - val_loss: 1578024.0403\n",
      "Epoch 203/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1615320.8524 - val_loss: 1952943.9322\n",
      "Epoch 204/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1595266.8497 - val_loss: 1877435.4302\n",
      "Epoch 205/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1583878.6108 - val_loss: 1753725.3204\n",
      "Epoch 206/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1571101.4662 - val_loss: 1646023.5147\n",
      "Epoch 207/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1619322.3005 - val_loss: 1741735.9365\n",
      "Epoch 208/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1580975.2533 - val_loss: 1663723.7466\n",
      "Epoch 209/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1586997.6811 - val_loss: 1753133.0968\n",
      "Epoch 210/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1584998.0206 - val_loss: 1939431.0478\n",
      "Epoch 211/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1563514.5685 - val_loss: 2009559.7430\n",
      "Epoch 212/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1603422.9825 - val_loss: 1602247.3433\n",
      "Epoch 213/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1588110.1453 - val_loss: 1940579.2886\n",
      "Epoch 214/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1575975.4852 - val_loss: 1868005.5139\n",
      "Epoch 215/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1589626.6819 - val_loss: 1697104.4443\n",
      "Epoch 216/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1546436.6825 - val_loss: 1636932.9092\n",
      "Epoch 217/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1561261.1212 - val_loss: 1865577.1764\n",
      "Epoch 218/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1569163.7250 - val_loss: 1787761.8116\n",
      "Epoch 219/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1556226.1866 - val_loss: 1593404.5656\n",
      "Epoch 220/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1562445.0748 - val_loss: 1818251.5772\n",
      "Epoch 221/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1567713.3388 - val_loss: 1811718.0324\n",
      "Epoch 222/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1584544.1455 - val_loss: 1670060.2062\n",
      "Epoch 223/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1563844.4871 - val_loss: 1646853.8927\n",
      "Epoch 224/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1555112.3671 - val_loss: 1628497.9458\n",
      "Epoch 225/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1546953.5898 - val_loss: 1900147.9833\n",
      "Epoch 226/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1595723.9629 - val_loss: 1873201.3915\n",
      "Epoch 227/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1542446.1751 - val_loss: 1799407.3441\n",
      "Epoch 228/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1558977.7345 - val_loss: 1688989.0403\n",
      "Epoch 229/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1535072.7125 - val_loss: 1775333.9024\n",
      "Epoch 230/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1529906.9591 - val_loss: 1786290.3313\n",
      "Epoch 231/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1553348.7010 - val_loss: 1798363.1346\n",
      "Epoch 232/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1538832.2552 - val_loss: 2053496.6502\n",
      "Epoch 233/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1578206.0811 - val_loss: 1848295.3488\n",
      "Epoch 234/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1545201.2494 - val_loss: 1820074.9017\n",
      "Epoch 235/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1529326.8694 - val_loss: 1701102.6986\n",
      "Epoch 236/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1529176.4640 - val_loss: 2047280.7534\n",
      "Epoch 237/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1563504.2000 - val_loss: 1679382.6062\n",
      "Epoch 238/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1546723.5235 - val_loss: 1533129.0420\n",
      "Epoch 239/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1563870.6407 - val_loss: 1665870.0995\n",
      "Epoch 240/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1508781.6174 - val_loss: 1690057.0391\n",
      "Epoch 241/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1515727.0599 - val_loss: 1664749.8591\n",
      "Epoch 242/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1518212.9958 - val_loss: 1618046.6979\n",
      "Epoch 243/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1511466.7760 - val_loss: 1734788.9944\n",
      "Epoch 244/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1517974.7423 - val_loss: 1924434.4620\n",
      "Epoch 245/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1517195.5391 - val_loss: 2088857.1132\n",
      "Epoch 246/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1557779.7770 - val_loss: 1718786.4273\n",
      "Epoch 247/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1546440.0344 - val_loss: 1645858.5604\n",
      "Epoch 248/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1524527.8692 - val_loss: 1718272.2882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1497220.8054 - val_loss: 1800108.2248\n",
      "Epoch 250/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1507320.3385 - val_loss: 1850716.5357\n",
      "Epoch 251/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1478253.5927 - val_loss: 1726700.5397\n",
      "Epoch 252/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1485778.2265 - val_loss: 1564347.9387\n",
      "Epoch 253/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1497745.8862 - val_loss: 1706193.7710\n",
      "Epoch 254/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1496633.7746 - val_loss: 1803961.3037\n",
      "Epoch 255/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1496230.3513 - val_loss: 1688707.9704\n",
      "Epoch 256/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1496465.7120 - val_loss: 1774539.0987\n",
      "Epoch 257/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1517102.1573 - val_loss: 1559077.6649\n",
      "Epoch 258/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1545221.0535 - val_loss: 1761778.9805\n",
      "Epoch 259/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1552564.0150 - val_loss: 1643106.8212\n",
      "Epoch 260/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1523150.4275 - val_loss: 1767250.6905\n",
      "Epoch 261/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1498320.7533 - val_loss: 1684614.6521\n",
      "Epoch 262/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1484545.1868 - val_loss: 1585790.7258\n",
      "Epoch 263/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1496257.2388 - val_loss: 1599259.1747\n",
      "Epoch 264/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1528925.5361 - val_loss: 1733610.7244\n",
      "Epoch 265/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1531870.2347 - val_loss: 1753439.9722\n",
      "Epoch 266/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1485110.3066 - val_loss: 1655236.7320\n",
      "Epoch 267/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1474949.1322 - val_loss: 1837383.9031\n",
      "Epoch 268/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1472538.4726 - val_loss: 1777463.3811\n",
      "Epoch 269/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1470022.1839 - val_loss: 1853111.1436\n",
      "Epoch 270/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1476884.0317 - val_loss: 1838539.3490\n",
      "Epoch 271/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1489466.2078 - val_loss: 1861771.2579\n",
      "Epoch 272/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1465885.7281 - val_loss: 1798191.8225\n",
      "Epoch 273/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1475408.2158 - val_loss: 1972482.6014\n",
      "Epoch 274/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1499042.6231 - val_loss: 1500278.3343\n",
      "Epoch 275/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1552426.8008 - val_loss: 1713602.4336\n",
      "Epoch 276/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1460997.7753 - val_loss: 1849965.7763\n",
      "Epoch 277/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1487891.3589 - val_loss: 1684086.6829\n",
      "Epoch 278/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1474735.9126 - val_loss: 1931824.4848\n",
      "Epoch 279/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1506189.3251 - val_loss: 1765580.7287\n",
      "Epoch 280/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1499719.5260 - val_loss: 1566447.9338\n",
      "Epoch 281/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1479239.1891 - val_loss: 1892054.8959\n",
      "Epoch 282/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1452011.9336 - val_loss: 1857618.4565\n",
      "Epoch 283/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1466335.3401 - val_loss: 1717733.8558\n",
      "Epoch 284/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1447210.5773 - val_loss: 1734195.2020\n",
      "Epoch 285/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1488353.3497 - val_loss: 1931791.9179\n",
      "Epoch 286/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1464116.6648 - val_loss: 1824415.7938\n",
      "Epoch 287/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1447802.3285 - val_loss: 1809580.2257\n",
      "Epoch 288/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1455661.6934 - val_loss: 1696761.7047\n",
      "Epoch 289/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1466766.2595 - val_loss: 1518194.8400\n",
      "Epoch 290/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1481927.0021 - val_loss: 1841409.0686\n",
      "Epoch 291/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1450593.9167 - val_loss: 1959985.4241\n",
      "Epoch 292/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1485572.9064 - val_loss: 1524214.7894\n",
      "Epoch 293/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1478556.2323 - val_loss: 1877152.8819\n",
      "Epoch 294/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1466132.1097 - val_loss: 1962241.9751\n",
      "Epoch 295/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1471958.7347 - val_loss: 1514575.1922\n",
      "Epoch 296/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1499109.3928 - val_loss: 1881979.5554\n",
      "Epoch 297/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1510049.4421 - val_loss: 1934923.7695\n",
      "Epoch 298/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1476160.6637 - val_loss: 1891030.5391\n",
      "Epoch 299/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1466099.1858 - val_loss: 1712090.6056\n",
      "Epoch 300/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1448617.5250 - val_loss: 1814010.7367\n",
      "Epoch 301/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1447585.9778 - val_loss: 1768916.3666\n",
      "Epoch 302/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1475076.7594 - val_loss: 1749925.0237\n",
      "Epoch 303/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1438174.2637 - val_loss: 1651111.9238\n",
      "Epoch 304/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1447930.1158 - val_loss: 1910621.4991\n",
      "Epoch 305/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1446884.8754 - val_loss: 1584034.0364\n",
      "Epoch 306/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1456511.0340 - val_loss: 1956166.6729\n",
      "Epoch 307/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1458177.1784 - val_loss: 1657650.1409\n",
      "Epoch 308/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1470367.4940 - val_loss: 1899788.6959\n",
      "Epoch 309/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1448081.7689 - val_loss: 1620958.1211\n",
      "Epoch 310/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1438989.1928 - val_loss: 2014908.8308\n",
      "Epoch 311/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1445823.4751 - val_loss: 1806494.9105\n",
      "Epoch 312/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1435931.6769 - val_loss: 1737903.8788\n",
      "Epoch 313/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1439954.1973 - val_loss: 2093606.6113\n",
      "Epoch 314/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1451985.1553 - val_loss: 1638368.6542\n",
      "Epoch 315/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1446762.6851 - val_loss: 1922989.2359\n",
      "Epoch 316/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1456809.5050 - val_loss: 1787815.6383\n",
      "Epoch 317/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1445042.4584 - val_loss: 1675416.8143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1436816.3960 - val_loss: 1695434.3046\n",
      "Epoch 319/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1433588.5275 - val_loss: 1760967.6780\n",
      "Epoch 320/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1436970.5758 - val_loss: 1939636.5546\n",
      "Epoch 321/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1441089.1762 - val_loss: 1883283.8131\n",
      "Epoch 322/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1461992.2262 - val_loss: 1904651.1448\n",
      "Epoch 323/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1432778.7487 - val_loss: 1876399.0720\n",
      "Epoch 324/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1438754.7512 - val_loss: 1825613.2696\n",
      "Epoch 325/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1452036.7754 - val_loss: 1937801.3859\n",
      "Epoch 326/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1482004.8013 - val_loss: 1743269.1728\n",
      "Epoch 327/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1493890.0046 - val_loss: 1467776.9311\n",
      "Epoch 328/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1531475.6273 - val_loss: 1738865.2018\n",
      "Epoch 329/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1427722.2773 - val_loss: 1755834.4517\n",
      "Epoch 330/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1427541.0439 - val_loss: 1590446.6920\n",
      "Epoch 331/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1442560.7082 - val_loss: 2082161.1614\n",
      "Epoch 332/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1483139.5539 - val_loss: 1898210.7016\n",
      "Epoch 333/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1431205.6657 - val_loss: 1668905.1396\n",
      "Epoch 334/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1423901.3745 - val_loss: 1702064.5294\n",
      "Epoch 335/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1444812.9091 - val_loss: 1666194.5156\n",
      "Epoch 336/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1428676.7106 - val_loss: 1776326.9848\n",
      "Epoch 337/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1437917.4927 - val_loss: 1882225.1123\n",
      "Epoch 338/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1421691.9930 - val_loss: 1622887.1438\n",
      "Epoch 339/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1413203.1070 - val_loss: 2074174.5862\n",
      "Epoch 340/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1465782.7880 - val_loss: 1755753.8274\n",
      "Epoch 341/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1425982.3167 - val_loss: 2084075.8084\n",
      "Epoch 342/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1502916.1107 - val_loss: 1838945.5949\n",
      "Epoch 343/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1443751.8566 - val_loss: 1587376.5132\n",
      "Epoch 344/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1464902.2584 - val_loss: 1630581.4416\n",
      "Epoch 345/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1422185.4504 - val_loss: 2024663.2144\n",
      "Epoch 346/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1477648.7678 - val_loss: 2033580.3371\n",
      "Epoch 347/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1469817.7390 - val_loss: 2207632.7674\n",
      "Epoch 348/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1487372.3983 - val_loss: 1912879.7326\n",
      "Epoch 349/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1426160.8593 - val_loss: 1943949.0974\n",
      "Epoch 350/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1439823.9612 - val_loss: 1656441.2908\n",
      "Epoch 351/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1426035.9917 - val_loss: 1736587.8847\n",
      "Epoch 352/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1405898.8636 - val_loss: 1702626.5230\n",
      "Epoch 353/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1420014.7784 - val_loss: 1801213.4920\n",
      "Epoch 354/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1422950.0849 - val_loss: 1610357.2520\n",
      "Epoch 355/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1414751.8976 - val_loss: 1944205.5694\n",
      "Epoch 356/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1442109.2416 - val_loss: 1766119.2353\n",
      "Epoch 357/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1419011.4945 - val_loss: 1587794.3907\n",
      "Epoch 358/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1419759.3100 - val_loss: 1801471.4334\n",
      "Epoch 359/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1447752.7507 - val_loss: 1886117.3340\n",
      "Epoch 360/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1423056.8833 - val_loss: 1746221.2148\n",
      "Epoch 361/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1440316.6159 - val_loss: 1552839.2543\n",
      "Epoch 362/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1436847.4446 - val_loss: 1978529.3813\n",
      "Epoch 363/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1435092.4496 - val_loss: 1863449.4611\n",
      "Epoch 364/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1456214.9377 - val_loss: 1510271.9885\n",
      "Epoch 365/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1457295.3772 - val_loss: 1537878.6656\n",
      "Epoch 366/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1453446.9634 - val_loss: 1930455.9774\n",
      "Epoch 367/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1448565.0041 - val_loss: 1774781.6575\n",
      "Epoch 368/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1433510.6213 - val_loss: 1671633.2899\n",
      "Epoch 369/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1420528.2744 - val_loss: 1789854.5408\n",
      "Epoch 370/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1413279.9883 - val_loss: 1636330.2090\n",
      "Epoch 371/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1417832.0859 - val_loss: 1804339.2928\n",
      "Epoch 372/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1406984.7240 - val_loss: 1779367.1686\n",
      "Epoch 373/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1424270.7675 - val_loss: 1881922.6990\n",
      "Epoch 374/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1408585.5272 - val_loss: 2023433.3612\n",
      "Epoch 375/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1421844.9583 - val_loss: 1806663.3113\n",
      "Epoch 376/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1424745.6423 - val_loss: 2018036.9149\n",
      "Epoch 377/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1460271.5575 - val_loss: 1918360.5937\n",
      "Epoch 378/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1427696.0215 - val_loss: 1953305.1057\n",
      "Epoch 379/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1413328.8321 - val_loss: 1474688.2385\n",
      "Epoch 380/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1446256.2404 - val_loss: 1756947.5852\n",
      "Epoch 381/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1414134.7881 - val_loss: 1715556.8008\n",
      "Epoch 382/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1413185.0794 - val_loss: 1645260.1637\n",
      "Epoch 383/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1407165.7102 - val_loss: 1783448.0220\n",
      "Epoch 384/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1409045.2713 - val_loss: 2013853.4444\n",
      "Epoch 385/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1448281.9946 - val_loss: 1839247.1672\n",
      "Epoch 386/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1409809.9512 - val_loss: 1892451.7319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1419262.0293 - val_loss: 1804486.1923\n",
      "Epoch 388/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1401035.6736 - val_loss: 1709794.8926\n",
      "Epoch 389/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1408796.3093 - val_loss: 1882515.7502\n",
      "Epoch 390/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1406107.4726 - val_loss: 1656460.6277\n",
      "Epoch 391/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1428817.8290 - val_loss: 1964174.7870\n",
      "Epoch 392/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1408206.4824 - val_loss: 1882328.6871\n",
      "Epoch 393/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1397574.4021 - val_loss: 1804272.9815\n",
      "Epoch 394/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1404200.9420 - val_loss: 1827394.5582\n",
      "Epoch 395/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1436916.2596 - val_loss: 1569665.5673\n",
      "Epoch 396/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1416989.9955 - val_loss: 1762887.1972\n",
      "Epoch 397/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1408683.9403 - val_loss: 1623698.1631\n",
      "Epoch 398/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1410610.7084 - val_loss: 1981026.6625\n",
      "Epoch 399/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1448151.5780 - val_loss: 2011436.7351\n",
      "Epoch 400/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1411314.5442 - val_loss: 1993755.0099\n",
      "Epoch 401/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1408636.5238 - val_loss: 1844680.4029\n",
      "Epoch 402/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1421007.3379 - val_loss: 2074822.0668\n",
      "Epoch 403/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1413612.2053 - val_loss: 1841914.0846\n",
      "Epoch 404/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1397331.2285 - val_loss: 1627417.1873\n",
      "Epoch 405/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1421187.8787 - val_loss: 1589501.2294\n",
      "Epoch 406/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1409460.2161 - val_loss: 1558946.1727\n",
      "Epoch 407/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1421534.1543 - val_loss: 1689055.0917\n",
      "Epoch 408/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1389145.3499 - val_loss: 1829871.6918\n",
      "Epoch 409/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1401571.2113 - val_loss: 1686250.6306\n",
      "Epoch 410/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1408032.3882 - val_loss: 1633975.0652\n",
      "Epoch 411/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1416283.4998 - val_loss: 1893676.6955\n",
      "Epoch 412/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1408479.2528 - val_loss: 1693654.8424\n",
      "Epoch 413/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1414208.3385 - val_loss: 1785588.8259\n",
      "Epoch 414/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1407766.2521 - val_loss: 1679548.4640\n",
      "Epoch 415/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1416228.4052 - val_loss: 1805022.0969\n",
      "Epoch 416/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1399525.7140 - val_loss: 1751460.6657\n",
      "Epoch 417/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1398699.9473 - val_loss: 1833924.3720\n",
      "Epoch 418/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1415125.7361 - val_loss: 1778695.9271\n",
      "Epoch 419/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1404245.4413 - val_loss: 1753786.0340\n",
      "Epoch 420/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1389764.6289 - val_loss: 1679632.4225\n",
      "Epoch 421/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1407071.6736 - val_loss: 1681938.3627\n",
      "Epoch 422/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1410148.5752 - val_loss: 1823155.3530\n",
      "Epoch 423/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1400527.3496 - val_loss: 1747550.5597\n",
      "Epoch 424/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1408449.4988 - val_loss: 1587882.6384\n",
      "Epoch 425/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1409801.5723 - val_loss: 1741664.5586\n",
      "Epoch 426/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1395830.4284 - val_loss: 1914940.2065\n",
      "Epoch 427/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1409633.7634 - val_loss: 1974340.1742\n",
      "Epoch 428/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1417060.6526 - val_loss: 1470309.4151\n",
      "Epoch 429/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1419567.1453 - val_loss: 1833614.1108\n",
      "Epoch 430/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1427838.6112 - val_loss: 1816557.4493\n",
      "Epoch 431/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1387277.1424 - val_loss: 1696036.6448\n",
      "Epoch 432/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1389997.4419 - val_loss: 1928222.0726\n",
      "Epoch 433/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1393697.8520 - val_loss: 1721722.0365\n",
      "Epoch 434/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1394302.5357 - val_loss: 1766294.3655\n",
      "Epoch 435/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1417831.3929 - val_loss: 2031487.6556\n",
      "Epoch 436/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1403839.9138 - val_loss: 1685453.9504\n",
      "Epoch 437/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1397930.0479 - val_loss: 1826872.8671\n",
      "Epoch 438/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1394046.0903 - val_loss: 1651076.3423\n",
      "Epoch 439/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1406821.5575 - val_loss: 2023181.6988\n",
      "Epoch 440/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1413984.1364 - val_loss: 1553248.1314\n",
      "Epoch 441/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1398304.5120 - val_loss: 1815296.5474\n",
      "Epoch 442/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1402744.9791 - val_loss: 1828575.8722\n",
      "Epoch 443/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1429807.5298 - val_loss: 1584502.4724\n",
      "Epoch 444/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1407194.1417 - val_loss: 1878782.9973\n",
      "Epoch 445/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1389411.8690 - val_loss: 1789422.6725\n",
      "Epoch 446/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1391888.9193 - val_loss: 1930299.3634\n",
      "Epoch 447/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1409583.7431 - val_loss: 1826926.2767\n",
      "Epoch 448/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1405195.1350 - val_loss: 1454880.0582\n",
      "Epoch 449/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1495856.1036 - val_loss: 1526087.1024\n",
      "Epoch 450/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1433985.6538 - val_loss: 1614801.1698\n",
      "Epoch 451/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1388370.1281 - val_loss: 1653331.2742\n",
      "Epoch 452/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1378512.5229 - val_loss: 1733689.0444\n",
      "Epoch 453/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1386640.2326 - val_loss: 1908624.6414\n",
      "Epoch 454/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1392558.8378 - val_loss: 1533176.7659\n",
      "Epoch 455/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1427657.5133 - val_loss: 1640920.4637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1395324.9288 - val_loss: 1491654.6265\n",
      "Epoch 457/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1415504.4509 - val_loss: 1588494.6801\n",
      "Epoch 458/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1394517.0884 - val_loss: 1966656.1740\n",
      "Epoch 459/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1393509.2560 - val_loss: 1764801.4511\n",
      "Epoch 460/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1387804.1649 - val_loss: 1793622.1539\n",
      "Epoch 461/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1386615.5044 - val_loss: 2150967.1366\n",
      "Epoch 462/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1425393.6057 - val_loss: 1702770.2829\n",
      "Epoch 463/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1400574.3973 - val_loss: 1904429.4307\n",
      "Epoch 464/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1400975.3849 - val_loss: 1865452.2174\n",
      "Epoch 465/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1414129.7896 - val_loss: 1906789.2759\n",
      "Epoch 466/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1409161.6433 - val_loss: 1840857.0065\n",
      "Epoch 467/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1384500.8482 - val_loss: 1828726.2289\n",
      "Epoch 468/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1382333.9485 - val_loss: 1709586.4497\n",
      "Epoch 469/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1377731.6991 - val_loss: 1702336.3528\n",
      "Epoch 470/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1391075.9411 - val_loss: 1560095.0423\n",
      "Epoch 471/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1430546.0582 - val_loss: 1752889.9873\n",
      "Epoch 472/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1387584.3886 - val_loss: 2015330.7309\n",
      "Epoch 473/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1401569.7394 - val_loss: 1649873.5316\n",
      "Epoch 474/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1370974.7454 - val_loss: 1553765.5310\n",
      "Epoch 475/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1399661.8581 - val_loss: 1931830.0630\n",
      "Epoch 476/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1390064.8382 - val_loss: 1885155.0933\n",
      "Epoch 477/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1394718.9673 - val_loss: 1550153.4751\n",
      "Epoch 478/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1413134.8392 - val_loss: 1800422.8282\n",
      "Epoch 479/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1378674.9341 - val_loss: 1630436.0234\n",
      "Epoch 480/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1371216.0068 - val_loss: 1665217.9127\n",
      "Epoch 481/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1384966.1796 - val_loss: 1620977.7106\n",
      "Epoch 482/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1383367.5030 - val_loss: 1892459.8770\n",
      "Epoch 483/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1381827.5568 - val_loss: 1531932.9607\n",
      "Epoch 484/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1442170.5705 - val_loss: 1777685.9096\n",
      "Epoch 485/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1369957.8651 - val_loss: 1538486.2005\n",
      "Epoch 486/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1396439.1305 - val_loss: 1966653.0271\n",
      "Epoch 487/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1392272.2383 - val_loss: 1915412.6499\n",
      "Epoch 488/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1405344.4958 - val_loss: 1825935.9791\n",
      "Epoch 489/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1382169.1449 - val_loss: 1851160.5571\n",
      "Epoch 490/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1375022.0863 - val_loss: 1806439.4503\n",
      "Epoch 491/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1387387.6042 - val_loss: 2008344.1232\n",
      "Epoch 492/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1417224.2315 - val_loss: 1497799.8017\n",
      "Epoch 493/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1385185.5498 - val_loss: 1861041.6391\n",
      "Epoch 494/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1367161.0027 - val_loss: 1566237.0265\n",
      "Epoch 495/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1375933.8650 - val_loss: 1815757.0985\n",
      "Epoch 496/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1382481.7678 - val_loss: 1572500.6040\n",
      "Epoch 497/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1380781.7974 - val_loss: 2061367.5561\n",
      "Epoch 498/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1394581.1181 - val_loss: 1629722.3143\n",
      "Epoch 499/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1378174.3301 - val_loss: 1775889.3831\n",
      "Epoch 500/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1370063.3568 - val_loss: 1815631.6762\n",
      "Epoch 501/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1366399.5725 - val_loss: 1737289.1663\n",
      "Epoch 502/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1378360.7466 - val_loss: 1696614.9695\n",
      "Epoch 503/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1370194.1187 - val_loss: 1945513.3982\n",
      "Epoch 504/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1406882.1392 - val_loss: 1624618.6127\n",
      "Epoch 505/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1379358.9297 - val_loss: 1855223.4947\n",
      "Epoch 506/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1389416.7605 - val_loss: 1594928.0263\n",
      "Epoch 507/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1369534.8796 - val_loss: 1729938.0009\n",
      "Epoch 508/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1365971.2616 - val_loss: 1882638.7133\n",
      "Epoch 509/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1381833.6129 - val_loss: 1912535.6389\n",
      "Epoch 510/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1365348.0766 - val_loss: 1548837.0159\n",
      "Epoch 511/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1413290.9404 - val_loss: 1773678.1072\n",
      "Epoch 512/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1382803.8131 - val_loss: 1844081.2521\n",
      "Epoch 513/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1385194.6208 - val_loss: 1877690.6732\n",
      "Epoch 514/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1375086.0186 - val_loss: 1708496.6442\n",
      "Epoch 515/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1387179.8376 - val_loss: 1608762.7669\n",
      "Epoch 516/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1401463.7882 - val_loss: 1679932.2455\n",
      "Epoch 517/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1376830.8630 - val_loss: 1648833.1952\n",
      "Epoch 518/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1395267.8153 - val_loss: 1783724.4414\n",
      "Epoch 519/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1366069.1671 - val_loss: 1554146.8821\n",
      "Epoch 520/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1375016.5338 - val_loss: 2003977.2495\n",
      "Epoch 521/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1394799.8893 - val_loss: 1571034.5374\n",
      "Epoch 522/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1377547.5259 - val_loss: 1649846.5440\n",
      "Epoch 523/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1388906.3095 - val_loss: 1799199.8600\n",
      "Epoch 524/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1392512.0192 - val_loss: 1627562.7455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 525/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1405876.4153 - val_loss: 1814592.6084\n",
      "Epoch 526/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1367900.4207 - val_loss: 1687642.6187\n",
      "Epoch 527/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1386394.0473 - val_loss: 1574014.4148\n",
      "Epoch 528/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1359674.5712 - val_loss: 1933475.5902\n",
      "Epoch 529/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1380919.8721 - val_loss: 1617991.3064\n",
      "Epoch 530/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1416139.6516 - val_loss: 1631357.1600\n",
      "Epoch 531/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1395855.4126 - val_loss: 1860074.3481\n",
      "Epoch 532/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1381573.4418 - val_loss: 1779041.7634\n",
      "Epoch 533/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1367904.6940 - val_loss: 1881187.3998\n",
      "Epoch 534/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1376320.7599 - val_loss: 1942547.6843\n",
      "Epoch 535/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1370524.8387 - val_loss: 1830453.4742\n",
      "Epoch 536/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1381968.4471 - val_loss: 1822240.8254\n",
      "Epoch 537/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1382594.7206 - val_loss: 1817042.5037\n",
      "Epoch 538/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1377236.0375 - val_loss: 1475769.8067\n",
      "Epoch 539/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1416892.9297 - val_loss: 1806053.6588\n",
      "Epoch 540/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1370023.0548 - val_loss: 1795152.9392\n",
      "Epoch 541/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1361275.6768 - val_loss: 1498310.6364\n",
      "Epoch 542/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1381690.5227 - val_loss: 1594142.3802\n",
      "Epoch 543/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1370221.3240 - val_loss: 1670834.1304\n",
      "Epoch 544/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1370365.2538 - val_loss: 1857875.0496\n",
      "Epoch 545/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1374497.1831 - val_loss: 1626710.8563\n",
      "Epoch 546/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1385847.2261 - val_loss: 1762110.8553\n",
      "Epoch 547/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1350623.5498 - val_loss: 2068590.4612\n",
      "Epoch 548/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1373350.9202 - val_loss: 1690245.0532\n",
      "Epoch 549/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1365910.1296 - val_loss: 1647400.1313\n",
      "Epoch 550/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1380218.9878 - val_loss: 1760047.2923\n",
      "Epoch 551/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1379697.7624 - val_loss: 1939420.7181\n",
      "Epoch 552/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1400562.4954 - val_loss: 1659532.9780\n",
      "Epoch 553/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1370534.2798 - val_loss: 1890500.9682\n",
      "Epoch 554/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1412002.3550 - val_loss: 1838222.3271\n",
      "Epoch 555/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1392090.9755 - val_loss: 2016691.1573\n",
      "Epoch 556/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1392012.0081 - val_loss: 1849650.3470\n",
      "Epoch 557/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1383347.4481 - val_loss: 1851270.1222\n",
      "Epoch 558/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1366765.6727 - val_loss: 1884655.5865\n",
      "Epoch 559/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1369931.7594 - val_loss: 1818668.9775\n",
      "Epoch 560/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1373988.4903 - val_loss: 1751401.7738\n",
      "Epoch 561/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1365978.7252 - val_loss: 1760472.3776\n",
      "Epoch 562/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1368274.2907 - val_loss: 1684826.0854\n",
      "Epoch 563/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1363698.5586 - val_loss: 1618587.9361\n",
      "Epoch 564/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1404064.4659 - val_loss: 1604444.9170\n",
      "Epoch 565/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1375182.7431 - val_loss: 1500310.2611\n",
      "Epoch 566/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1405667.5424 - val_loss: 1952773.8319\n",
      "Epoch 567/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1375158.4568 - val_loss: 1727063.0194\n",
      "Epoch 568/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1358765.1041 - val_loss: 1494433.7007\n",
      "Epoch 569/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1408746.6088 - val_loss: 2111789.5669\n",
      "Epoch 570/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1433673.8439 - val_loss: 1898177.7285\n",
      "Epoch 571/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1360772.3843 - val_loss: 1811817.6040\n",
      "Epoch 572/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1363770.4974 - val_loss: 1670929.0009\n",
      "Epoch 573/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1364335.7211 - val_loss: 1724685.4351\n",
      "Epoch 574/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1373809.9256 - val_loss: 1706254.4471\n",
      "Epoch 575/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1363078.8794 - val_loss: 1696490.1492\n",
      "Epoch 576/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1369253.2457 - val_loss: 1707015.7043\n",
      "Epoch 577/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1354491.6076 - val_loss: 1719763.3680\n",
      "Epoch 578/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1391291.1164 - val_loss: 1580588.8956\n",
      "Epoch 579/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1353484.5737 - val_loss: 1656441.7158\n",
      "Epoch 580/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1359377.5611 - val_loss: 1862575.2178\n",
      "Epoch 581/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1368143.6510 - val_loss: 1811722.7146\n",
      "Epoch 582/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1353492.8073 - val_loss: 1804810.9189\n",
      "Epoch 583/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1366566.5680 - val_loss: 1711689.5575\n",
      "Epoch 584/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1361821.3033 - val_loss: 1849250.6302\n",
      "Epoch 585/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1379795.3791 - val_loss: 1639060.9490\n",
      "Epoch 586/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1399415.2957 - val_loss: 1679511.2824\n",
      "Epoch 587/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1389640.9154 - val_loss: 1691222.4789\n",
      "Epoch 588/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1388489.5243 - val_loss: 1681269.7365\n",
      "Epoch 589/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1345362.5200 - val_loss: 1673968.5312\n",
      "Epoch 590/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1350873.2398 - val_loss: 1665730.1061\n",
      "Epoch 591/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1366363.0428 - val_loss: 1587662.7663\n",
      "Epoch 592/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1389361.6472 - val_loss: 1457810.6899\n",
      "Epoch 593/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1413659.7168 - val_loss: 1940686.0183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 594/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1366619.7359 - val_loss: 1869858.4619\n",
      "Epoch 595/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1373841.4799 - val_loss: 1787798.9538\n",
      "Epoch 596/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1350141.8233 - val_loss: 1603536.8313\n",
      "Epoch 597/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1383402.2822 - val_loss: 1528491.4056\n",
      "Epoch 598/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1406899.9633 - val_loss: 1600876.0182\n",
      "Epoch 599/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1361017.7369 - val_loss: 1924523.2514\n",
      "Epoch 600/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1352372.4134 - val_loss: 2021970.0213\n",
      "Train on 14390 samples, validate on 1599 samples\n",
      "Epoch 1/600\n",
      "14390/14390 [==============================] - 0s 22us/step - loss: 7087556.6560 - val_loss: 7251634.6338\n",
      "Epoch 2/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 7078759.1334 - val_loss: 7188014.9196\n",
      "Epoch 3/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 5744040.9605 - val_loss: 3123189.7578\n",
      "Epoch 4/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2789417.6222 - val_loss: 2718630.8232\n",
      "Epoch 5/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2610755.8011 - val_loss: 2705264.1304\n",
      "Epoch 6/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2599471.2116 - val_loss: 2701650.3632\n",
      "Epoch 7/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2597536.3110 - val_loss: 2702841.4148\n",
      "Epoch 8/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2592891.2153 - val_loss: 2700096.0124\n",
      "Epoch 9/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2591727.7605 - val_loss: 2697806.6249\n",
      "Epoch 10/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2586288.9265 - val_loss: 2698392.9107\n",
      "Epoch 11/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2588130.2309 - val_loss: 2692742.4833\n",
      "Epoch 12/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2583883.5101 - val_loss: 2690466.0604\n",
      "Epoch 13/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2582887.7921 - val_loss: 2687739.1612\n",
      "Epoch 14/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2574580.0692 - val_loss: 2688167.9705\n",
      "Epoch 15/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2577016.3935 - val_loss: 2683738.2953\n",
      "Epoch 16/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2574166.8213 - val_loss: 2681592.8438\n",
      "Epoch 17/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2572098.5181 - val_loss: 2692588.0614\n",
      "Epoch 18/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2583986.2431 - val_loss: 2680807.2068\n",
      "Epoch 19/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2571228.4905 - val_loss: 2673014.6726\n",
      "Epoch 20/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2563898.4761 - val_loss: 2671275.1374\n",
      "Epoch 21/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2564421.7704 - val_loss: 2669389.7133\n",
      "Epoch 22/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2566042.9280 - val_loss: 2664549.7500\n",
      "Epoch 23/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2554618.6014 - val_loss: 2663097.9187\n",
      "Epoch 24/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2550988.7214 - val_loss: 2664879.5524\n",
      "Epoch 25/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2547858.5861 - val_loss: 2657024.1782\n",
      "Epoch 26/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2544653.2883 - val_loss: 2652580.2402\n",
      "Epoch 27/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2539755.4305 - val_loss: 2649652.8760\n",
      "Epoch 28/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2537357.0559 - val_loss: 2645370.8164\n",
      "Epoch 29/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2532429.7886 - val_loss: 2644035.1640\n",
      "Epoch 30/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2526457.4042 - val_loss: 2636094.0821\n",
      "Epoch 31/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2523959.7367 - val_loss: 2644171.3196\n",
      "Epoch 32/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2520706.4901 - val_loss: 2623508.5405\n",
      "Epoch 33/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2509367.6606 - val_loss: 2615847.2150\n",
      "Epoch 34/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2499597.5981 - val_loss: 2605658.2899\n",
      "Epoch 35/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2491349.8255 - val_loss: 2590976.6528\n",
      "Epoch 36/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2483370.8990 - val_loss: 2594388.4603\n",
      "Epoch 37/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2483158.5631 - val_loss: 2572631.4911\n",
      "Epoch 38/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2461634.6285 - val_loss: 2546235.2517\n",
      "Epoch 39/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2441019.7430 - val_loss: 2530189.9509\n",
      "Epoch 40/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2424546.7553 - val_loss: 2507508.7412\n",
      "Epoch 41/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2407298.3441 - val_loss: 2484348.9975\n",
      "Epoch 42/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2389494.1966 - val_loss: 2447281.4900\n",
      "Epoch 43/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2367112.3211 - val_loss: 2422782.4412\n",
      "Epoch 44/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2345968.5179 - val_loss: 2391790.4099\n",
      "Epoch 45/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2311897.3906 - val_loss: 2365137.2214\n",
      "Epoch 46/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2287420.5798 - val_loss: 2326285.6052\n",
      "Epoch 47/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2260084.7050 - val_loss: 2292752.7317\n",
      "Epoch 48/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2240034.4298 - val_loss: 2273929.2597\n",
      "Epoch 49/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2215338.6231 - val_loss: 2237093.1867\n",
      "Epoch 50/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2212780.7823 - val_loss: 2197368.4848\n",
      "Epoch 51/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2173319.9174 - val_loss: 2157625.1225\n",
      "Epoch 52/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2161835.6736 - val_loss: 2135136.3287\n",
      "Epoch 53/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2128914.5779 - val_loss: 2102572.6383\n",
      "Epoch 54/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2126430.5750 - val_loss: 2135917.0938\n",
      "Epoch 55/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2110740.8579 - val_loss: 2178553.0722\n",
      "Epoch 56/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2089869.4145 - val_loss: 2072633.6130\n",
      "Epoch 57/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2080770.2629 - val_loss: 2069820.3397\n",
      "Epoch 58/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2057911.7107 - val_loss: 2070738.0715\n",
      "Epoch 59/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2060928.5671 - val_loss: 2170301.7616\n",
      "Epoch 60/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2049372.2307 - val_loss: 2065705.0156\n",
      "Epoch 61/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2013216.9317 - val_loss: 2023817.0668\n",
      "Epoch 62/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2011282.2379 - val_loss: 2021663.6646\n",
      "Epoch 63/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14390/14390 [==============================] - 0s 6us/step - loss: 1992320.1103 - val_loss: 2065520.2066\n",
      "Epoch 64/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2000947.0595 - val_loss: 2065479.6342\n",
      "Epoch 65/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1984797.9755 - val_loss: 1905314.9595\n",
      "Epoch 66/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1988507.3511 - val_loss: 1897418.5945\n",
      "Epoch 67/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1961583.9340 - val_loss: 1913159.6152\n",
      "Epoch 68/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1950756.2430 - val_loss: 1936490.2122\n",
      "Epoch 69/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1944948.0972 - val_loss: 1879849.9219\n",
      "Epoch 70/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1941485.8795 - val_loss: 1965524.7352\n",
      "Epoch 71/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1927241.7636 - val_loss: 1981517.2303\n",
      "Epoch 72/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1920321.0005 - val_loss: 1907185.6875\n",
      "Epoch 73/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1927987.2699 - val_loss: 1916010.9651\n",
      "Epoch 74/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1904644.7522 - val_loss: 1904119.0955\n",
      "Epoch 75/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1901445.0300 - val_loss: 1833057.8691\n",
      "Epoch 76/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1914430.4763 - val_loss: 1863350.7960\n",
      "Epoch 77/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1891977.3319 - val_loss: 1834578.0873\n",
      "Epoch 78/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1874027.0389 - val_loss: 1817926.7121\n",
      "Epoch 79/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1887100.3240 - val_loss: 1977539.7727\n",
      "Epoch 80/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1865342.8447 - val_loss: 1885321.8229\n",
      "Epoch 81/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1856576.5938 - val_loss: 1898418.0786\n",
      "Epoch 82/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1879227.8027 - val_loss: 1792592.4982\n",
      "Epoch 83/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1868365.0071 - val_loss: 1961871.3416\n",
      "Epoch 84/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1865838.0486 - val_loss: 1910605.2276\n",
      "Epoch 85/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1845448.8052 - val_loss: 1865986.0512\n",
      "Epoch 86/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1846015.5320 - val_loss: 2006559.1869\n",
      "Epoch 87/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1863024.5224 - val_loss: 1878768.6955\n",
      "Epoch 88/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1854520.7772 - val_loss: 1767511.3562\n",
      "Epoch 89/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1845693.1827 - val_loss: 1771810.4517\n",
      "Epoch 90/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1864715.0218 - val_loss: 1886629.2267\n",
      "Epoch 91/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1854437.9145 - val_loss: 1879771.7273\n",
      "Epoch 92/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1838024.8044 - val_loss: 1895056.4694\n",
      "Epoch 93/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1823590.3851 - val_loss: 1967384.3839\n",
      "Epoch 94/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1828855.3541 - val_loss: 1916295.4483\n",
      "Epoch 95/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1831369.7007 - val_loss: 1803459.0715\n",
      "Epoch 96/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1833623.6320 - val_loss: 1797513.7929\n",
      "Epoch 97/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1822182.4279 - val_loss: 1936981.6305\n",
      "Epoch 98/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1793595.3515 - val_loss: 1869037.8306\n",
      "Epoch 99/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1804538.8641 - val_loss: 1857841.4226\n",
      "Epoch 100/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1813578.0758 - val_loss: 1857676.8727\n",
      "Epoch 101/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1796313.7847 - val_loss: 2015090.6504\n",
      "Epoch 102/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1822001.0232 - val_loss: 1788204.3087\n",
      "Epoch 103/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1810363.2556 - val_loss: 1992928.9895\n",
      "Epoch 104/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1807396.3517 - val_loss: 1719148.7575\n",
      "Epoch 105/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1815619.9763 - val_loss: 1906711.9254\n",
      "Epoch 106/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1820207.4384 - val_loss: 1755189.0341\n",
      "Epoch 107/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1777673.9464 - val_loss: 1807668.2130\n",
      "Epoch 108/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1774662.7415 - val_loss: 1824903.1159\n",
      "Epoch 109/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1795793.3593 - val_loss: 1719623.1621\n",
      "Epoch 110/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1798812.9356 - val_loss: 1805813.9980\n",
      "Epoch 111/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1799723.6087 - val_loss: 1829045.2641\n",
      "Epoch 112/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1789830.1950 - val_loss: 1815976.4746\n",
      "Epoch 113/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1786393.0029 - val_loss: 1841511.5951\n",
      "Epoch 114/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1794592.5617 - val_loss: 1739192.0245\n",
      "Epoch 115/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1793019.0317 - val_loss: 1714931.3727\n",
      "Epoch 116/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1789956.2836 - val_loss: 1837469.4880\n",
      "Epoch 117/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1767559.1582 - val_loss: 1877397.0815\n",
      "Epoch 118/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1785221.0857 - val_loss: 1911275.2685\n",
      "Epoch 119/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1780001.1618 - val_loss: 1755171.7300\n",
      "Epoch 120/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1773832.4026 - val_loss: 1888160.3083\n",
      "Epoch 121/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1747261.0880 - val_loss: 1860035.7891\n",
      "Epoch 122/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1787717.5704 - val_loss: 1727064.0973\n",
      "Epoch 123/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1780752.9133 - val_loss: 1896418.2958\n",
      "Epoch 124/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1763997.3958 - val_loss: 1901988.4264\n",
      "Epoch 125/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1766929.1236 - val_loss: 1887140.7144\n",
      "Epoch 126/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1783996.1095 - val_loss: 1883186.2737\n",
      "Epoch 127/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1763552.6937 - val_loss: 1814727.2221\n",
      "Epoch 128/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1750665.5953 - val_loss: 1885051.1478\n",
      "Epoch 129/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1764291.7292 - val_loss: 1919693.6514\n",
      "Epoch 130/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1798402.4069 - val_loss: 1841966.5457\n",
      "Epoch 131/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1773388.4997 - val_loss: 1866569.1187\n",
      "Epoch 132/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1767660.1169 - val_loss: 1681431.6095\n",
      "Epoch 133/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1752302.3419 - val_loss: 1847302.7143\n",
      "Epoch 134/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1749119.1549 - val_loss: 1959405.4491\n",
      "Epoch 135/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1754015.5655 - val_loss: 1903402.7896\n",
      "Epoch 136/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1742065.1853 - val_loss: 1733489.0106\n",
      "Epoch 137/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1721734.8042 - val_loss: 1777976.9167\n",
      "Epoch 138/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1746093.4581 - val_loss: 1810857.5344\n",
      "Epoch 139/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1734575.1949 - val_loss: 1794330.3356\n",
      "Epoch 140/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1737315.6666 - val_loss: 1783350.6864\n",
      "Epoch 141/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1743098.3706 - val_loss: 1787134.9052\n",
      "Epoch 142/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1741163.0255 - val_loss: 1743256.9639\n",
      "Epoch 143/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1742906.8009 - val_loss: 1792986.9946\n",
      "Epoch 144/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1727307.3322 - val_loss: 1847264.3390\n",
      "Epoch 145/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1731386.5633 - val_loss: 1903132.6271\n",
      "Epoch 146/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1743936.0200 - val_loss: 1932954.6481\n",
      "Epoch 147/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1718101.3716 - val_loss: 1753048.5511\n",
      "Epoch 148/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1743937.7232 - val_loss: 1659791.4219\n",
      "Epoch 149/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1747721.9532 - val_loss: 1915777.5554\n",
      "Epoch 150/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1743083.0139 - val_loss: 1900352.2041\n",
      "Epoch 151/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1713470.8260 - val_loss: 1824654.6245\n",
      "Epoch 152/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1706539.4391 - val_loss: 1919506.0656\n",
      "Epoch 153/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1715361.2151 - val_loss: 1690302.8906\n",
      "Epoch 154/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1744004.2072 - val_loss: 1834970.9199\n",
      "Epoch 155/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1708457.4331 - val_loss: 1737036.3542\n",
      "Epoch 156/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1707439.9111 - val_loss: 2009415.4737\n",
      "Epoch 157/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1736829.5114 - val_loss: 1744467.1997\n",
      "Epoch 158/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1696617.0653 - val_loss: 1685199.5604\n",
      "Epoch 159/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1725421.9358 - val_loss: 1868793.7763\n",
      "Epoch 160/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1724599.5313 - val_loss: 1915845.0901\n",
      "Epoch 161/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1702253.2772 - val_loss: 1691970.1377\n",
      "Epoch 162/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1700072.7084 - val_loss: 1787727.1282\n",
      "Epoch 163/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1692467.6253 - val_loss: 1689915.2685\n",
      "Epoch 164/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1704217.7784 - val_loss: 1831422.7149\n",
      "Epoch 165/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1685216.2094 - val_loss: 1702952.6618\n",
      "Epoch 166/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1690553.3077 - val_loss: 1889405.8405\n",
      "Epoch 167/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1689003.4346 - val_loss: 1695925.7639\n",
      "Epoch 168/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1690650.4018 - val_loss: 1708960.7072\n",
      "Epoch 169/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1685996.9567 - val_loss: 1917098.1376\n",
      "Epoch 170/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1687461.5644 - val_loss: 2099071.4137\n",
      "Epoch 171/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1733270.9781 - val_loss: 1797415.8934\n",
      "Epoch 172/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1696832.5320 - val_loss: 1841576.9352\n",
      "Epoch 173/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1691042.8841 - val_loss: 1833278.3646\n",
      "Epoch 174/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1700034.0392 - val_loss: 1819805.4269\n",
      "Epoch 175/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1681666.1191 - val_loss: 1943508.0930\n",
      "Epoch 176/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1683885.3080 - val_loss: 1892796.0789\n",
      "Epoch 177/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1671286.3202 - val_loss: 1798848.9629\n",
      "Epoch 178/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1661823.3607 - val_loss: 1844159.7373\n",
      "Epoch 179/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1682974.5345 - val_loss: 1781083.0824\n",
      "Epoch 180/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1668340.3857 - val_loss: 1872150.2341\n",
      "Epoch 181/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1665913.0514 - val_loss: 1742511.2015\n",
      "Epoch 182/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1654242.0943 - val_loss: 1768866.1709\n",
      "Epoch 183/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1673034.0526 - val_loss: 2025157.2548\n",
      "Epoch 184/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1667837.9831 - val_loss: 1846320.0371\n",
      "Epoch 185/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1678541.3504 - val_loss: 1606733.4365\n",
      "Epoch 186/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1668953.7483 - val_loss: 1749295.8132\n",
      "Epoch 187/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1645143.6031 - val_loss: 1661518.3590\n",
      "Epoch 188/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1645366.8991 - val_loss: 1690481.3450\n",
      "Epoch 189/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1686538.2114 - val_loss: 1645609.6966\n",
      "Epoch 190/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1661002.7450 - val_loss: 1682994.6736\n",
      "Epoch 191/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1642527.1347 - val_loss: 1794035.1317\n",
      "Epoch 192/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1646838.2112 - val_loss: 1744756.0725\n",
      "Epoch 193/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1642003.8610 - val_loss: 1792441.1419\n",
      "Epoch 194/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1657115.4366 - val_loss: 1768336.6431\n",
      "Epoch 195/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1657642.6287 - val_loss: 1837242.2156\n",
      "Epoch 196/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1640801.7055 - val_loss: 1735329.9888\n",
      "Epoch 197/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1654654.1782 - val_loss: 1852158.5080\n",
      "Epoch 198/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1658613.3769 - val_loss: 1863894.3532\n",
      "Epoch 199/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1657922.8737 - val_loss: 1695179.7291\n",
      "Epoch 200/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1647048.3247 - val_loss: 1670772.7759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1652934.6368 - val_loss: 1791969.9780\n",
      "Epoch 202/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1627832.8321 - val_loss: 1819807.3675\n",
      "Epoch 203/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1628406.7577 - val_loss: 1694013.7965\n",
      "Epoch 204/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1632536.4902 - val_loss: 1857151.0011\n",
      "Epoch 205/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1631826.8001 - val_loss: 1714267.8666\n",
      "Epoch 206/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1626339.8704 - val_loss: 1666550.2545\n",
      "Epoch 207/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1630698.9722 - val_loss: 1638915.3243\n",
      "Epoch 208/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1627505.5921 - val_loss: 1983691.3835\n",
      "Epoch 209/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1653553.7631 - val_loss: 2036101.9433\n",
      "Epoch 210/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1655054.8145 - val_loss: 2008703.2971\n",
      "Epoch 211/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1680208.3690 - val_loss: 1749554.6298\n",
      "Epoch 212/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1621548.7453 - val_loss: 1646418.9634\n",
      "Epoch 213/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1640684.9130 - val_loss: 1791897.7762\n",
      "Epoch 214/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1602500.3064 - val_loss: 1731081.8080\n",
      "Epoch 215/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1603879.1460 - val_loss: 1762811.3988\n",
      "Epoch 216/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1603662.9571 - val_loss: 1954834.3765\n",
      "Epoch 217/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1633966.4256 - val_loss: 1931066.9088\n",
      "Epoch 218/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1626763.4536 - val_loss: 1879430.2506\n",
      "Epoch 219/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1639228.7040 - val_loss: 1747655.0644\n",
      "Epoch 220/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1609963.2745 - val_loss: 1766300.4357\n",
      "Epoch 221/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1622139.8170 - val_loss: 1870324.8914\n",
      "Epoch 222/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1602446.3421 - val_loss: 1819713.6432\n",
      "Epoch 223/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1606599.3726 - val_loss: 1704840.4925\n",
      "Epoch 224/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1607153.5244 - val_loss: 1902246.7463\n",
      "Epoch 225/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1630467.6995 - val_loss: 1715312.9302\n",
      "Epoch 226/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1601632.7074 - val_loss: 1788480.1603\n",
      "Epoch 227/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1599229.0244 - val_loss: 1716566.5654\n",
      "Epoch 228/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1587799.7375 - val_loss: 1716794.8376\n",
      "Epoch 229/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1594133.3517 - val_loss: 1935479.7326\n",
      "Epoch 230/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1629935.4697 - val_loss: 1820613.2043\n",
      "Epoch 231/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1596485.6133 - val_loss: 1622607.0673\n",
      "Epoch 232/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1615356.5122 - val_loss: 1698609.6400\n",
      "Epoch 233/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1602725.7911 - val_loss: 1702973.8920\n",
      "Epoch 234/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1597672.6973 - val_loss: 1799880.4073\n",
      "Epoch 235/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1590972.6281 - val_loss: 1746101.4352\n",
      "Epoch 236/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1602307.8715 - val_loss: 1748525.3836\n",
      "Epoch 237/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1576637.8528 - val_loss: 1680173.4753\n",
      "Epoch 238/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1589029.4694 - val_loss: 1719101.8304\n",
      "Epoch 239/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1570208.5536 - val_loss: 1596597.5832\n",
      "Epoch 240/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1587779.8098 - val_loss: 1815125.5422\n",
      "Epoch 241/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1594910.0692 - val_loss: 1713529.8980\n",
      "Epoch 242/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1561787.3239 - val_loss: 1658473.4881\n",
      "Epoch 243/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1563714.3952 - val_loss: 1654610.4213\n",
      "Epoch 244/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1581668.9647 - val_loss: 1658108.5966\n",
      "Epoch 245/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1573269.7903 - val_loss: 1673576.6163\n",
      "Epoch 246/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1564120.7675 - val_loss: 1848057.9160\n",
      "Epoch 247/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1570665.9324 - val_loss: 1667480.7566\n",
      "Epoch 248/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1561343.1573 - val_loss: 1699148.4676\n",
      "Epoch 249/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1564614.0711 - val_loss: 1786773.2620\n",
      "Epoch 250/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1573818.9260 - val_loss: 1697255.8412\n",
      "Epoch 251/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1578919.8431 - val_loss: 1826637.9979\n",
      "Epoch 252/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1566034.7741 - val_loss: 1691932.2763\n",
      "Epoch 253/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1558550.0034 - val_loss: 1576840.1465\n",
      "Epoch 254/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1580625.9463 - val_loss: 1732146.8933\n",
      "Epoch 255/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1554571.4035 - val_loss: 1672328.4056\n",
      "Epoch 256/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1559698.9048 - val_loss: 1842066.8520\n",
      "Epoch 257/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1566459.0457 - val_loss: 1741297.7176\n",
      "Epoch 258/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1555321.4256 - val_loss: 1595212.8803\n",
      "Epoch 259/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1549402.0908 - val_loss: 1825147.3638\n",
      "Epoch 260/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1536584.3112 - val_loss: 1715701.0104\n",
      "Epoch 261/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1556450.8277 - val_loss: 1942681.0714\n",
      "Epoch 262/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1582645.9752 - val_loss: 1738388.9708\n",
      "Epoch 263/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1545374.6129 - val_loss: 1893739.2685\n",
      "Epoch 264/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1571832.0763 - val_loss: 1746762.5413\n",
      "Epoch 265/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1553019.7038 - val_loss: 1612276.4646\n",
      "Epoch 266/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1527925.3815 - val_loss: 1917938.6180\n",
      "Epoch 267/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1557434.8265 - val_loss: 1763073.9464\n",
      "Epoch 268/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1533497.2489 - val_loss: 1841825.5018\n",
      "Epoch 269/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1541102.3212 - val_loss: 1666159.2293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1535357.2246 - val_loss: 1572319.3202\n",
      "Epoch 271/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1551561.2159 - val_loss: 1602684.2940\n",
      "Epoch 272/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1530652.7123 - val_loss: 1682487.8257\n",
      "Epoch 273/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1523082.5913 - val_loss: 1990515.6136\n",
      "Epoch 274/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1561370.7803 - val_loss: 1585386.7175\n",
      "Epoch 275/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1545701.0787 - val_loss: 1685057.9525\n",
      "Epoch 276/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1545510.5047 - val_loss: 1789017.5482\n",
      "Epoch 277/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1542238.7560 - val_loss: 1713494.6764\n",
      "Epoch 278/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1533918.3263 - val_loss: 1817313.4899\n",
      "Epoch 279/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1519325.3133 - val_loss: 1682300.7382\n",
      "Epoch 280/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1541412.7218 - val_loss: 1742632.2269\n",
      "Epoch 281/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1515780.3045 - val_loss: 1568466.7756\n",
      "Epoch 282/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1524204.2490 - val_loss: 1792291.8410\n",
      "Epoch 283/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1530772.5150 - val_loss: 1666619.5188\n",
      "Epoch 284/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1529798.4761 - val_loss: 1657354.5301\n",
      "Epoch 285/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1501011.2268 - val_loss: 1689327.7518\n",
      "Epoch 286/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1506828.5130 - val_loss: 1690394.4880\n",
      "Epoch 287/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1523855.2887 - val_loss: 1872414.1601\n",
      "Epoch 288/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1518621.2896 - val_loss: 1816354.0152\n",
      "Epoch 289/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1513229.0904 - val_loss: 1816787.8989\n",
      "Epoch 290/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1516931.5868 - val_loss: 1742240.8475\n",
      "Epoch 291/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1483243.1375 - val_loss: 1660168.0199\n",
      "Epoch 292/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1516731.6563 - val_loss: 1909942.4662\n",
      "Epoch 293/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1521910.4320 - val_loss: 1696178.5235\n",
      "Epoch 294/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1514871.5843 - val_loss: 1618807.6865\n",
      "Epoch 295/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1509928.7409 - val_loss: 1697631.4421\n",
      "Epoch 296/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1488982.9616 - val_loss: 1880667.1678\n",
      "Epoch 297/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1520704.4766 - val_loss: 1589513.9176\n",
      "Epoch 298/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1495898.8436 - val_loss: 1792984.2256\n",
      "Epoch 299/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1498864.2652 - val_loss: 1789279.8538\n",
      "Epoch 300/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1475341.6918 - val_loss: 1809760.9316\n",
      "Epoch 301/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1471279.1696 - val_loss: 1685678.7000\n",
      "Epoch 302/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1487100.1082 - val_loss: 1768493.2493\n",
      "Epoch 303/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1499329.0329 - val_loss: 1580568.8235\n",
      "Epoch 304/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1504644.3075 - val_loss: 1812218.0162\n",
      "Epoch 305/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1505467.1791 - val_loss: 1889185.1488\n",
      "Epoch 306/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1488836.0515 - val_loss: 1674978.1625\n",
      "Epoch 307/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1466460.8160 - val_loss: 1629963.0752\n",
      "Epoch 308/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1473702.4827 - val_loss: 1740809.4780\n",
      "Epoch 309/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1477824.2848 - val_loss: 1666347.7895\n",
      "Epoch 310/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1471868.4584 - val_loss: 1656626.6886\n",
      "Epoch 311/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1452667.3423 - val_loss: 1581830.1675\n",
      "Epoch 312/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1485476.3068 - val_loss: 1701068.3500\n",
      "Epoch 313/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1472033.7186 - val_loss: 1572968.5672\n",
      "Epoch 314/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1483100.2806 - val_loss: 1595333.4697\n",
      "Epoch 315/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1471091.1868 - val_loss: 1587555.0446\n",
      "Epoch 316/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1479849.3844 - val_loss: 1761637.4672\n",
      "Epoch 317/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1471808.9362 - val_loss: 1824470.3306\n",
      "Epoch 318/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1459613.0367 - val_loss: 1976374.0355\n",
      "Epoch 319/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1480646.3006 - val_loss: 1568751.8240\n",
      "Epoch 320/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1477147.7885 - val_loss: 1615444.1023\n",
      "Epoch 321/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1456287.0668 - val_loss: 1626797.1315\n",
      "Epoch 322/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1458009.7325 - val_loss: 1865560.1155\n",
      "Epoch 323/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1480544.4744 - val_loss: 1882065.5285\n",
      "Epoch 324/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1447643.3107 - val_loss: 1671693.0115\n",
      "Epoch 325/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1467081.4413 - val_loss: 1671893.8296\n",
      "Epoch 326/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1455849.7374 - val_loss: 1609377.1924\n",
      "Epoch 327/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1451651.5530 - val_loss: 1712029.1267\n",
      "Epoch 328/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1443680.0758 - val_loss: 1783209.9197\n",
      "Epoch 329/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1436662.2886 - val_loss: 1531104.9923\n",
      "Epoch 330/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1474409.7618 - val_loss: 1768345.8048\n",
      "Epoch 331/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1442498.1586 - val_loss: 1822292.4821\n",
      "Epoch 332/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1436335.2952 - val_loss: 1741471.9817\n",
      "Epoch 333/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1430218.9930 - val_loss: 1482419.5931\n",
      "Epoch 334/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1454563.7663 - val_loss: 1772501.4620\n",
      "Epoch 335/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1440714.8763 - val_loss: 1535119.6920\n",
      "Epoch 336/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1436435.2434 - val_loss: 1879418.9956\n",
      "Epoch 337/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1437972.9013 - val_loss: 2036802.5117\n",
      "Epoch 338/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1466139.6589 - val_loss: 1770240.8795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1460936.8622 - val_loss: 1696640.5832\n",
      "Epoch 340/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1454605.9951 - val_loss: 1820380.2951\n",
      "Epoch 341/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1422626.3307 - val_loss: 1665301.5680\n",
      "Epoch 342/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1443130.9044 - val_loss: 1750211.8087\n",
      "Epoch 343/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1425663.2852 - val_loss: 1745906.7459\n",
      "Epoch 344/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1421919.9311 - val_loss: 1694860.3995\n",
      "Epoch 345/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1434127.3653 - val_loss: 1611414.4124\n",
      "Epoch 346/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1427077.7281 - val_loss: 1661165.3684\n",
      "Epoch 347/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1436067.7421 - val_loss: 1639688.7552\n",
      "Epoch 348/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1490950.9327 - val_loss: 1531936.3084\n",
      "Epoch 349/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1427430.1171 - val_loss: 1701968.0885\n",
      "Epoch 350/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1407330.9214 - val_loss: 1603114.6465\n",
      "Epoch 351/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1439727.1596 - val_loss: 1818661.1165\n",
      "Epoch 352/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1456697.1007 - val_loss: 1621789.8467\n",
      "Epoch 353/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1425835.0177 - val_loss: 1769257.9439\n",
      "Epoch 354/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1419186.2861 - val_loss: 1708986.7158\n",
      "Epoch 355/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1438319.0278 - val_loss: 1864261.8096\n",
      "Epoch 356/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1414495.5942 - val_loss: 1698473.3702\n",
      "Epoch 357/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1408839.6509 - val_loss: 1718637.7569\n",
      "Epoch 358/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1403033.1934 - val_loss: 1566476.4807\n",
      "Epoch 359/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1419421.1832 - val_loss: 1956595.5568\n",
      "Epoch 360/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1419167.2812 - val_loss: 1537596.8942\n",
      "Epoch 361/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1453934.0422 - val_loss: 1716890.3666\n",
      "Epoch 362/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1422191.2543 - val_loss: 1877280.3548\n",
      "Epoch 363/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1413547.6904 - val_loss: 1691939.5188\n",
      "Epoch 364/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1441072.8836 - val_loss: 1520130.9318\n",
      "Epoch 365/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1431548.9769 - val_loss: 2000250.9361\n",
      "Epoch 366/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1433751.4236 - val_loss: 1585603.2541\n",
      "Epoch 367/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1437582.4618 - val_loss: 1628110.3032\n",
      "Epoch 368/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1411125.1859 - val_loss: 1689620.3542\n",
      "Epoch 369/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1415061.5493 - val_loss: 1588415.1419\n",
      "Epoch 370/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1401169.5813 - val_loss: 1912345.0643\n",
      "Epoch 371/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1452166.7849 - val_loss: 1761816.8266\n",
      "Epoch 372/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1442821.1347 - val_loss: 1915154.6101\n",
      "Epoch 373/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1405575.3451 - val_loss: 1803352.6662\n",
      "Epoch 374/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1413422.2822 - val_loss: 1553702.4558\n",
      "Epoch 375/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1398207.9682 - val_loss: 1961887.8488\n",
      "Epoch 376/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1445140.2135 - val_loss: 1808076.3745\n",
      "Epoch 377/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1405795.2547 - val_loss: 1634718.6968\n",
      "Epoch 378/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1406345.6157 - val_loss: 1557100.1275\n",
      "Epoch 379/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1414186.6806 - val_loss: 1633174.0733\n",
      "Epoch 380/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1399018.9109 - val_loss: 1872832.0806\n",
      "Epoch 381/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1420815.1022 - val_loss: 1545870.4475\n",
      "Epoch 382/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1453594.3476 - val_loss: 1453301.9443\n",
      "Epoch 383/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1476995.6736 - val_loss: 1649598.7532\n",
      "Epoch 384/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1411672.9152 - val_loss: 1725130.9157\n",
      "Epoch 385/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1409974.5202 - val_loss: 1849919.7441\n",
      "Epoch 386/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1417071.5196 - val_loss: 1674759.3725\n",
      "Epoch 387/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1394190.0882 - val_loss: 1782612.2370\n",
      "Epoch 388/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1390906.6185 - val_loss: 1732168.3807\n",
      "Epoch 389/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1396403.5122 - val_loss: 1829911.6764\n",
      "Epoch 390/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1407729.8779 - val_loss: 1678428.5381\n",
      "Epoch 391/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1390348.9352 - val_loss: 1787377.3997\n",
      "Epoch 392/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1406011.3288 - val_loss: 1717857.1474\n",
      "Epoch 393/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1385873.5905 - val_loss: 1641964.5629\n",
      "Epoch 394/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1416601.5638 - val_loss: 1784515.2929\n",
      "Epoch 395/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1388349.7728 - val_loss: 1528157.2844\n",
      "Epoch 396/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1397947.8987 - val_loss: 1483187.4919\n",
      "Epoch 397/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1404476.1333 - val_loss: 1559541.9413\n",
      "Epoch 398/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1404298.4925 - val_loss: 1502987.8236\n",
      "Epoch 399/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1433957.9508 - val_loss: 1839839.6325\n",
      "Epoch 400/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1387498.1219 - val_loss: 1632942.3006\n",
      "Epoch 401/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1403953.2583 - val_loss: 1620930.5919\n",
      "Epoch 402/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1393377.8774 - val_loss: 1688668.7501\n",
      "Epoch 403/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1387741.3088 - val_loss: 1742352.5732\n",
      "Epoch 404/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1399147.0728 - val_loss: 1720196.9818\n",
      "Epoch 405/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1396957.8552 - val_loss: 1976134.0202\n",
      "Epoch 406/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1392549.3624 - val_loss: 1604179.0807\n",
      "Epoch 407/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1420784.3609 - val_loss: 2192372.9178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 408/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1427122.1315 - val_loss: 1631818.8554\n",
      "Epoch 409/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1387535.1543 - val_loss: 1582108.0324\n",
      "Epoch 410/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1404351.8920 - val_loss: 1750664.1808\n",
      "Epoch 411/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1393366.1048 - val_loss: 1618116.6825\n",
      "Epoch 412/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1420136.4781 - val_loss: 1670189.9493\n",
      "Epoch 413/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1397429.5334 - val_loss: 1670672.7526\n",
      "Epoch 414/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1381928.1744 - val_loss: 1992182.0297\n",
      "Epoch 415/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1432840.1706 - val_loss: 1978788.8448\n",
      "Epoch 416/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1396168.4205 - val_loss: 1704972.0393\n",
      "Epoch 417/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1413354.9278 - val_loss: 1450490.9153\n",
      "Epoch 418/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1404847.9218 - val_loss: 1658986.1346\n",
      "Epoch 419/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1407038.7632 - val_loss: 1822303.0983\n",
      "Epoch 420/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1391392.9983 - val_loss: 1811246.0068\n",
      "Epoch 421/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1383347.2782 - val_loss: 1696723.2509\n",
      "Epoch 422/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1375494.6973 - val_loss: 1656781.9847\n",
      "Epoch 423/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1430701.2483 - val_loss: 1652722.3402\n",
      "Epoch 424/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1385767.2217 - val_loss: 1837519.6363\n",
      "Epoch 425/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1400243.5479 - val_loss: 1615325.4964\n",
      "Epoch 426/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1409013.3650 - val_loss: 1519955.8300\n",
      "Epoch 427/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1422834.0193 - val_loss: 1756846.3677\n",
      "Epoch 428/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1391211.5442 - val_loss: 1830352.3354\n",
      "Epoch 429/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1377849.8308 - val_loss: 1597247.1306\n",
      "Epoch 430/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1382402.4106 - val_loss: 1783737.5048\n",
      "Epoch 431/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1378412.3371 - val_loss: 1632994.9071\n",
      "Epoch 432/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1387647.5821 - val_loss: 1601634.7518\n",
      "Epoch 433/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1406013.4754 - val_loss: 1668687.5790\n",
      "Epoch 434/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1386022.1899 - val_loss: 1701383.1040\n",
      "Epoch 435/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1403728.6949 - val_loss: 1755946.9888\n",
      "Epoch 436/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1402697.2875 - val_loss: 1532834.2386\n",
      "Epoch 437/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1413853.2110 - val_loss: 1627892.6850\n",
      "Epoch 438/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1371202.2042 - val_loss: 1880050.9927\n",
      "Epoch 439/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1376589.7560 - val_loss: 1631713.7323\n",
      "Epoch 440/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1440658.7013 - val_loss: 1743909.1136\n",
      "Epoch 441/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1389465.5061 - val_loss: 1561906.3170\n",
      "Epoch 442/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1390614.4445 - val_loss: 1832738.2616\n",
      "Epoch 443/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1374663.6918 - val_loss: 1491630.6748\n",
      "Epoch 444/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1445867.7375 - val_loss: 1833107.7963\n",
      "Epoch 445/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1388930.3800 - val_loss: 1798517.2107\n",
      "Epoch 446/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1380603.0169 - val_loss: 1688160.2832\n",
      "Epoch 447/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1376999.4708 - val_loss: 1748330.9178\n",
      "Epoch 448/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1371268.5767 - val_loss: 1530388.5553\n",
      "Epoch 449/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1396527.8639 - val_loss: 1759934.0774\n",
      "Epoch 450/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1377994.8324 - val_loss: 1818266.9458\n",
      "Epoch 451/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1376280.0613 - val_loss: 2004347.6570\n",
      "Epoch 452/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1430780.3049 - val_loss: 1723071.6440\n",
      "Epoch 453/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1376541.1124 - val_loss: 1542433.5560\n",
      "Epoch 454/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1400117.4347 - val_loss: 1598618.9948\n",
      "Epoch 455/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1382878.2260 - val_loss: 1733481.8670\n",
      "Epoch 456/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1385058.5052 - val_loss: 1869615.9038\n",
      "Epoch 457/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1400823.5012 - val_loss: 1982361.9074\n",
      "Epoch 458/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1396298.1644 - val_loss: 1572081.9123\n",
      "Epoch 459/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1374525.9788 - val_loss: 1624535.7243\n",
      "Epoch 460/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1386471.8451 - val_loss: 1541436.8066\n",
      "Epoch 461/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1447397.1261 - val_loss: 1741202.0923\n",
      "Epoch 462/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1369533.9801 - val_loss: 1716052.3231\n",
      "Epoch 463/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1361115.1409 - val_loss: 1762322.6394\n",
      "Epoch 464/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1391181.6928 - val_loss: 1798011.4089\n",
      "Epoch 465/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1391242.6842 - val_loss: 1646340.7072\n",
      "Epoch 466/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1365879.0077 - val_loss: 1598558.7531\n",
      "Epoch 467/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1400437.7818 - val_loss: 1826465.1420\n",
      "Epoch 468/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1402469.5906 - val_loss: 1647088.4208\n",
      "Epoch 469/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1382941.1493 - val_loss: 1917727.5195\n",
      "Epoch 470/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1373520.8108 - val_loss: 1581137.2194\n",
      "Epoch 471/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1369365.5492 - val_loss: 1791542.3687\n",
      "Epoch 472/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1373718.8921 - val_loss: 1793536.3601\n",
      "Epoch 473/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1365080.4156 - val_loss: 1713036.8701\n",
      "Epoch 474/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1373479.4245 - val_loss: 1821934.8011\n",
      "Epoch 475/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1385269.8930 - val_loss: 1867967.2384\n",
      "Epoch 476/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1377326.6676 - val_loss: 1661303.6449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 477/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1367462.6117 - val_loss: 1807531.4053\n",
      "Epoch 478/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1371411.9464 - val_loss: 2317829.3504\n",
      "Epoch 479/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1480410.2970 - val_loss: 1533969.9207\n",
      "Epoch 480/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1379164.8800 - val_loss: 1735716.5844\n",
      "Epoch 481/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1372106.0505 - val_loss: 1623308.4776\n",
      "Epoch 482/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1373847.6490 - val_loss: 1701875.2410\n",
      "Epoch 483/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1369658.4335 - val_loss: 1845314.1309\n",
      "Epoch 484/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1379743.9029 - val_loss: 1590233.2366\n",
      "Epoch 485/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1371948.7868 - val_loss: 1886912.1245\n",
      "Epoch 486/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1362177.8661 - val_loss: 1694028.8007\n",
      "Epoch 487/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1377816.5992 - val_loss: 1604614.2717\n",
      "Epoch 488/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1385967.9498 - val_loss: 1658504.0825\n",
      "Epoch 489/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1369205.9518 - val_loss: 1668884.1923\n",
      "Epoch 490/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1382367.6758 - val_loss: 1914537.9536\n",
      "Epoch 491/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1388774.9403 - val_loss: 1834897.8147\n",
      "Epoch 492/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1365369.8089 - val_loss: 1784741.3568\n",
      "Epoch 493/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1371598.2226 - val_loss: 1840716.6671\n",
      "Epoch 494/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1362765.6646 - val_loss: 1961518.1815\n",
      "Epoch 495/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1392261.5031 - val_loss: 1726560.5915\n",
      "Epoch 496/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1380048.0865 - val_loss: 1588394.1914\n",
      "Epoch 497/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1358915.2639 - val_loss: 1786484.3349\n",
      "Epoch 498/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1382134.1242 - val_loss: 1559064.0448\n",
      "Epoch 499/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1387358.1623 - val_loss: 1482948.7793\n",
      "Epoch 500/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1392008.4238 - val_loss: 1740362.2373\n",
      "Epoch 501/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1361762.2182 - val_loss: 1659891.6783\n",
      "Epoch 502/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1356778.3915 - val_loss: 1640960.8256\n",
      "Epoch 503/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1365998.9705 - val_loss: 1718935.9168\n",
      "Epoch 504/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1366504.3769 - val_loss: 1976398.8815\n",
      "Epoch 505/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1425084.1479 - val_loss: 1681650.8419\n",
      "Epoch 506/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1370729.0208 - val_loss: 1660015.2142\n",
      "Epoch 507/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1363993.4411 - val_loss: 1815365.0126\n",
      "Epoch 508/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1370680.3574 - val_loss: 1916361.5182\n",
      "Epoch 509/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1385567.2307 - val_loss: 2088302.2520\n",
      "Epoch 510/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1385581.3200 - val_loss: 1897902.0852\n",
      "Epoch 511/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1369758.7676 - val_loss: 1748342.4610\n",
      "Epoch 512/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1362291.9661 - val_loss: 1580173.0386\n",
      "Epoch 513/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1380918.6648 - val_loss: 1723124.1741\n",
      "Epoch 514/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1358612.0121 - val_loss: 1672472.6321\n",
      "Epoch 515/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1365283.5264 - val_loss: 1595714.2740\n",
      "Epoch 516/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1385903.1035 - val_loss: 1657713.1427\n",
      "Epoch 517/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1363947.1232 - val_loss: 1711899.2287\n",
      "Epoch 518/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1391941.6444 - val_loss: 1704945.8930\n",
      "Epoch 519/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1375769.2964 - val_loss: 1523201.9301\n",
      "Epoch 520/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1384040.7217 - val_loss: 1840728.0560\n",
      "Epoch 521/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1360969.2347 - val_loss: 1924820.8045\n",
      "Epoch 522/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1390379.4890 - val_loss: 1519515.7569\n",
      "Epoch 523/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1390904.1757 - val_loss: 1582869.1141\n",
      "Epoch 524/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1385259.9934 - val_loss: 1713800.6109\n",
      "Epoch 525/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1354800.5854 - val_loss: 1613485.5503\n",
      "Epoch 526/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1384124.2863 - val_loss: 1570435.2534\n",
      "Epoch 527/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1362681.4084 - val_loss: 1783302.4976\n",
      "Epoch 528/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1373189.8510 - val_loss: 1699284.0716\n",
      "Epoch 529/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1353804.3134 - val_loss: 1892038.0099\n",
      "Epoch 530/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1378441.5555 - val_loss: 1675549.4683\n",
      "Epoch 531/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1363708.8040 - val_loss: 1906451.4099\n",
      "Epoch 532/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1369610.7427 - val_loss: 1998023.4575\n",
      "Epoch 533/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1389406.5580 - val_loss: 1757358.6187\n",
      "Epoch 534/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1366034.4183 - val_loss: 1648841.4539\n",
      "Epoch 535/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1338883.7850 - val_loss: 1534519.6750\n",
      "Epoch 536/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1363512.3513 - val_loss: 2077330.6399\n",
      "Epoch 537/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1436345.7200 - val_loss: 1558137.8057\n",
      "Epoch 538/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1384140.0017 - val_loss: 1521598.2104\n",
      "Epoch 539/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1387628.3520 - val_loss: 1774966.7660\n",
      "Epoch 540/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1349138.8599 - val_loss: 1718278.2156\n",
      "Epoch 541/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1363043.8533 - val_loss: 1639102.6395\n",
      "Epoch 542/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1354963.0632 - val_loss: 1869316.0610\n",
      "Epoch 543/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1353253.6579 - val_loss: 1817417.1566\n",
      "Epoch 544/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1383426.6519 - val_loss: 1543869.6420\n",
      "Epoch 545/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1394997.9084 - val_loss: 1667028.5005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 546/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1348890.3809 - val_loss: 1769273.3646\n",
      "Epoch 547/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1366677.7918 - val_loss: 1542860.3952\n",
      "Epoch 548/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1393078.7449 - val_loss: 1469761.9962\n",
      "Epoch 549/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1379526.8779 - val_loss: 1743721.3683\n",
      "Epoch 550/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1371436.5719 - val_loss: 1969666.0356\n",
      "Epoch 551/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1342998.3528 - val_loss: 1831561.2453\n",
      "Epoch 552/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1355025.4861 - val_loss: 1924573.3078\n",
      "Epoch 553/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1401014.8410 - val_loss: 1655324.1259\n",
      "Epoch 554/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1357509.5038 - val_loss: 1608786.2294\n",
      "Epoch 555/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1395043.9228 - val_loss: 1762672.9263\n",
      "Epoch 556/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1372291.2090 - val_loss: 1693482.6867\n",
      "Epoch 557/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1359828.5897 - val_loss: 1789354.6986\n",
      "Epoch 558/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1383917.6706 - val_loss: 1722968.3635\n",
      "Epoch 559/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1353838.0479 - val_loss: 1905269.7567\n",
      "Epoch 560/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1380715.8699 - val_loss: 1722109.3293\n",
      "Epoch 561/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1345318.1816 - val_loss: 1675398.0029\n",
      "Epoch 562/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1355517.0684 - val_loss: 1725034.6049\n",
      "Epoch 563/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1361163.2118 - val_loss: 1906203.4905\n",
      "Epoch 564/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1354792.9165 - val_loss: 1996834.2480\n",
      "Epoch 565/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1377148.5814 - val_loss: 1859548.7988\n",
      "Epoch 566/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1371421.1074 - val_loss: 1797422.1674\n",
      "Epoch 567/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1349589.4919 - val_loss: 1669611.6171\n",
      "Epoch 568/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1378907.5835 - val_loss: 1588597.9437\n",
      "Epoch 569/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1359889.8579 - val_loss: 1759085.7495\n",
      "Epoch 570/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1383359.8509 - val_loss: 1895589.3508\n",
      "Epoch 571/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1364199.4559 - val_loss: 1575191.6441\n",
      "Epoch 572/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1406182.5556 - val_loss: 1667125.0014\n",
      "Epoch 573/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1362398.4100 - val_loss: 1657317.5825\n",
      "Epoch 574/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1362844.4136 - val_loss: 1549380.7036\n",
      "Epoch 575/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1357352.3490 - val_loss: 1581111.4866\n",
      "Epoch 576/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1354936.3091 - val_loss: 1680913.7598\n",
      "Epoch 577/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1346588.7094 - val_loss: 1813223.3981\n",
      "Epoch 578/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1349914.7551 - val_loss: 1761917.8773\n",
      "Epoch 579/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1345939.0106 - val_loss: 1534322.7911\n",
      "Epoch 580/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1413080.1023 - val_loss: 1676377.7583\n",
      "Epoch 581/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1368322.4361 - val_loss: 1808604.2785\n",
      "Epoch 582/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1356955.2627 - val_loss: 1819724.4164\n",
      "Epoch 583/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1363532.9031 - val_loss: 2004869.4406\n",
      "Epoch 584/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1427103.6414 - val_loss: 1828340.0106\n",
      "Epoch 585/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1337589.7927 - val_loss: 1685522.7496\n",
      "Epoch 586/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1364535.2772 - val_loss: 1836531.1360\n",
      "Epoch 587/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1373742.5845 - val_loss: 1491978.2262\n",
      "Epoch 588/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1393064.0276 - val_loss: 1670406.4716\n",
      "Epoch 589/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1356024.0473 - val_loss: 1676952.7475\n",
      "Epoch 590/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1349820.0083 - val_loss: 1892221.9414\n",
      "Epoch 591/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1381845.0324 - val_loss: 1496023.8161\n",
      "Epoch 592/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1365406.7592 - val_loss: 1634865.5231\n",
      "Epoch 593/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1330954.7831 - val_loss: 1572152.6709\n",
      "Epoch 594/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1359813.6879 - val_loss: 1663104.0077\n",
      "Epoch 595/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1334753.3111 - val_loss: 1632847.6814\n",
      "Epoch 596/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1334621.1726 - val_loss: 1664892.9443\n",
      "Epoch 597/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1348415.9966 - val_loss: 1593580.5596\n",
      "Epoch 598/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1377356.0227 - val_loss: 1800295.6601\n",
      "Epoch 599/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1364118.5458 - val_loss: 1574623.8113\n",
      "Epoch 600/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1361058.0594 - val_loss: 1750299.5265\n",
      "Train on 14390 samples, validate on 1599 samples\n",
      "Epoch 1/600\n",
      "14390/14390 [==============================] - 0s 23us/step - loss: 7101776.3841 - val_loss: 7075485.2761\n",
      "Epoch 2/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 7086228.8010 - val_loss: 6959795.7974\n",
      "Epoch 3/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 5214231.7764 - val_loss: 2905824.8418\n",
      "Epoch 4/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2693750.5169 - val_loss: 2594474.4526\n",
      "Epoch 5/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2629933.8301 - val_loss: 2549552.4331\n",
      "Epoch 6/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2607259.9635 - val_loss: 2546266.4361\n",
      "Epoch 7/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2605610.5864 - val_loss: 2544506.2178\n",
      "Epoch 8/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2603714.1028 - val_loss: 2544407.1373\n",
      "Epoch 9/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2600734.6451 - val_loss: 2538296.3458\n",
      "Epoch 10/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2601443.9661 - val_loss: 2539698.6284\n",
      "Epoch 11/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2599802.1269 - val_loss: 2537547.4472\n",
      "Epoch 12/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2596047.3993 - val_loss: 2533876.9153\n",
      "Epoch 13/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2590856.4180 - val_loss: 2528889.0721\n",
      "Epoch 14/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2589739.0406 - val_loss: 2527779.4669\n",
      "Epoch 15/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2587491.7045 - val_loss: 2524031.1906\n",
      "Epoch 16/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2587153.9174 - val_loss: 2521195.8069\n",
      "Epoch 17/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2581009.1693 - val_loss: 2518830.3080\n",
      "Epoch 18/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2580222.2521 - val_loss: 2521366.2638\n",
      "Epoch 19/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2575618.7005 - val_loss: 2513589.3240\n",
      "Epoch 20/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2566205.7728 - val_loss: 2514570.5286\n",
      "Epoch 21/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2570697.8424 - val_loss: 2509816.6836\n",
      "Epoch 22/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2564088.7362 - val_loss: 2505328.5321\n",
      "Epoch 23/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2563166.8612 - val_loss: 2499709.2547\n",
      "Epoch 24/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2557281.2123 - val_loss: 2496478.7020\n",
      "Epoch 25/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2548467.9034 - val_loss: 2497200.8699\n",
      "Epoch 26/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2546616.4193 - val_loss: 2484765.5072\n",
      "Epoch 27/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2535284.4327 - val_loss: 2479070.5813\n",
      "Epoch 28/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2527158.8032 - val_loss: 2472443.0241\n",
      "Epoch 29/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2523836.0844 - val_loss: 2468153.8956\n",
      "Epoch 30/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2517174.1813 - val_loss: 2456668.4967\n",
      "Epoch 31/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2503239.4270 - val_loss: 2447960.3910\n",
      "Epoch 32/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2487780.9628 - val_loss: 2434281.4992\n",
      "Epoch 33/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2482231.6510 - val_loss: 2421655.5683\n",
      "Epoch 34/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2459947.5458 - val_loss: 2404813.2919\n",
      "Epoch 35/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2443778.8822 - val_loss: 2385480.2422\n",
      "Epoch 36/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2416442.7636 - val_loss: 2373505.0600\n",
      "Epoch 37/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2398722.7545 - val_loss: 2333917.5522\n",
      "Epoch 38/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2362506.9410 - val_loss: 2299724.3676\n",
      "Epoch 39/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2348267.9320 - val_loss: 2275616.8366\n",
      "Epoch 40/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2304743.2519 - val_loss: 2277332.6887\n",
      "Epoch 41/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2284550.6317 - val_loss: 2213168.9811\n",
      "Epoch 42/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2248699.0259 - val_loss: 2197376.6950\n",
      "Epoch 43/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2230925.2513 - val_loss: 2156088.8324\n",
      "Epoch 44/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2206706.9986 - val_loss: 2125573.7530\n",
      "Epoch 45/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2176931.4062 - val_loss: 2229397.3346\n",
      "Epoch 46/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2175402.5776 - val_loss: 2143266.2428\n",
      "Epoch 47/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2162460.3906 - val_loss: 2058091.4492\n",
      "Epoch 48/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2136404.6800 - val_loss: 2033832.3143\n",
      "Epoch 49/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2103954.7287 - val_loss: 2031607.2765\n",
      "Epoch 50/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2109092.9892 - val_loss: 2043622.4821\n",
      "Epoch 51/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2100169.1687 - val_loss: 2000181.5944\n",
      "Epoch 52/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2079868.5963 - val_loss: 1971758.1539\n",
      "Epoch 53/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2042266.3440 - val_loss: 1943834.5951\n",
      "Epoch 54/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2037413.3280 - val_loss: 2005589.3109\n",
      "Epoch 55/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 2039178.6730 - val_loss: 1914729.5519\n",
      "Epoch 56/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 2012640.5668 - val_loss: 1916597.3202\n",
      "Epoch 57/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1998651.1355 - val_loss: 1879881.9183\n",
      "Epoch 58/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1983653.0343 - val_loss: 1898629.4332\n",
      "Epoch 59/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1955851.8213 - val_loss: 1973995.0457\n",
      "Epoch 60/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1960439.7305 - val_loss: 1886965.7743\n",
      "Epoch 61/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1944972.6615 - val_loss: 1836738.6103\n",
      "Epoch 62/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1963495.7353 - val_loss: 1926153.3839\n",
      "Epoch 63/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1943936.1247 - val_loss: 1895075.4792\n",
      "Epoch 64/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1927452.8912 - val_loss: 1907505.2490\n",
      "Epoch 65/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1917547.3671 - val_loss: 1823472.5359\n",
      "Epoch 66/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1920603.5270 - val_loss: 1828878.2170\n",
      "Epoch 67/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1901947.3093 - val_loss: 1864564.6949\n",
      "Epoch 68/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1897616.4682 - val_loss: 1792082.9909\n",
      "Epoch 69/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1906971.3890 - val_loss: 1779167.2713\n",
      "Epoch 70/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1898270.3557 - val_loss: 1816425.0640\n",
      "Epoch 71/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1890784.2768 - val_loss: 1876006.9955\n",
      "Epoch 72/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1894790.0085 - val_loss: 1824839.0026\n",
      "Epoch 73/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1866711.8511 - val_loss: 1748723.6308\n",
      "Epoch 74/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1879360.5782 - val_loss: 1971048.9723\n",
      "Epoch 75/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1858870.1120 - val_loss: 1737081.5361\n",
      "Epoch 76/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1872462.4431 - val_loss: 1782572.5360\n",
      "Epoch 77/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1849635.0671 - val_loss: 1820018.2518\n",
      "Epoch 78/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1846164.1044 - val_loss: 1722248.3859\n",
      "Epoch 79/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1844450.8429 - val_loss: 1761309.3827\n",
      "Epoch 80/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1833229.5066 - val_loss: 1828259.6104\n",
      "Epoch 81/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1840249.4121 - val_loss: 1726436.2850\n",
      "Epoch 82/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1851348.5572 - val_loss: 1828954.8626\n",
      "Epoch 83/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14390/14390 [==============================] - 0s 7us/step - loss: 1823083.8782 - val_loss: 1779525.4867\n",
      "Epoch 84/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1797638.5123 - val_loss: 1763092.7516\n",
      "Epoch 85/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1807444.7115 - val_loss: 1871366.7240\n",
      "Epoch 86/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1815352.9588 - val_loss: 1920738.2891\n",
      "Epoch 87/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1813848.9851 - val_loss: 1876217.8752\n",
      "Epoch 88/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1814123.9618 - val_loss: 1846389.9862\n",
      "Epoch 89/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1797856.3403 - val_loss: 1730778.3787\n",
      "Epoch 90/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1800053.1698 - val_loss: 1831208.6531\n",
      "Epoch 91/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1819854.5292 - val_loss: 1740358.5363\n",
      "Epoch 92/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1775620.8130 - val_loss: 1749460.8419\n",
      "Epoch 93/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1802284.0161 - val_loss: 1691132.1591\n",
      "Epoch 94/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1799348.7101 - val_loss: 1707050.6549\n",
      "Epoch 95/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1789383.6855 - val_loss: 1700428.4893\n",
      "Epoch 96/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1766443.1640 - val_loss: 1690043.8261\n",
      "Epoch 97/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1839348.8284 - val_loss: 1732380.6315\n",
      "Epoch 98/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1801101.0399 - val_loss: 1709355.3756\n",
      "Epoch 99/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1759424.7938 - val_loss: 1746733.8967\n",
      "Epoch 100/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1786190.9241 - val_loss: 1726701.2166\n",
      "Epoch 101/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1801673.5902 - val_loss: 1797780.2833\n",
      "Epoch 102/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1802271.2718 - val_loss: 1767881.4944\n",
      "Epoch 103/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1773137.9890 - val_loss: 1683357.0097\n",
      "Epoch 104/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1765192.3592 - val_loss: 1774654.9332\n",
      "Epoch 105/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1760969.2822 - val_loss: 1768205.4199\n",
      "Epoch 106/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1761337.8984 - val_loss: 1749592.3640\n",
      "Epoch 107/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1760362.2716 - val_loss: 1688563.2706\n",
      "Epoch 108/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1752741.0678 - val_loss: 1772132.9340\n",
      "Epoch 109/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1749870.4947 - val_loss: 1652288.1534\n",
      "Epoch 110/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1766648.3404 - val_loss: 1659851.0802\n",
      "Epoch 111/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1733202.6542 - val_loss: 1842270.5665\n",
      "Epoch 112/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1746550.4069 - val_loss: 1870947.6945\n",
      "Epoch 113/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1744283.2490 - val_loss: 1758358.6963\n",
      "Epoch 114/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1744894.6670 - val_loss: 1713138.5203\n",
      "Epoch 115/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1752342.3495 - val_loss: 1779851.2561\n",
      "Epoch 116/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1733699.3268 - val_loss: 1731983.0010\n",
      "Epoch 117/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1703073.5587 - val_loss: 1724414.6889\n",
      "Epoch 118/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1731275.2903 - val_loss: 1641040.7129\n",
      "Epoch 119/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1738140.8746 - val_loss: 1947898.7576\n",
      "Epoch 120/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1729147.8568 - val_loss: 1777021.9001\n",
      "Epoch 121/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1751074.9864 - val_loss: 1663892.2655\n",
      "Epoch 122/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1728754.7474 - val_loss: 1727868.4818\n",
      "Epoch 123/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1719070.5497 - val_loss: 1819892.9414\n",
      "Epoch 124/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1742152.4951 - val_loss: 1937281.6515\n",
      "Epoch 125/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1738104.1600 - val_loss: 1848127.4293\n",
      "Epoch 126/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1721732.7668 - val_loss: 1870425.2195\n",
      "Epoch 127/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1731878.1385 - val_loss: 1673451.7294\n",
      "Epoch 128/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1707572.8378 - val_loss: 1645501.3753\n",
      "Epoch 129/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1705380.8001 - val_loss: 1702280.5523\n",
      "Epoch 130/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1716558.7240 - val_loss: 1871777.9989\n",
      "Epoch 131/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1711138.3570 - val_loss: 1755119.5508\n",
      "Epoch 132/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1709902.4289 - val_loss: 1665179.0010\n",
      "Epoch 133/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1701952.4035 - val_loss: 1628897.8637\n",
      "Epoch 134/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1702897.3253 - val_loss: 1713155.3600\n",
      "Epoch 135/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1703800.5260 - val_loss: 1669238.3325\n",
      "Epoch 136/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1704016.8832 - val_loss: 1644911.9311\n",
      "Epoch 137/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1725029.6461 - val_loss: 1637812.7232\n",
      "Epoch 138/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1713174.1613 - val_loss: 1739344.5457\n",
      "Epoch 139/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1708170.8118 - val_loss: 1705021.6065\n",
      "Epoch 140/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1693926.2899 - val_loss: 1667135.7768\n",
      "Epoch 141/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1680455.1958 - val_loss: 1672420.5526\n",
      "Epoch 142/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1699166.4168 - val_loss: 1886597.3187\n",
      "Epoch 143/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1696375.1017 - val_loss: 1712880.1331\n",
      "Epoch 144/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1688631.3817 - val_loss: 1741899.5587\n",
      "Epoch 145/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1705116.2265 - val_loss: 1624091.3857\n",
      "Epoch 146/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1747235.5967 - val_loss: 1697006.7471\n",
      "Epoch 147/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1692050.0884 - val_loss: 1864069.4810\n",
      "Epoch 148/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1680327.8784 - val_loss: 1761061.8918\n",
      "Epoch 149/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1669046.6767 - val_loss: 1625056.3299\n",
      "Epoch 150/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1685857.3466 - val_loss: 1651824.8125\n",
      "Epoch 151/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1673058.3446 - val_loss: 1695956.7727\n",
      "Epoch 152/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14390/14390 [==============================] - 0s 8us/step - loss: 1656814.7157 - val_loss: 1710640.6886\n",
      "Epoch 153/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1662538.1827 - val_loss: 1793202.2920\n",
      "Epoch 154/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1668617.2579 - val_loss: 1620400.3102\n",
      "Epoch 155/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1662538.4784 - val_loss: 1814449.1212\n",
      "Epoch 156/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1660381.5946 - val_loss: 1791454.9576\n",
      "Epoch 157/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1671814.1430 - val_loss: 1724181.8030\n",
      "Epoch 158/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1710006.9003 - val_loss: 1643506.1334\n",
      "Epoch 159/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1638897.0001 - val_loss: 1642623.5235\n",
      "Epoch 160/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1665523.3737 - val_loss: 1802877.2477\n",
      "Epoch 161/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1674880.6069 - val_loss: 1870287.3015\n",
      "Epoch 162/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1680957.6906 - val_loss: 1767759.7197\n",
      "Epoch 163/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1630087.0663 - val_loss: 1845093.6528\n",
      "Epoch 164/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1674158.0359 - val_loss: 1695019.2730\n",
      "Epoch 165/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1637004.5995 - val_loss: 1698101.8134\n",
      "Epoch 166/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1652403.6604 - val_loss: 1619934.5906\n",
      "Epoch 167/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1637666.0117 - val_loss: 1640965.1778\n",
      "Epoch 168/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1650604.8919 - val_loss: 1691125.0380\n",
      "Epoch 169/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1641571.5070 - val_loss: 1719278.8782\n",
      "Epoch 170/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1630880.0456 - val_loss: 1631741.2513\n",
      "Epoch 171/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1670451.4697 - val_loss: 1595864.7947\n",
      "Epoch 172/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1668323.9497 - val_loss: 1862337.5004\n",
      "Epoch 173/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1643041.1301 - val_loss: 1656938.4959\n",
      "Epoch 174/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1643390.4514 - val_loss: 1650169.4561\n",
      "Epoch 175/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1644036.0871 - val_loss: 1726627.8635\n",
      "Epoch 176/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1626776.9686 - val_loss: 1813356.8498\n",
      "Epoch 177/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1655000.5017 - val_loss: 1596094.2145\n",
      "Epoch 178/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1631033.8600 - val_loss: 1679211.2156\n",
      "Epoch 179/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1622714.5339 - val_loss: 1902422.4649\n",
      "Epoch 180/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1630673.7972 - val_loss: 1663156.9984\n",
      "Epoch 181/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1612038.2212 - val_loss: 1764785.7251\n",
      "Epoch 182/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1633534.1466 - val_loss: 1579175.0265\n",
      "Epoch 183/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1634930.8666 - val_loss: 1735049.2738\n",
      "Epoch 184/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1622461.5820 - val_loss: 1735625.0754\n",
      "Epoch 185/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1612824.8593 - val_loss: 1913621.9756\n",
      "Epoch 186/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1676585.6401 - val_loss: 1657369.1321\n",
      "Epoch 187/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1628115.5214 - val_loss: 1922059.0155\n",
      "Epoch 188/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1618918.8012 - val_loss: 1622560.1716\n",
      "Epoch 189/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1613083.0530 - val_loss: 1591547.9106\n",
      "Epoch 190/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1624124.0994 - val_loss: 1699252.3437\n",
      "Epoch 191/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1624453.1569 - val_loss: 1627340.2775\n",
      "Epoch 192/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1603227.0063 - val_loss: 1858794.0196\n",
      "Epoch 193/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1612529.2608 - val_loss: 1725360.0172\n",
      "Epoch 194/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1603501.7451 - val_loss: 1847132.2494\n",
      "Epoch 195/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1598687.0587 - val_loss: 1735543.3286\n",
      "Epoch 196/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1607937.8356 - val_loss: 1614202.0009\n",
      "Epoch 197/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1650897.7548 - val_loss: 1793090.9592\n",
      "Epoch 198/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1613746.1015 - val_loss: 1690989.7808\n",
      "Epoch 199/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1603525.9708 - val_loss: 1761558.9055\n",
      "Epoch 200/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1621813.5991 - val_loss: 1687436.4259\n",
      "Epoch 201/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1591788.9792 - val_loss: 1765187.8706\n",
      "Epoch 202/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1587090.7248 - val_loss: 1734777.8863\n",
      "Epoch 203/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1600423.2237 - val_loss: 1676733.7169\n",
      "Epoch 204/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1595235.9500 - val_loss: 1717806.9314\n",
      "Epoch 205/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1604921.6512 - val_loss: 1748908.8051\n",
      "Epoch 206/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1598279.5825 - val_loss: 1740440.1682\n",
      "Epoch 207/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1603871.5051 - val_loss: 1766328.4085\n",
      "Epoch 208/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1609474.0965 - val_loss: 1665929.2258\n",
      "Epoch 209/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1581643.9163 - val_loss: 1647694.1652\n",
      "Epoch 210/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1584917.1805 - val_loss: 1643585.8154\n",
      "Epoch 211/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1595598.7495 - val_loss: 1968675.1924\n",
      "Epoch 212/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1604739.0995 - val_loss: 1599147.3961\n",
      "Epoch 213/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1585601.2055 - val_loss: 1617497.7167\n",
      "Epoch 214/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1573052.0328 - val_loss: 1611991.4361\n",
      "Epoch 215/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1591117.2389 - val_loss: 1694627.0741\n",
      "Epoch 216/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1588533.4886 - val_loss: 1721491.1269\n",
      "Epoch 217/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1598513.5245 - val_loss: 1647177.4250\n",
      "Epoch 218/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1566550.3999 - val_loss: 1659796.0121\n",
      "Epoch 219/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1586882.7146 - val_loss: 1746864.9830\n",
      "Epoch 220/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1573546.3543 - val_loss: 2078664.6386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1630986.3627 - val_loss: 1692202.3775\n",
      "Epoch 222/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1581465.9085 - val_loss: 1779233.4558\n",
      "Epoch 223/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1589869.2791 - val_loss: 1653647.6344\n",
      "Epoch 224/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1564586.6796 - val_loss: 1687889.8724\n",
      "Epoch 225/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1582255.3494 - val_loss: 1559508.4058\n",
      "Epoch 226/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1572133.1812 - val_loss: 1637333.5528\n",
      "Epoch 227/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1605458.5890 - val_loss: 1718236.6052\n",
      "Epoch 228/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1563392.7151 - val_loss: 1623102.0464\n",
      "Epoch 229/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1555611.6894 - val_loss: 1724738.4115\n",
      "Epoch 230/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1571369.2420 - val_loss: 1743717.4032\n",
      "Epoch 231/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1568903.6951 - val_loss: 1638072.8231\n",
      "Epoch 232/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1565054.0900 - val_loss: 1718182.9797\n",
      "Epoch 233/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1553622.3699 - val_loss: 1639670.2646\n",
      "Epoch 234/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1543445.2566 - val_loss: 1681436.8475\n",
      "Epoch 235/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1552286.4547 - val_loss: 1920474.8380\n",
      "Epoch 236/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1593220.1517 - val_loss: 1755822.6308\n",
      "Epoch 237/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1558160.1378 - val_loss: 1634700.6018\n",
      "Epoch 238/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1553037.4095 - val_loss: 1825722.9281\n",
      "Epoch 239/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1602262.2345 - val_loss: 1554683.8598\n",
      "Epoch 240/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1589225.4942 - val_loss: 1888857.7289\n",
      "Epoch 241/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1560897.1378 - val_loss: 1905396.4808\n",
      "Epoch 242/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1590690.7218 - val_loss: 1587376.9393\n",
      "Epoch 243/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1558310.3016 - val_loss: 1679275.0470\n",
      "Epoch 244/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1540165.7564 - val_loss: 1623331.9110\n",
      "Epoch 245/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1530516.7609 - val_loss: 1784115.4941\n",
      "Epoch 246/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1549283.7671 - val_loss: 1860465.9434\n",
      "Epoch 247/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1553739.5324 - val_loss: 1607987.5625\n",
      "Epoch 248/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1533087.1766 - val_loss: 1597629.6352\n",
      "Epoch 249/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1544038.2875 - val_loss: 1662967.7546\n",
      "Epoch 250/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1537461.8479 - val_loss: 1616513.2205\n",
      "Epoch 251/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1531339.9225 - val_loss: 1652827.3209\n",
      "Epoch 252/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1533988.9234 - val_loss: 1818595.4040\n",
      "Epoch 253/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1537482.7853 - val_loss: 1795029.8287\n",
      "Epoch 254/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1549584.3514 - val_loss: 1628778.9259\n",
      "Epoch 255/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1532751.4273 - val_loss: 1623557.1301\n",
      "Epoch 256/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1555822.1912 - val_loss: 1675634.8906\n",
      "Epoch 257/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1524468.1305 - val_loss: 1912775.9129\n",
      "Epoch 258/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1550113.7218 - val_loss: 1676071.1756\n",
      "Epoch 259/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1505378.0969 - val_loss: 1867011.5504\n",
      "Epoch 260/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1537258.2933 - val_loss: 1785881.9442\n",
      "Epoch 261/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1535309.3932 - val_loss: 1671159.1572\n",
      "Epoch 262/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1513411.9713 - val_loss: 1884099.8247\n",
      "Epoch 263/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1535647.0570 - val_loss: 1609427.6008\n",
      "Epoch 264/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1527799.0989 - val_loss: 1597559.4697\n",
      "Epoch 265/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1507700.8010 - val_loss: 1635291.0165\n",
      "Epoch 266/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1524846.7684 - val_loss: 1589396.1037\n",
      "Epoch 267/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1523614.9756 - val_loss: 1711483.0692\n",
      "Epoch 268/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1510132.3535 - val_loss: 1740540.8669\n",
      "Epoch 269/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1506535.0939 - val_loss: 1947086.6223\n",
      "Epoch 270/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1544675.7011 - val_loss: 1817336.6171\n",
      "Epoch 271/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1506427.7370 - val_loss: 1614458.0660\n",
      "Epoch 272/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1519555.8393 - val_loss: 1586162.9601\n",
      "Epoch 273/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1495749.0223 - val_loss: 1750832.8328\n",
      "Epoch 274/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1521606.8224 - val_loss: 1682127.3488\n",
      "Epoch 275/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1501489.8087 - val_loss: 1746799.7700\n",
      "Epoch 276/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1506925.4525 - val_loss: 1683489.9845\n",
      "Epoch 277/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1525015.8305 - val_loss: 1690491.7294\n",
      "Epoch 278/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1518596.7769 - val_loss: 1584343.7036\n",
      "Epoch 279/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1520795.8745 - val_loss: 1601632.5295\n",
      "Epoch 280/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1495976.5038 - val_loss: 1655322.4708\n",
      "Epoch 281/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1501486.4600 - val_loss: 1585216.8719\n",
      "Epoch 282/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1512922.4679 - val_loss: 1744701.3974\n",
      "Epoch 283/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1510622.0726 - val_loss: 1714247.9831\n",
      "Epoch 284/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1491343.8820 - val_loss: 1519899.9239\n",
      "Epoch 285/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1497404.3685 - val_loss: 1868363.4351\n",
      "Epoch 286/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1486974.8608 - val_loss: 1685590.9590\n",
      "Epoch 287/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1490465.6634 - val_loss: 1790594.7199\n",
      "Epoch 288/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1506848.4272 - val_loss: 1502294.2792\n",
      "Epoch 289/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1525590.5290 - val_loss: 1654742.8631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1497327.3402 - val_loss: 1666192.9518\n",
      "Epoch 291/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1496011.4642 - val_loss: 1542711.3227\n",
      "Epoch 292/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1499822.0546 - val_loss: 1765002.0518\n",
      "Epoch 293/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1485288.7815 - val_loss: 1613885.1696\n",
      "Epoch 294/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1484179.6834 - val_loss: 1780942.5002\n",
      "Epoch 295/600\n",
      "14390/14390 [==============================] - 0s 7us/step - loss: 1499210.5153 - val_loss: 1718068.5617\n",
      "Epoch 296/600\n",
      "14390/14390 [==============================] - 0s 6us/step - loss: 1486140.3292 - val_loss: 1586532.0526\n",
      "Epoch 297/600\n",
      "14390/14390 [==============================] - 0s 8us/step - loss: 1487092.5063 - val_loss: 1906260.6923\n",
      "Epoch 298/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1467634.2294 - val_loss: 1669384.7600\n",
      "Epoch 299/600\n",
      "14390/14390 [==============================] - 0s 24us/step - loss: 1462958.1554 - val_loss: 1836697.3826\n",
      "Epoch 300/600\n",
      "14390/14390 [==============================] - 0s 21us/step - loss: 1479233.3593 - val_loss: 1893397.6887\n",
      "Epoch 301/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1491272.1366 - val_loss: 1560300.3294\n",
      "Epoch 302/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1498633.6984 - val_loss: 1911812.1023\n",
      "Epoch 303/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1484745.5574 - val_loss: 1604026.3459\n",
      "Epoch 304/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1478627.5571 - val_loss: 1736131.6864\n",
      "Epoch 305/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1465072.6437 - val_loss: 2007823.2369\n",
      "Epoch 306/600\n",
      "14390/14390 [==============================] - 0s 21us/step - loss: 1507576.2662 - val_loss: 1644443.8257\n",
      "Epoch 307/600\n",
      "14390/14390 [==============================] - 1s 49us/step - loss: 1462757.0141 - val_loss: 1741742.9053\n",
      "Epoch 308/600\n",
      "14390/14390 [==============================] - 0s 28us/step - loss: 1469647.5898 - val_loss: 1499736.7151\n",
      "Epoch 309/600\n",
      "14390/14390 [==============================] - 0s 25us/step - loss: 1487276.8117 - val_loss: 1703464.7771\n",
      "Epoch 310/600\n",
      "14390/14390 [==============================] - 0s 31us/step - loss: 1468716.1419 - val_loss: 1532350.1778\n",
      "Epoch 311/600\n",
      "14390/14390 [==============================] - 0s 20us/step - loss: 1460788.7999 - val_loss: 1846709.1025\n",
      "Epoch 312/600\n",
      "14390/14390 [==============================] - 1s 37us/step - loss: 1489635.6013 - val_loss: 1764326.6169\n",
      "Epoch 313/600\n",
      "14390/14390 [==============================] - 0s 22us/step - loss: 1468237.2700 - val_loss: 1531670.9928\n",
      "Epoch 314/600\n",
      "14390/14390 [==============================] - 1s 38us/step - loss: 1489557.4622 - val_loss: 1862108.9404\n",
      "Epoch 315/600\n",
      "14390/14390 [==============================] - 0s 25us/step - loss: 1476558.4578 - val_loss: 1806775.5703\n",
      "Epoch 316/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1451547.4491 - val_loss: 1472545.4848\n",
      "Epoch 317/600\n",
      "14390/14390 [==============================] - 0s 20us/step - loss: 1473490.1842 - val_loss: 1501749.2735\n",
      "Epoch 318/600\n",
      "14390/14390 [==============================] - 0s 25us/step - loss: 1479048.8605 - val_loss: 1514130.8014\n",
      "Epoch 319/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1504783.3839 - val_loss: 1665941.6533\n",
      "Epoch 320/600\n",
      "14390/14390 [==============================] - 0s 26us/step - loss: 1435273.9719 - val_loss: 1722860.5786\n",
      "Epoch 321/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1444879.5587 - val_loss: 1927533.0970\n",
      "Epoch 322/600\n",
      "14390/14390 [==============================] - 1s 66us/step - loss: 1446181.9209 - val_loss: 2068585.8251\n",
      "Epoch 323/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1498082.0449 - val_loss: 1633522.5940\n",
      "Epoch 324/600\n",
      "14390/14390 [==============================] - 0s 20us/step - loss: 1504805.5531 - val_loss: 1525290.0884\n",
      "Epoch 325/600\n",
      "14390/14390 [==============================] - 0s 16us/step - loss: 1489945.7966 - val_loss: 1848761.6049\n",
      "Epoch 326/600\n",
      "14390/14390 [==============================] - 0s 20us/step - loss: 1474805.6165 - val_loss: 1521459.8604\n",
      "Epoch 327/600\n",
      "14390/14390 [==============================] - 0s 31us/step - loss: 1441548.8053 - val_loss: 1882534.1625\n",
      "Epoch 328/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1471139.0661 - val_loss: 1556185.7646\n",
      "Epoch 329/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1471719.9453 - val_loss: 1513083.3465\n",
      "Epoch 330/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1431803.5816 - val_loss: 1697602.0038\n",
      "Epoch 331/600\n",
      "14390/14390 [==============================] - 0s 27us/step - loss: 1445061.5228 - val_loss: 1655589.2154\n",
      "Epoch 332/600\n",
      "14390/14390 [==============================] - 0s 32us/step - loss: 1437199.5712 - val_loss: 1776659.7710\n",
      "Epoch 333/600\n",
      "14390/14390 [==============================] - 0s 33us/step - loss: 1458118.9781 - val_loss: 1742332.4291\n",
      "Epoch 334/600\n",
      "14390/14390 [==============================] - 0s 23us/step - loss: 1447421.9865 - val_loss: 1786177.0227\n",
      "Epoch 335/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1470336.4689 - val_loss: 1466724.1017\n",
      "Epoch 336/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1517595.5487 - val_loss: 1538060.7497\n",
      "Epoch 337/600\n",
      "14390/14390 [==============================] - 0s 20us/step - loss: 1448071.6853 - val_loss: 1959876.2100\n",
      "Epoch 338/600\n",
      "14390/14390 [==============================] - 0s 31us/step - loss: 1437958.1821 - val_loss: 1478514.3101\n",
      "Epoch 339/600\n",
      "14390/14390 [==============================] - 1s 56us/step - loss: 1513722.1002 - val_loss: 1766114.0453\n",
      "Epoch 340/600\n",
      "14390/14390 [==============================] - 1s 82us/step - loss: 1461606.2983 - val_loss: 1552414.3895\n",
      "Epoch 341/600\n",
      "14390/14390 [==============================] - 0s 26us/step - loss: 1444484.9516 - val_loss: 1572252.2168\n",
      "Epoch 342/600\n",
      "14390/14390 [==============================] - 1s 91us/step - loss: 1433580.8243 - val_loss: 1828837.1143\n",
      "Epoch 343/600\n",
      "14390/14390 [==============================] - 1s 94us/step - loss: 1443046.1754 - val_loss: 1569131.1479\n",
      "Epoch 344/600\n",
      "14390/14390 [==============================] - 1s 65us/step - loss: 1428256.7932 - val_loss: 2011823.7946\n",
      "Epoch 345/600\n",
      "14390/14390 [==============================] - 0s 34us/step - loss: 1462484.0630 - val_loss: 1671886.2098\n",
      "Epoch 346/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1433317.4310 - val_loss: 1752130.8526\n",
      "Epoch 347/600\n",
      "14390/14390 [==============================] - 0s 21us/step - loss: 1422621.9862 - val_loss: 1570018.2907\n",
      "Epoch 348/600\n",
      "14390/14390 [==============================] - 0s 23us/step - loss: 1429925.6228 - val_loss: 1731401.5378\n",
      "Epoch 349/600\n",
      "14390/14390 [==============================] - 0s 24us/step - loss: 1418260.4474 - val_loss: 1910946.8392\n",
      "Epoch 350/600\n",
      "14390/14390 [==============================] - 0s 20us/step - loss: 1436159.3883 - val_loss: 1495357.8489\n",
      "Epoch 351/600\n",
      "14390/14390 [==============================] - 0s 33us/step - loss: 1446782.2598 - val_loss: 1803109.4129\n",
      "Epoch 352/600\n",
      "14390/14390 [==============================] - 1s 36us/step - loss: 1428153.2842 - val_loss: 1781789.3073\n",
      "Epoch 353/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1421898.7643 - val_loss: 1672817.5161\n",
      "Epoch 354/600\n",
      "14390/14390 [==============================] - 0s 16us/step - loss: 1417565.8450 - val_loss: 2005600.4734\n",
      "Epoch 355/600\n",
      "14390/14390 [==============================] - 0s 15us/step - loss: 1496754.0515 - val_loss: 1822733.4687\n",
      "Epoch 356/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1416075.1319 - val_loss: 1808702.8626\n",
      "Epoch 357/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1427263.9468 - val_loss: 1629772.3437\n",
      "Epoch 358/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1428344.4915 - val_loss: 1668196.5446\n",
      "Epoch 359/600\n",
      "14390/14390 [==============================] - 0s 22us/step - loss: 1425491.8191 - val_loss: 1746025.1499\n",
      "Epoch 360/600\n",
      "14390/14390 [==============================] - 0s 33us/step - loss: 1423411.4300 - val_loss: 1864192.6714\n",
      "Epoch 361/600\n",
      "14390/14390 [==============================] - 1s 78us/step - loss: 1441717.7827 - val_loss: 1922549.5149\n",
      "Epoch 362/600\n",
      "14390/14390 [==============================] - 1s 74us/step - loss: 1452578.3437 - val_loss: 1499791.4571\n",
      "Epoch 363/600\n",
      "14390/14390 [==============================] - 0s 21us/step - loss: 1431860.4275 - val_loss: 1645464.1374\n",
      "Epoch 364/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1400432.2799 - val_loss: 1696857.6406\n",
      "Epoch 365/600\n",
      "14390/14390 [==============================] - 1s 43us/step - loss: 1421837.0425 - val_loss: 1532982.8744\n",
      "Epoch 366/600\n",
      "14390/14390 [==============================] - 1s 49us/step - loss: 1426696.2252 - val_loss: 1828952.2256\n",
      "Epoch 367/600\n",
      "14390/14390 [==============================] - 1s 68us/step - loss: 1412033.7973 - val_loss: 1624969.8434\n",
      "Epoch 368/600\n",
      "14390/14390 [==============================] - 0s 29us/step - loss: 1420698.5640 - val_loss: 1605721.9282\n",
      "Epoch 369/600\n",
      "14390/14390 [==============================] - 1s 36us/step - loss: 1461643.6390 - val_loss: 1615944.6046\n",
      "Epoch 370/600\n",
      "14390/14390 [==============================] - 0s 21us/step - loss: 1426296.9147 - val_loss: 1918660.9246\n",
      "Epoch 371/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1446627.1499 - val_loss: 1901057.8594\n",
      "Epoch 372/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1441405.9006 - val_loss: 1838671.8788\n",
      "Epoch 373/600\n",
      "14390/14390 [==============================] - 0s 27us/step - loss: 1420611.1822 - val_loss: 1931494.1420\n",
      "Epoch 374/600\n",
      "14390/14390 [==============================] - 0s 21us/step - loss: 1422754.3985 - val_loss: 1906946.3292\n",
      "Epoch 375/600\n",
      "14390/14390 [==============================] - 1s 37us/step - loss: 1428989.1319 - val_loss: 1579489.5095\n",
      "Epoch 376/600\n",
      "14390/14390 [==============================] - 0s 21us/step - loss: 1459757.0059 - val_loss: 1777940.4428\n",
      "Epoch 377/600\n",
      "14390/14390 [==============================] - 1s 47us/step - loss: 1438263.0394 - val_loss: 1760810.3716\n",
      "Epoch 378/600\n",
      "14390/14390 [==============================] - 0s 34us/step - loss: 1430548.1719 - val_loss: 2047197.7785\n",
      "Epoch 379/600\n",
      "14390/14390 [==============================] - 0s 28us/step - loss: 1458286.2700 - val_loss: 1622840.4880\n",
      "Epoch 380/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1434618.0927 - val_loss: 1852193.7605\n",
      "Epoch 381/600\n",
      "14390/14390 [==============================] - 0s 22us/step - loss: 1454008.5355 - val_loss: 1519872.0722\n",
      "Epoch 382/600\n",
      "14390/14390 [==============================] - 0s 28us/step - loss: 1448530.0596 - val_loss: 1543716.7274\n",
      "Epoch 383/600\n",
      "14390/14390 [==============================] - 1s 45us/step - loss: 1472074.3782 - val_loss: 2000035.9948\n",
      "Epoch 384/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1494894.1867 - val_loss: 1894254.9111\n",
      "Epoch 385/600\n",
      "14390/14390 [==============================] - 0s 28us/step - loss: 1429701.1554 - val_loss: 1705639.3124\n",
      "Epoch 386/600\n",
      "14390/14390 [==============================] - 0s 31us/step - loss: 1405842.1812 - val_loss: 1623305.7055\n",
      "Epoch 387/600\n",
      "14390/14390 [==============================] - 1s 50us/step - loss: 1402350.6562 - val_loss: 1671796.2682\n",
      "Epoch 388/600\n",
      "14390/14390 [==============================] - 0s 21us/step - loss: 1430573.3971 - val_loss: 2044100.0340\n",
      "Epoch 389/600\n",
      "14390/14390 [==============================] - 0s 20us/step - loss: 1488260.1169 - val_loss: 1714599.3253\n",
      "Epoch 390/600\n",
      "14390/14390 [==============================] - 0s 16us/step - loss: 1415283.9532 - val_loss: 1570899.8136\n",
      "Epoch 391/600\n",
      "14390/14390 [==============================] - 0s 14us/step - loss: 1415870.5600 - val_loss: 1780597.4336\n",
      "Epoch 392/600\n",
      "14390/14390 [==============================] - 0s 29us/step - loss: 1425260.7465 - val_loss: 1876387.1719\n",
      "Epoch 393/600\n",
      "14390/14390 [==============================] - 1s 88us/step - loss: 1407275.3760 - val_loss: 1446281.4630\n",
      "Epoch 394/600\n",
      "14390/14390 [==============================] - 0s 27us/step - loss: 1472732.9532 - val_loss: 1569531.1330\n",
      "Epoch 395/600\n",
      "14390/14390 [==============================] - 0s 14us/step - loss: 1406268.8729 - val_loss: 1714496.0424\n",
      "Epoch 396/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1406577.8266 - val_loss: 1527196.8095\n",
      "Epoch 397/600\n",
      "14390/14390 [==============================] - 0s 20us/step - loss: 1438227.4418 - val_loss: 1544034.0678\n",
      "Epoch 398/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1436876.3932 - val_loss: 1809599.1977\n",
      "Epoch 399/600\n",
      "14390/14390 [==============================] - 0s 29us/step - loss: 1412357.5148 - val_loss: 1763224.0366\n",
      "Epoch 400/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1437370.3794 - val_loss: 1636971.8480\n",
      "Epoch 401/600\n",
      "14390/14390 [==============================] - 1s 69us/step - loss: 1429478.1255 - val_loss: 1746381.1343\n",
      "Epoch 402/600\n",
      "14390/14390 [==============================] - 1s 57us/step - loss: 1399356.9122 - val_loss: 1558344.8537\n",
      "Epoch 403/600\n",
      "14390/14390 [==============================] - 0s 32us/step - loss: 1442465.4882 - val_loss: 1555373.1098\n",
      "Epoch 404/600\n",
      "14390/14390 [==============================] - 1s 44us/step - loss: 1417876.7443 - val_loss: 1766814.6777\n",
      "Epoch 405/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1416247.1695 - val_loss: 2027305.7727\n",
      "Epoch 406/600\n",
      "14390/14390 [==============================] - 1s 35us/step - loss: 1457284.2690 - val_loss: 1513400.5818\n",
      "Epoch 407/600\n",
      "14390/14390 [==============================] - 0s 33us/step - loss: 1437008.8439 - val_loss: 1675480.5636\n",
      "Epoch 408/600\n",
      "14390/14390 [==============================] - 0s 26us/step - loss: 1404942.5294 - val_loss: 1621734.6670\n",
      "Epoch 409/600\n",
      "14390/14390 [==============================] - 0s 23us/step - loss: 1408319.2307 - val_loss: 2006535.2896\n",
      "Epoch 410/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1414730.1281 - val_loss: 1656054.5333\n",
      "Epoch 411/600\n",
      "14390/14390 [==============================] - 0s 35us/step - loss: 1410012.7322 - val_loss: 1646345.1680\n",
      "Epoch 412/600\n",
      "14390/14390 [==============================] - 1s 40us/step - loss: 1398497.5607 - val_loss: 1638554.4157\n",
      "Epoch 413/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1402258.7559 - val_loss: 1559876.9666\n",
      "Epoch 414/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1414433.8379 - val_loss: 1940917.2355\n",
      "Epoch 415/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1449354.8298 - val_loss: 1679556.9146\n",
      "Epoch 416/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1402542.1629 - val_loss: 1850927.2806\n",
      "Epoch 417/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1412135.3813 - val_loss: 1685790.9479\n",
      "Epoch 418/600\n",
      "14390/14390 [==============================] - 0s 21us/step - loss: 1404086.0166 - val_loss: 2073076.6337\n",
      "Epoch 419/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1449963.1803 - val_loss: 1628538.4457\n",
      "Epoch 420/600\n",
      "14390/14390 [==============================] - 1s 55us/step - loss: 1414519.5640 - val_loss: 1760214.3984\n",
      "Epoch 421/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1404785.4089 - val_loss: 1562414.0493\n",
      "Epoch 422/600\n",
      "14390/14390 [==============================] - 1s 44us/step - loss: 1422282.6392 - val_loss: 1919764.6784\n",
      "Epoch 423/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1392377.8872 - val_loss: 1956569.6426\n",
      "Epoch 424/600\n",
      "14390/14390 [==============================] - 0s 21us/step - loss: 1401476.9635 - val_loss: 1828415.7812\n",
      "Epoch 425/600\n",
      "14390/14390 [==============================] - 1s 85us/step - loss: 1422354.2901 - val_loss: 1875043.3625\n",
      "Epoch 426/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14390/14390 [==============================] - 1s 96us/step - loss: 1411111.0134 - val_loss: 1759580.3133\n",
      "Epoch 427/600\n",
      "14390/14390 [==============================] - 1s 51us/step - loss: 1413333.1306 - val_loss: 1647851.7083\n",
      "Epoch 428/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1420250.0061 - val_loss: 1472349.3386\n",
      "Epoch 429/600\n",
      "14390/14390 [==============================] - 0s 15us/step - loss: 1423336.1755 - val_loss: 1553260.0918\n",
      "Epoch 430/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1438178.0725 - val_loss: 1787022.6808\n",
      "Epoch 431/600\n",
      "14390/14390 [==============================] - 0s 15us/step - loss: 1448474.7787 - val_loss: 1999692.5320\n",
      "Epoch 432/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1422667.0265 - val_loss: 2087969.1936\n",
      "Epoch 433/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1465089.5617 - val_loss: 2003374.4486\n",
      "Epoch 434/600\n",
      "14390/14390 [==============================] - 0s 30us/step - loss: 1449090.9365 - val_loss: 1667184.0820\n",
      "Epoch 435/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1420363.0705 - val_loss: 1529779.4926\n",
      "Epoch 436/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1398689.8612 - val_loss: 1718200.6075\n",
      "Epoch 437/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1403449.6858 - val_loss: 1705661.3229\n",
      "Epoch 438/600\n",
      "14390/14390 [==============================] - 0s 22us/step - loss: 1398421.5924 - val_loss: 1706368.7511\n",
      "Epoch 439/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1391416.0466 - val_loss: 1641295.2648\n",
      "Epoch 440/600\n",
      "14390/14390 [==============================] - 0s 21us/step - loss: 1387235.1820 - val_loss: 1774626.3449\n",
      "Epoch 441/600\n",
      "14390/14390 [==============================] - 0s 20us/step - loss: 1390706.3432 - val_loss: 1670203.9321\n",
      "Epoch 442/600\n",
      "14390/14390 [==============================] - 0s 35us/step - loss: 1396124.7022 - val_loss: 1676502.9340\n",
      "Epoch 443/600\n",
      "14390/14390 [==============================] - 1s 36us/step - loss: 1425846.7688 - val_loss: 1986308.4556\n",
      "Epoch 444/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1483306.4291 - val_loss: 1482020.6515\n",
      "Epoch 445/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1406377.7017 - val_loss: 1780285.8343\n",
      "Epoch 446/600\n",
      "14390/14390 [==============================] - 0s 28us/step - loss: 1409662.9544 - val_loss: 1862822.2394\n",
      "Epoch 447/600\n",
      "14390/14390 [==============================] - 0s 32us/step - loss: 1403837.3839 - val_loss: 1686711.9783\n",
      "Epoch 448/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1379162.7990 - val_loss: 1839815.7847\n",
      "Epoch 449/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1394567.0773 - val_loss: 1701454.8912\n",
      "Epoch 450/600\n",
      "14390/14390 [==============================] - 0s 16us/step - loss: 1394223.3497 - val_loss: 1815845.4237\n",
      "Epoch 451/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1385618.8162 - val_loss: 1510342.1345\n",
      "Epoch 452/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1403445.3382 - val_loss: 1758368.8201\n",
      "Epoch 453/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1419944.5279 - val_loss: 1739243.8195\n",
      "Epoch 454/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1457836.9125 - val_loss: 1748359.0399\n",
      "Epoch 455/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1401554.1301 - val_loss: 1660304.4499\n",
      "Epoch 456/600\n",
      "14390/14390 [==============================] - 0s 32us/step - loss: 1391386.1839 - val_loss: 1669953.7226\n",
      "Epoch 457/600\n",
      "14390/14390 [==============================] - 0s 21us/step - loss: 1402743.6758 - val_loss: 1650075.6146\n",
      "Epoch 458/600\n",
      "14390/14390 [==============================] - 1s 56us/step - loss: 1410271.8412 - val_loss: 1645387.9901\n",
      "Epoch 459/600\n",
      "14390/14390 [==============================] - 1s 64us/step - loss: 1401717.6329 - val_loss: 2097720.0098\n",
      "Epoch 460/600\n",
      "14390/14390 [==============================] - 1s 51us/step - loss: 1434021.9475 - val_loss: 1581554.6261\n",
      "Epoch 461/600\n",
      "14390/14390 [==============================] - 0s 16us/step - loss: 1388401.0283 - val_loss: 1881480.0937\n",
      "Epoch 462/600\n",
      "14390/14390 [==============================] - 0s 23us/step - loss: 1390877.5178 - val_loss: 1740817.4093\n",
      "Epoch 463/600\n",
      "14390/14390 [==============================] - 1s 50us/step - loss: 1385947.6463 - val_loss: 1454172.6828\n",
      "Epoch 464/600\n",
      "14390/14390 [==============================] - 0s 24us/step - loss: 1434724.2626 - val_loss: 1649874.0186\n",
      "Epoch 465/600\n",
      "14390/14390 [==============================] - 0s 22us/step - loss: 1384044.2782 - val_loss: 1666450.5682\n",
      "Epoch 466/600\n",
      "14390/14390 [==============================] - 0s 29us/step - loss: 1404775.2474 - val_loss: 1500039.5723\n",
      "Epoch 467/600\n",
      "14390/14390 [==============================] - 0s 20us/step - loss: 1409674.9700 - val_loss: 1770103.9873\n",
      "Epoch 468/600\n",
      "14390/14390 [==============================] - 0s 30us/step - loss: 1397585.9380 - val_loss: 1771498.8666\n",
      "Epoch 469/600\n",
      "14390/14390 [==============================] - 0s 26us/step - loss: 1387574.7014 - val_loss: 1753458.8899\n",
      "Epoch 470/600\n",
      "14390/14390 [==============================] - 0s 22us/step - loss: 1387180.9706 - val_loss: 1933007.1873\n",
      "Epoch 471/600\n",
      "14390/14390 [==============================] - 0s 20us/step - loss: 1395340.3298 - val_loss: 1663812.1600\n",
      "Epoch 472/600\n",
      "14390/14390 [==============================] - 1s 58us/step - loss: 1387274.5229 - val_loss: 1824932.0164\n",
      "Epoch 473/600\n",
      "14390/14390 [==============================] - 0s 31us/step - loss: 1402371.1738 - val_loss: 1683867.8869\n",
      "Epoch 474/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1398369.8870 - val_loss: 1786653.8991\n",
      "Epoch 475/600\n",
      "14390/14390 [==============================] - 0s 25us/step - loss: 1403933.9261 - val_loss: 1720488.8469\n",
      "Epoch 476/600\n",
      "14390/14390 [==============================] - 2s 107us/step - loss: 1414602.5649 - val_loss: 1654414.7631\n",
      "Epoch 477/600\n",
      "14390/14390 [==============================] - 1s 82us/step - loss: 1413851.4646 - val_loss: 1516463.5611\n",
      "Epoch 478/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1380532.9631 - val_loss: 1678552.7060\n",
      "Epoch 479/600\n",
      "14390/14390 [==============================] - 0s 15us/step - loss: 1392315.0718 - val_loss: 1687236.4641\n",
      "Epoch 480/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1377335.8919 - val_loss: 1535801.4928\n",
      "Epoch 481/600\n",
      "14390/14390 [==============================] - 0s 16us/step - loss: 1389937.0337 - val_loss: 1743233.3405\n",
      "Epoch 482/600\n",
      "14390/14390 [==============================] - 0s 15us/step - loss: 1387578.9405 - val_loss: 1765518.2266\n",
      "Epoch 483/600\n",
      "14390/14390 [==============================] - 0s 21us/step - loss: 1400691.7681 - val_loss: 1539415.5561\n",
      "Epoch 484/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1376816.3392 - val_loss: 1603187.1868\n",
      "Epoch 485/600\n",
      "14390/14390 [==============================] - 0s 21us/step - loss: 1404358.3339 - val_loss: 1578450.1822\n",
      "Epoch 486/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1403155.1552 - val_loss: 1833454.4062\n",
      "Epoch 487/600\n",
      "14390/14390 [==============================] - 0s 16us/step - loss: 1399732.6548 - val_loss: 1415299.7712\n",
      "Epoch 488/600\n",
      "14390/14390 [==============================] - 0s 16us/step - loss: 1452173.5449 - val_loss: 1719378.9879\n",
      "Epoch 489/600\n",
      "14390/14390 [==============================] - 0s 16us/step - loss: 1400179.8286 - val_loss: 1642252.7278\n",
      "Epoch 490/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1397323.6409 - val_loss: 1534054.2091\n",
      "Epoch 491/600\n",
      "14390/14390 [==============================] - 0s 20us/step - loss: 1385395.0667 - val_loss: 1852282.2980\n",
      "Epoch 492/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1439148.3437 - val_loss: 2001720.8365\n",
      "Epoch 493/600\n",
      "14390/14390 [==============================] - 1s 36us/step - loss: 1420064.8316 - val_loss: 1651743.2210\n",
      "Epoch 494/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1397662.5249 - val_loss: 1640519.8873\n",
      "Epoch 495/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1385094.1890 - val_loss: 1535813.2819\n",
      "Epoch 496/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1399818.1714 - val_loss: 1487156.6369\n",
      "Epoch 497/600\n",
      "14390/14390 [==============================] - 0s 26us/step - loss: 1388094.3184 - val_loss: 1771683.2399\n",
      "Epoch 498/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1390058.5592 - val_loss: 1580986.6868\n",
      "Epoch 499/600\n",
      "14390/14390 [==============================] - 0s 21us/step - loss: 1394448.6972 - val_loss: 1600509.4700\n",
      "Epoch 500/600\n",
      "14390/14390 [==============================] - 0s 22us/step - loss: 1407710.4501 - val_loss: 1999035.9432\n",
      "Epoch 501/600\n",
      "14390/14390 [==============================] - 0s 26us/step - loss: 1412644.6665 - val_loss: 1589747.9045\n",
      "Epoch 502/600\n",
      "14390/14390 [==============================] - 0s 34us/step - loss: 1382300.5348 - val_loss: 1761761.7033\n",
      "Epoch 503/600\n",
      "14390/14390 [==============================] - 1s 74us/step - loss: 1379257.8032 - val_loss: 1756768.1502\n",
      "Epoch 504/600\n",
      "14390/14390 [==============================] - 1s 80us/step - loss: 1371783.5568 - val_loss: 1599650.1590\n",
      "Epoch 505/600\n",
      "14390/14390 [==============================] - 0s 31us/step - loss: 1374976.3816 - val_loss: 1603122.4629\n",
      "Epoch 506/600\n",
      "14390/14390 [==============================] - 0s 20us/step - loss: 1411458.9075 - val_loss: 1778520.7915\n",
      "Epoch 507/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1390317.3159 - val_loss: 1531143.5295\n",
      "Epoch 508/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1402024.5524 - val_loss: 1688736.0095\n",
      "Epoch 509/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1374283.6930 - val_loss: 1614402.3075\n",
      "Epoch 510/600\n",
      "14390/14390 [==============================] - 0s 21us/step - loss: 1398562.9026 - val_loss: 1573296.2872\n",
      "Epoch 511/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1415445.3238 - val_loss: 1781751.4277\n",
      "Epoch 512/600\n",
      "14390/14390 [==============================] - 0s 33us/step - loss: 1397138.5217 - val_loss: 1562430.0356\n",
      "Epoch 513/600\n",
      "14390/14390 [==============================] - 1s 85us/step - loss: 1396757.5526 - val_loss: 1800291.4045\n",
      "Epoch 514/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1391319.6815 - val_loss: 1544383.8419\n",
      "Epoch 515/600\n",
      "14390/14390 [==============================] - 1s 65us/step - loss: 1394850.6825 - val_loss: 1748094.6445\n",
      "Epoch 516/600\n",
      "14390/14390 [==============================] - 1s 56us/step - loss: 1366350.4168 - val_loss: 1515447.4639\n",
      "Epoch 517/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1389424.2891 - val_loss: 1560733.2967\n",
      "Epoch 518/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1375034.3877 - val_loss: 1743593.7814\n",
      "Epoch 519/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1372320.8383 - val_loss: 1697328.1990\n",
      "Epoch 520/600\n",
      "14390/14390 [==============================] - 1s 35us/step - loss: 1385175.4804 - val_loss: 1815236.8508\n",
      "Epoch 521/600\n",
      "14390/14390 [==============================] - 0s 20us/step - loss: 1397696.0349 - val_loss: 1498602.0861\n",
      "Epoch 522/600\n",
      "14390/14390 [==============================] - 0s 23us/step - loss: 1402998.4111 - val_loss: 1702814.6474\n",
      "Epoch 523/600\n",
      "14390/14390 [==============================] - 0s 27us/step - loss: 1378093.2905 - val_loss: 1784588.5169\n",
      "Epoch 524/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1384014.4105 - val_loss: 1853080.7146\n",
      "Epoch 525/600\n",
      "14390/14390 [==============================] - 1s 53us/step - loss: 1368907.8251 - val_loss: 1629940.8619\n",
      "Epoch 526/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1369038.3449 - val_loss: 1739914.7371\n",
      "Epoch 527/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1395469.4095 - val_loss: 1905357.5002\n",
      "Epoch 528/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1442433.9013 - val_loss: 1672815.1095\n",
      "Epoch 529/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1427573.4693 - val_loss: 1622080.9385\n",
      "Epoch 530/600\n",
      "14390/14390 [==============================] - 0s 23us/step - loss: 1379492.3582 - val_loss: 1587774.3298\n",
      "Epoch 531/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1407029.6747 - val_loss: 1852628.0535\n",
      "Epoch 532/600\n",
      "14390/14390 [==============================] - 0s 15us/step - loss: 1419828.3510 - val_loss: 1585197.4276\n",
      "Epoch 533/600\n",
      "14390/14390 [==============================] - 0s 16us/step - loss: 1399299.3569 - val_loss: 1952337.8834\n",
      "Epoch 534/600\n",
      "14390/14390 [==============================] - 1s 47us/step - loss: 1430911.4172 - val_loss: 1761951.5405\n",
      "Epoch 535/600\n",
      "14390/14390 [==============================] - 0s 26us/step - loss: 1391472.8772 - val_loss: 1734370.8007\n",
      "Epoch 536/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1384138.3593 - val_loss: 1554734.7907\n",
      "Epoch 537/600\n",
      "14390/14390 [==============================] - 1s 43us/step - loss: 1374323.2449 - val_loss: 1886863.2486\n",
      "Epoch 538/600\n",
      "14390/14390 [==============================] - 1s 41us/step - loss: 1366084.8537 - val_loss: 1744313.9185\n",
      "Epoch 539/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1371081.8691 - val_loss: 2098424.2777\n",
      "Epoch 540/600\n",
      "14390/14390 [==============================] - 1s 76us/step - loss: 1418026.8910 - val_loss: 1998225.6488\n",
      "Epoch 541/600\n",
      "14390/14390 [==============================] - 1s 86us/step - loss: 1406123.6192 - val_loss: 1587963.0260\n",
      "Epoch 542/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1374966.5702 - val_loss: 1604883.7433\n",
      "Epoch 543/600\n",
      "14390/14390 [==============================] - 1s 79us/step - loss: 1382934.8015 - val_loss: 1893439.8047\n",
      "Epoch 544/600\n",
      "14390/14390 [==============================] - 0s 30us/step - loss: 1387802.9953 - val_loss: 1723698.4719\n",
      "Epoch 545/600\n",
      "14390/14390 [==============================] - 0s 20us/step - loss: 1366616.6860 - val_loss: 1678751.6659\n",
      "Epoch 546/600\n",
      "14390/14390 [==============================] - 0s 16us/step - loss: 1374307.5719 - val_loss: 1942032.6169\n",
      "Epoch 547/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1386545.1304 - val_loss: 1773452.5656\n",
      "Epoch 548/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1387764.6334 - val_loss: 1763550.3898\n",
      "Epoch 549/600\n",
      "14390/14390 [==============================] - 1s 55us/step - loss: 1389806.4483 - val_loss: 1739730.6724\n",
      "Epoch 550/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1379146.4670 - val_loss: 1624304.4091\n",
      "Epoch 551/600\n",
      "14390/14390 [==============================] - 0s 29us/step - loss: 1376708.7381 - val_loss: 1761685.8146\n",
      "Epoch 552/600\n",
      "14390/14390 [==============================] - 0s 25us/step - loss: 1382887.5013 - val_loss: 1904703.9807\n",
      "Epoch 553/600\n",
      "14390/14390 [==============================] - 1s 38us/step - loss: 1394998.1956 - val_loss: 1571634.8310\n",
      "Epoch 554/600\n",
      "14390/14390 [==============================] - 1s 38us/step - loss: 1383991.4026 - val_loss: 1858343.9964\n",
      "Epoch 555/600\n",
      "14390/14390 [==============================] - 1s 38us/step - loss: 1377514.0113 - val_loss: 1713236.7037\n",
      "Epoch 556/600\n",
      "14390/14390 [==============================] - 1s 35us/step - loss: 1363026.7537 - val_loss: 1854735.8927\n",
      "Epoch 557/600\n",
      "14390/14390 [==============================] - 1s 44us/step - loss: 1374753.3424 - val_loss: 1817986.1436\n",
      "Epoch 558/600\n",
      "14390/14390 [==============================] - 1s 66us/step - loss: 1390710.8713 - val_loss: 1857352.6417\n",
      "Epoch 559/600\n",
      "14390/14390 [==============================] - 0s 16us/step - loss: 1397198.4300 - val_loss: 1701853.3634\n",
      "Epoch 560/600\n",
      "14390/14390 [==============================] - 0s 15us/step - loss: 1370992.7123 - val_loss: 1683426.4055\n",
      "Epoch 561/600\n",
      "14390/14390 [==============================] - 0s 31us/step - loss: 1366923.8440 - val_loss: 1531726.3490\n",
      "Epoch 562/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14390/14390 [==============================] - 0s 16us/step - loss: 1391278.3669 - val_loss: 1874789.8528\n",
      "Epoch 563/600\n",
      "14390/14390 [==============================] - 0s 28us/step - loss: 1384825.3530 - val_loss: 1572713.4257\n",
      "Epoch 564/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1399234.1547 - val_loss: 1897250.4791\n",
      "Epoch 565/600\n",
      "14390/14390 [==============================] - 0s 15us/step - loss: 1367171.2369 - val_loss: 1592219.7778\n",
      "Epoch 566/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1399489.6961 - val_loss: 1618539.1617\n",
      "Epoch 567/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1373139.1120 - val_loss: 1489103.1083\n",
      "Epoch 568/600\n",
      "14390/14390 [==============================] - 0s 16us/step - loss: 1390030.6445 - val_loss: 1497889.3185\n",
      "Epoch 569/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1388858.2955 - val_loss: 1777886.1009\n",
      "Epoch 570/600\n",
      "14390/14390 [==============================] - 0s 31us/step - loss: 1391526.3776 - val_loss: 1554673.7592\n",
      "Epoch 571/600\n",
      "14390/14390 [==============================] - 0s 21us/step - loss: 1373570.1626 - val_loss: 1720668.6990\n",
      "Epoch 572/600\n",
      "14390/14390 [==============================] - 0s 27us/step - loss: 1355551.0751 - val_loss: 1841277.3727\n",
      "Epoch 573/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1392921.4941 - val_loss: 1516201.0661\n",
      "Epoch 574/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1421023.5597 - val_loss: 1970445.5324\n",
      "Epoch 575/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1384199.0765 - val_loss: 1546166.3057\n",
      "Epoch 576/600\n",
      "14390/14390 [==============================] - 0s 18us/step - loss: 1378684.5328 - val_loss: 1611726.4085\n",
      "Epoch 577/600\n",
      "14390/14390 [==============================] - 0s 16us/step - loss: 1368128.2346 - val_loss: 1913867.7961\n",
      "Epoch 578/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1402442.3494 - val_loss: 1633174.3513\n",
      "Epoch 579/600\n",
      "14390/14390 [==============================] - 0s 16us/step - loss: 1427614.3583 - val_loss: 1528779.4031\n",
      "Epoch 580/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1402676.5992 - val_loss: 1496978.6300\n",
      "Epoch 581/600\n",
      "14390/14390 [==============================] - 1s 36us/step - loss: 1371025.9387 - val_loss: 1426381.0260\n",
      "Epoch 582/600\n",
      "14390/14390 [==============================] - 1s 43us/step - loss: 1470920.3295 - val_loss: 1743080.9579\n",
      "Epoch 583/600\n",
      "14390/14390 [==============================] - 1s 51us/step - loss: 1369189.9520 - val_loss: 1861337.9644\n",
      "Epoch 584/600\n",
      "14390/14390 [==============================] - 1s 48us/step - loss: 1375023.0214 - val_loss: 1663678.8819\n",
      "Epoch 585/600\n",
      "14390/14390 [==============================] - 0s 31us/step - loss: 1378578.5616 - val_loss: 1740752.1489\n",
      "Epoch 586/600\n",
      "14390/14390 [==============================] - 0s 16us/step - loss: 1364503.9813 - val_loss: 1668885.1515\n",
      "Epoch 587/600\n",
      "14390/14390 [==============================] - 0s 15us/step - loss: 1374340.5605 - val_loss: 2166089.7678\n",
      "Epoch 588/600\n",
      "14390/14390 [==============================] - 0s 27us/step - loss: 1425875.3761 - val_loss: 1629144.6438\n",
      "Epoch 589/600\n",
      "14390/14390 [==============================] - 1s 57us/step - loss: 1382044.9513 - val_loss: 1639581.4494\n",
      "Epoch 590/600\n",
      "14390/14390 [==============================] - 0s 25us/step - loss: 1394125.7773 - val_loss: 1663092.4255\n",
      "Epoch 591/600\n",
      "14390/14390 [==============================] - 0s 17us/step - loss: 1349400.9800 - val_loss: 1695325.6377\n",
      "Epoch 592/600\n",
      "14390/14390 [==============================] - 0s 28us/step - loss: 1375434.5994 - val_loss: 1708876.0704\n",
      "Epoch 593/600\n",
      "14390/14390 [==============================] - 0s 20us/step - loss: 1394498.1161 - val_loss: 1643790.0668\n",
      "Epoch 594/600\n",
      "14390/14390 [==============================] - 0s 16us/step - loss: 1396344.9486 - val_loss: 1456440.2095\n",
      "Epoch 595/600\n",
      "14390/14390 [==============================] - 0s 16us/step - loss: 1513173.8758 - val_loss: 1715213.2001\n",
      "Epoch 596/600\n",
      "14390/14390 [==============================] - 0s 19us/step - loss: 1395635.6257 - val_loss: 1760314.3887\n",
      "Epoch 597/600\n",
      "14390/14390 [==============================] - 1s 54us/step - loss: 1364400.5994 - val_loss: 1720976.5902\n",
      "Epoch 598/600\n",
      "14390/14390 [==============================] - 1s 66us/step - loss: 1436430.2476 - val_loss: 1471176.5987\n",
      "Epoch 599/600\n",
      "14390/14390 [==============================] - 1s 80us/step - loss: 1402924.7496 - val_loss: 1710977.7611\n",
      "Epoch 600/600\n",
      "14390/14390 [==============================] - 1s 65us/step - loss: 1366963.2811 - val_loss: 1601553.8999\n",
      "NN score: 1367997.3056 (37969.3186)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(NNClassifier())\n",
    "print(\"NN score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5a66c27c-be80-4ec0-8953-eaeb2a7dd2e7",
    "_execution_state": "idle",
    "_uuid": "14b60a7e4296cccb39042c9c625a1480d59a01c1"
   },
   "source": [
    "### Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_cell_guid": "af13332c-fd37-40bb-a078-6bad6caaa2ab",
    "_execution_state": "idle",
    "_uuid": "9a983f0f62a0dde7689b20a8e52022bb189478b4"
   },
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=112, max_depth=9,\n",
    "                                  min_samples_leaf=25, max_features=47,\n",
    "                                   loss='lad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "_cell_guid": "43dd152f-7c49-41b6-8f8e-a5864b1e2a71",
    "_execution_state": "idle",
    "_uuid": "e9d8c4bd191f77d8d275f53c0c1a6cf344151294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting score: 1273835.5522 (33283.3347)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d44ac87e-bf01-440b-ab22-b2868eb6ae48",
    "_execution_state": "idle",
    "_uuid": "53d7991f7dd03fcd7fb5ab1ec26fcd0614d002d3"
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "_cell_guid": "ed738a4c-c246-443c-a3c1-39df25f988b7",
    "_execution_state": "idle",
    "_uuid": "57c24b596ceb46d6f32ebf9501d672d7e469c15b"
   },
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.7, gamma=0.01,\n",
    "                             learning_rate=0.05, max_depth=10, \n",
    "                            n_estimators=500,\n",
    "                             reg_alpha=0.7, reg_lambda=0,\n",
    "                             subsample=0.8, silent=1, nthread =-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "_cell_guid": "30738ecc-39f8-44ed-9f42-68518beb7e6a",
    "_execution_state": "idle",
    "_uuid": "5f52ccf39d01165e61a7c6be8b788be4e58e286b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgboost score: 1394365.2318 (35655.3379)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(model_xgb)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a43ca74d-093c-4a56-a76c-b3223bf82fbc",
    "_execution_state": "idle",
    "_uuid": "460f3ccf7d5c33ea9f8a826bbf056d759e7b5119"
   },
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_cell_guid": "dd84d7db-3f83-4e4e-b02f-7632ca5ee4ac",
    "_execution_state": "idle",
    "_uuid": "4c94cf90f0ef0d350c5e66f3bd397865bfcc61ae"
   },
   "outputs": [],
   "source": [
    "model_lgb = lgb.LGBMRegressor(objective='mean_absolute_error', num_leaves=10,\n",
    "                              learning_rate=0.05, n_estimators=1400,\n",
    "                              bagging_fraction = 0.8,\n",
    "                              bagging_freq = 3, feature_fraction = 0.8,\n",
    "                              min_data_in_leaf=40,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "_cell_guid": "41e0eab9-630d-48d3-905b-e4663aad2262",
    "_execution_state": "idle",
    "_uuid": "5cd5377ee097fbc6fd14b42b4ea654221b097e59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM score: 1236379.6835 (31888.2631)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(model_lgb)\n",
    "print(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d0145496-896a-44e3-b01b-e12546328f06",
    "_execution_state": "idle",
    "_uuid": "5ecc887f1ab4001c872862cecf3a0b350ac51a23"
   },
   "source": [
    "### Averaged base models class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_cell_guid": "49e44ad6-8dc4-4a67-8079-adbac934fec4",
    "_execution_state": "idle",
    "_uuid": "ff3ee5889bcac40847909c3a71285d2b8f9d431f"
   },
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x, _ in self.models]\n",
    "        self.weights = [weight for _, weight in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model  in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        sum_weight = 0\n",
    "        for weight in self.weights:\n",
    "            sum_weight += weight\n",
    "            \n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) * (self.weights[i] / sum_weight) for i, model in enumerate(self.models_)\n",
    "        ])\n",
    "        return np.sum(predictions, axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "_cell_guid": "d480916f-89e7-4bcc-9b9d-b54492591654",
    "_execution_state": "idle",
    "_uuid": "81ce9e148b7e735f465b4b6508511dea44fbf791"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Averaged base models score: 1234194.5062 (34013.4975)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "averaged_models = AveragingModels(models = ((GBoost, 1), (model_lgb, 1), (NNClassifier(), 1)))\n",
    "\n",
    "score = rmsle_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_cell_guid": "232c3959-c6e1-4535-8ad4-62892edc3f06",
    "_execution_state": "idle",
    "_uuid": "07f9ef433905b61a08a36790254d6a34661f0653"
   },
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    return mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_cell_guid": "e64b2750-1e32-4e91-affb-e583d6ca8722",
    "_execution_state": "busy",
    "_uuid": "8936479533c4bb147ab09f1d2133d8bacbf9afc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17987 samples, validate on 1999 samples\n",
      "Epoch 1/600\n",
      "17987/17987 [==============================] - 1s 62us/step - loss: 7104992.8847 - val_loss: 7237852.6438\n",
      "Epoch 2/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 6880232.9634 - val_loss: 5608119.8517\n",
      "Epoch 3/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 3138289.4080 - val_loss: 2765996.6041\n",
      "Epoch 4/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2623205.6898 - val_loss: 2714323.4240\n",
      "Epoch 5/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2610220.0991 - val_loss: 2711307.5962\n",
      "Epoch 6/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2605865.7815 - val_loss: 2709981.8014\n",
      "Epoch 7/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 2604222.5838 - val_loss: 2712888.9601\n",
      "Epoch 8/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2599806.6765 - val_loss: 2705471.9025\n",
      "Epoch 9/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 2597758.1846 - val_loss: 2705732.3869\n",
      "Epoch 10/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 2596616.4277 - val_loss: 2707818.5029\n",
      "Epoch 11/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2594865.7288 - val_loss: 2701126.1705\n",
      "Epoch 12/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2588307.9131 - val_loss: 2699476.4170\n",
      "Epoch 13/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2589989.2517 - val_loss: 2693822.4381\n",
      "Epoch 14/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 2590257.1493 - val_loss: 2697641.8944\n",
      "Epoch 15/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2583923.6139 - val_loss: 2684549.5279\n",
      "Epoch 16/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2575411.5058 - val_loss: 2684036.8270\n",
      "Epoch 17/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2578918.4058 - val_loss: 2677789.4730\n",
      "Epoch 18/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2569008.8167 - val_loss: 2673680.0937\n",
      "Epoch 19/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2563925.4073 - val_loss: 2670065.1419\n",
      "Epoch 20/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2562308.0788 - val_loss: 2667389.3946\n",
      "Epoch 21/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2553697.4077 - val_loss: 2660662.7051\n",
      "Epoch 22/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2549623.3800 - val_loss: 2652958.0547\n",
      "Epoch 23/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2540312.8464 - val_loss: 2645780.2950\n",
      "Epoch 24/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2535392.6781 - val_loss: 2640336.2130\n",
      "Epoch 25/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2527038.6201 - val_loss: 2628614.3673\n",
      "Epoch 26/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 2520265.5937 - val_loss: 2638369.5634\n",
      "Epoch 27/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2506561.1406 - val_loss: 2609602.2929\n",
      "Epoch 28/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2495130.6708 - val_loss: 2596066.6038\n",
      "Epoch 29/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2478061.0671 - val_loss: 2567961.2049\n",
      "Epoch 30/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2462409.7469 - val_loss: 2556351.8578\n",
      "Epoch 31/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2431928.6342 - val_loss: 2508354.0824\n",
      "Epoch 32/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2403143.0067 - val_loss: 2470649.3821\n",
      "Epoch 33/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2371937.3042 - val_loss: 2417586.9514\n",
      "Epoch 34/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2340322.9607 - val_loss: 2403038.5665\n",
      "Epoch 35/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 2325963.2557 - val_loss: 2404976.4420\n",
      "Epoch 36/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2288790.3959 - val_loss: 2337824.7628\n",
      "Epoch 37/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2263186.7395 - val_loss: 2280539.7745\n",
      "Epoch 38/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2233349.7949 - val_loss: 2236406.7234\n",
      "Epoch 39/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2218115.4759 - val_loss: 2200996.0120\n",
      "Epoch 40/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2187268.0197 - val_loss: 2183224.9740\n",
      "Epoch 41/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2162815.4325 - val_loss: 2152955.1797\n",
      "Epoch 42/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2130396.4455 - val_loss: 2109500.4780\n",
      "Epoch 43/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 2121384.5141 - val_loss: 2122791.8892\n",
      "Epoch 44/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2119709.0586 - val_loss: 2094066.1228\n",
      "Epoch 45/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2083137.5617 - val_loss: 2021200.6562\n",
      "Epoch 46/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 2068268.2338 - val_loss: 1998581.5197\n",
      "Epoch 47/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 2047684.0287 - val_loss: 2006451.8916\n",
      "Epoch 48/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 2029490.5201 - val_loss: 2035453.6535\n",
      "Epoch 49/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 2018409.9063 - val_loss: 2022511.8295\n",
      "Epoch 50/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1997122.1352 - val_loss: 2019471.4357\n",
      "Epoch 51/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 1989620.4057 - val_loss: 1952749.9330\n",
      "Epoch 52/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1982881.9308 - val_loss: 1977754.6945\n",
      "Epoch 53/600\n",
      "17987/17987 [==============================] - 0s 11us/step - loss: 1980446.2586 - val_loss: 1867537.2916\n",
      "Epoch 54/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1979959.3964 - val_loss: 1918617.0291\n",
      "Epoch 55/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1934205.1449 - val_loss: 1925835.8962\n",
      "Epoch 56/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1933185.7157 - val_loss: 1883125.3337\n",
      "Epoch 57/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 1924547.3899 - val_loss: 1856342.3566\n",
      "Epoch 58/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1914428.4491 - val_loss: 2044981.8289\n",
      "Epoch 59/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1915509.0598 - val_loss: 2051224.5670\n",
      "Epoch 60/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1914935.5269 - val_loss: 1863629.4344\n",
      "Epoch 61/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1884587.7821 - val_loss: 1980378.0859\n",
      "Epoch 62/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 1887876.1485 - val_loss: 1824046.4959\n",
      "Epoch 63/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 1894630.6646 - val_loss: 1785454.1485\n",
      "Epoch 64/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1873914.7290 - val_loss: 1943317.6357\n",
      "Epoch 65/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1863054.7816 - val_loss: 1908039.1360\n",
      "Epoch 66/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1863526.4446 - val_loss: 1859004.7274\n",
      "Epoch 67/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1853693.2059 - val_loss: 1844172.7886\n",
      "Epoch 68/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1858087.4989 - val_loss: 1803666.5238\n",
      "Epoch 69/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1859427.3160 - val_loss: 1980315.4273\n",
      "Epoch 70/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1853599.2047 - val_loss: 1835129.8232\n",
      "Epoch 71/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1838634.1104 - val_loss: 1787662.4823\n",
      "Epoch 72/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1837631.5892 - val_loss: 1884300.5318\n",
      "Epoch 73/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1837873.0608 - val_loss: 1815239.1105\n",
      "Epoch 74/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1855116.5518 - val_loss: 1921092.1933\n",
      "Epoch 75/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 1829343.1203 - val_loss: 1734761.7672\n",
      "Epoch 76/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1842967.9660 - val_loss: 1747879.2548\n",
      "Epoch 77/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1830365.5331 - val_loss: 1914829.6212\n",
      "Epoch 78/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1810699.2795 - val_loss: 1815000.2150\n",
      "Epoch 79/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1813958.3857 - val_loss: 1902173.6973\n",
      "Epoch 80/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1814192.2310 - val_loss: 1747174.7984\n",
      "Epoch 81/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1823597.6246 - val_loss: 1875846.8739\n",
      "Epoch 82/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 1797519.1510 - val_loss: 1723765.8390\n",
      "Epoch 83/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1806166.1876 - val_loss: 1727352.4035\n",
      "Epoch 84/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1804719.3588 - val_loss: 2021071.4564\n",
      "Epoch 85/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1809911.1091 - val_loss: 1889912.9295\n",
      "Epoch 86/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1794592.0600 - val_loss: 1843779.7245\n",
      "Epoch 87/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1792545.1140 - val_loss: 1910870.4114\n",
      "Epoch 88/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1796662.8502 - val_loss: 1793288.7599\n",
      "Epoch 89/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 1787059.0219 - val_loss: 1684752.4644\n",
      "Epoch 90/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1803089.9022 - val_loss: 1750968.1221\n",
      "Epoch 91/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1787891.8805 - val_loss: 1893783.3784\n",
      "Epoch 92/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1791525.8559 - val_loss: 1796998.6785\n",
      "Epoch 93/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1788688.7316 - val_loss: 1701113.9227\n",
      "Epoch 94/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1773649.4892 - val_loss: 1949330.3345\n",
      "Epoch 95/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1772291.3581 - val_loss: 1692850.7180\n",
      "Epoch 96/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1778221.9027 - val_loss: 1756661.0451\n",
      "Epoch 97/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1759233.9448 - val_loss: 1836267.0938\n",
      "Epoch 98/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1763509.0546 - val_loss: 1777440.0146\n",
      "Epoch 99/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1773544.1171 - val_loss: 1704534.6681\n",
      "Epoch 100/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1781272.2301 - val_loss: 1705553.2946\n",
      "Epoch 101/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1762596.1873 - val_loss: 1695013.3592\n",
      "Epoch 102/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1751307.2897 - val_loss: 1809678.4974\n",
      "Epoch 103/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1753072.2804 - val_loss: 1696559.9846\n",
      "Epoch 104/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1774111.9926 - val_loss: 1742780.5567\n",
      "Epoch 105/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1757502.8483 - val_loss: 1838487.8259\n",
      "Epoch 106/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1750091.0348 - val_loss: 1820863.9745\n",
      "Epoch 107/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1761887.7227 - val_loss: 1828370.3846\n",
      "Epoch 108/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1745125.9633 - val_loss: 1807324.2898\n",
      "Epoch 109/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1735822.5668 - val_loss: 1773048.7699\n",
      "Epoch 110/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1736795.2883 - val_loss: 1767847.7007\n",
      "Epoch 111/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1731309.7033 - val_loss: 1862120.9058\n",
      "Epoch 112/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1732668.6659 - val_loss: 1797649.8089\n",
      "Epoch 113/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1731898.3783 - val_loss: 1686488.7697\n",
      "Epoch 114/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1741639.9013 - val_loss: 1816680.4479\n",
      "Epoch 115/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1725074.3662 - val_loss: 1760325.0173\n",
      "Epoch 116/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 1735838.4720 - val_loss: 1665171.2825\n",
      "Epoch 117/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1739866.8826 - val_loss: 1805023.3212\n",
      "Epoch 118/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1721607.1901 - val_loss: 1888483.1513\n",
      "Epoch 119/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1728992.7900 - val_loss: 1734173.8450\n",
      "Epoch 120/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1730308.6537 - val_loss: 1858071.5370\n",
      "Epoch 121/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1740909.3153 - val_loss: 1877709.4430\n",
      "Epoch 122/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1717882.9686 - val_loss: 1817681.3919\n",
      "Epoch 123/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1698287.0662 - val_loss: 1738525.8829\n",
      "Epoch 124/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1698119.0387 - val_loss: 1978025.6187\n",
      "Epoch 125/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1712185.3250 - val_loss: 1788834.6508\n",
      "Epoch 126/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1712568.0216 - val_loss: 1748119.6842\n",
      "Epoch 127/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1731776.3010 - val_loss: 1705677.7558\n",
      "Epoch 128/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1698958.5716 - val_loss: 1951270.0862\n",
      "Epoch 129/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1722076.4206 - val_loss: 1751109.1365\n",
      "Epoch 130/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1702140.0000 - val_loss: 1718827.5483\n",
      "Epoch 131/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1685092.9808 - val_loss: 1802929.1583\n",
      "Epoch 132/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1695050.3480 - val_loss: 1815900.1093\n",
      "Epoch 133/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1675694.5295 - val_loss: 1754439.1819\n",
      "Epoch 134/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1689605.2469 - val_loss: 1788640.5531\n",
      "Epoch 135/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 1705280.3372 - val_loss: 1660266.8243\n",
      "Epoch 136/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1691426.2377 - val_loss: 1699363.7526\n",
      "Epoch 137/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1697460.2207 - val_loss: 1849196.2333\n",
      "Epoch 138/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17987/17987 [==============================] - 0s 9us/step - loss: 1670919.6939 - val_loss: 1923171.9210\n",
      "Epoch 139/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1688851.6594 - val_loss: 1724220.1499\n",
      "Epoch 140/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1678338.4461 - val_loss: 1699742.0730\n",
      "Epoch 141/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 1678578.9032 - val_loss: 1622709.9083\n",
      "Epoch 142/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 1693088.4351 - val_loss: 1615760.8007\n",
      "Epoch 143/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1676237.2178 - val_loss: 1804512.4228\n",
      "Epoch 144/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1672496.1219 - val_loss: 1656930.1419\n",
      "Epoch 145/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1664840.5770 - val_loss: 1690628.8241\n",
      "Epoch 146/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1649745.4024 - val_loss: 1690108.3458\n",
      "Epoch 147/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1667924.5165 - val_loss: 1802339.2619\n",
      "Epoch 148/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1673258.0899 - val_loss: 1862176.3764\n",
      "Epoch 149/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1658017.0980 - val_loss: 1659783.0445\n",
      "Epoch 150/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1658634.0597 - val_loss: 1654721.7266\n",
      "Epoch 151/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1657624.7829 - val_loss: 1875148.5535\n",
      "Epoch 152/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1655778.8519 - val_loss: 1812131.5704\n",
      "Epoch 153/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1671009.7781 - val_loss: 1807942.9423\n",
      "Epoch 154/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1641882.3854 - val_loss: 1858865.7294\n",
      "Epoch 155/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1656523.9986 - val_loss: 1825903.0985\n",
      "Epoch 156/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1642441.3376 - val_loss: 1694252.4924\n",
      "Epoch 157/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1634329.9445 - val_loss: 1632899.0538\n",
      "Epoch 158/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 1647281.1832 - val_loss: 1606606.1871\n",
      "Epoch 159/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1656587.9569 - val_loss: 1741263.7467\n",
      "Epoch 160/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 1649190.8110 - val_loss: 1580022.6057\n",
      "Epoch 161/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1649658.5249 - val_loss: 1653981.9600\n",
      "Epoch 162/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1646247.8334 - val_loss: 1739214.9944\n",
      "Epoch 163/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1633990.8342 - val_loss: 1795871.5091\n",
      "Epoch 164/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1652984.7347 - val_loss: 1903815.2538\n",
      "Epoch 165/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1662752.4403 - val_loss: 1733164.4616\n",
      "Epoch 166/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1645468.7566 - val_loss: 1716857.8903\n",
      "Epoch 167/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1635595.0925 - val_loss: 1933933.4847\n",
      "Epoch 168/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1668238.6720 - val_loss: 1651193.3834\n",
      "Epoch 169/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1633848.8863 - val_loss: 1664865.4664\n",
      "Epoch 170/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1632334.8809 - val_loss: 1820783.6099\n",
      "Epoch 171/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1629194.4324 - val_loss: 1780475.7638\n",
      "Epoch 172/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1633419.9476 - val_loss: 1669543.7574\n",
      "Epoch 173/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1628514.4015 - val_loss: 1791339.8068\n",
      "Epoch 174/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1610284.6465 - val_loss: 1807418.7575\n",
      "Epoch 175/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1618138.5776 - val_loss: 1741785.6149\n",
      "Epoch 176/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1606965.8123 - val_loss: 1782916.5920\n",
      "Epoch 177/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1625415.1869 - val_loss: 1626668.2684\n",
      "Epoch 178/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1610633.3829 - val_loss: 1687854.0796\n",
      "Epoch 179/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1619269.6113 - val_loss: 1754014.0907\n",
      "Epoch 180/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1588184.7205 - val_loss: 1711666.3716\n",
      "Epoch 181/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1601030.9398 - val_loss: 1617951.8378\n",
      "Epoch 182/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1586391.8531 - val_loss: 1587780.6642\n",
      "Epoch 183/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1607115.4380 - val_loss: 1972374.9226\n",
      "Epoch 184/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 1597206.3062 - val_loss: 1569210.0910\n",
      "Epoch 185/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1618744.4736 - val_loss: 1747887.1236\n",
      "Epoch 186/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1586393.3417 - val_loss: 1767758.8411\n",
      "Epoch 187/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1605511.0742 - val_loss: 1656523.1350\n",
      "Epoch 188/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1602515.8557 - val_loss: 1884880.2024\n",
      "Epoch 189/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1602141.3611 - val_loss: 1702334.3701\n",
      "Epoch 190/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1583246.3999 - val_loss: 1627251.7002\n",
      "Epoch 191/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1590488.6254 - val_loss: 1726041.8650\n",
      "Epoch 192/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1575751.0176 - val_loss: 1693258.9553\n",
      "Epoch 193/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1593534.1245 - val_loss: 1683687.0325\n",
      "Epoch 194/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1591611.5265 - val_loss: 1796197.3268\n",
      "Epoch 195/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1578708.9341 - val_loss: 1763215.5932\n",
      "Epoch 196/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1577297.5337 - val_loss: 1619178.1221\n",
      "Epoch 197/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1584713.6690 - val_loss: 1599252.0243\n",
      "Epoch 198/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1580280.6499 - val_loss: 1722689.3570\n",
      "Epoch 199/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1575476.5557 - val_loss: 1705872.2380\n",
      "Epoch 200/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1566167.3638 - val_loss: 1687585.8289\n",
      "Epoch 201/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 1561410.1365 - val_loss: 1540557.5762\n",
      "Epoch 202/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1575065.2419 - val_loss: 1772674.3923\n",
      "Epoch 203/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1565328.4068 - val_loss: 1660050.8861\n",
      "Epoch 204/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1577850.7159 - val_loss: 1567951.1936\n",
      "Epoch 205/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1554955.3770 - val_loss: 1628637.0371\n",
      "Epoch 206/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1560861.2196 - val_loss: 1785305.7337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1555188.3872 - val_loss: 1678644.6277\n",
      "Epoch 208/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1561299.7682 - val_loss: 1851041.7945\n",
      "Epoch 209/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1540861.4388 - val_loss: 1545781.0830\n",
      "Epoch 210/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1579438.2044 - val_loss: 1649512.5843\n",
      "Epoch 211/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1556868.4636 - val_loss: 1856881.3072\n",
      "Epoch 212/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1583219.2300 - val_loss: 1961900.5860\n",
      "Epoch 213/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1547505.7984 - val_loss: 1585733.0222\n",
      "Epoch 214/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1545043.6103 - val_loss: 1572318.6576\n",
      "Epoch 215/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1547965.3381 - val_loss: 1733096.8174\n",
      "Epoch 216/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1529546.2438 - val_loss: 1786860.8667\n",
      "Epoch 217/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1545788.0399 - val_loss: 1582063.5807\n",
      "Epoch 218/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1535834.6947 - val_loss: 1888177.5945\n",
      "Epoch 219/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1543407.0343 - val_loss: 1851330.1266\n",
      "Epoch 220/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1529564.5419 - val_loss: 1609346.7885\n",
      "Epoch 221/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 1526635.5238 - val_loss: 1529545.4943\n",
      "Epoch 222/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1558823.7005 - val_loss: 1700769.3832\n",
      "Epoch 223/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1519602.5655 - val_loss: 1696945.3424\n",
      "Epoch 224/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1516255.2565 - val_loss: 1677850.9624\n",
      "Epoch 225/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1521386.8541 - val_loss: 1854628.5841\n",
      "Epoch 226/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1555528.0787 - val_loss: 1670083.7042\n",
      "Epoch 227/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1516843.0326 - val_loss: 1645662.8996\n",
      "Epoch 228/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1517161.5754 - val_loss: 1669560.4178\n",
      "Epoch 229/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1520126.9741 - val_loss: 1691874.2356\n",
      "Epoch 230/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1501600.3467 - val_loss: 1612895.1493\n",
      "Epoch 231/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1508902.9275 - val_loss: 1567165.4317\n",
      "Epoch 232/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1512521.9281 - val_loss: 1640514.7930\n",
      "Epoch 233/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1485447.3011 - val_loss: 1596954.0156\n",
      "Epoch 234/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1497882.7302 - val_loss: 1571772.4466\n",
      "Epoch 235/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1511053.5173 - val_loss: 1569850.5851\n",
      "Epoch 236/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1529838.7789 - val_loss: 1835251.2634\n",
      "Epoch 237/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1513111.6510 - val_loss: 1790949.8834\n",
      "Epoch 238/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1490622.6864 - val_loss: 1746858.6075\n",
      "Epoch 239/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 1474541.5877 - val_loss: 1510394.3908\n",
      "Epoch 240/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1507899.2830 - val_loss: 1724893.2605\n",
      "Epoch 241/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1492596.4928 - val_loss: 1694330.8080\n",
      "Epoch 242/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1500396.7207 - val_loss: 1681096.2566\n",
      "Epoch 243/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1479046.8434 - val_loss: 1643458.5849\n",
      "Epoch 244/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1486595.6789 - val_loss: 1965048.9290\n",
      "Epoch 245/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1465739.4781 - val_loss: 1856395.3783\n",
      "Epoch 246/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1482239.8758 - val_loss: 1716932.5572\n",
      "Epoch 247/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1487248.8324 - val_loss: 1624627.5585\n",
      "Epoch 248/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1480141.7706 - val_loss: 1940814.8864\n",
      "Epoch 249/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1488350.2786 - val_loss: 1564351.6066\n",
      "Epoch 250/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1454302.0160 - val_loss: 1648669.7606\n",
      "Epoch 251/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1471960.4023 - val_loss: 2100650.9621\n",
      "Epoch 252/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1517799.8689 - val_loss: 1695495.5461\n",
      "Epoch 253/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1449446.6995 - val_loss: 1781920.4697\n",
      "Epoch 254/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1451433.0863 - val_loss: 1901093.4143\n",
      "Epoch 255/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1484844.7946 - val_loss: 1643161.0687\n",
      "Epoch 256/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1448425.2829 - val_loss: 1781859.1853\n",
      "Epoch 257/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1473075.6708 - val_loss: 1531557.5411\n",
      "Epoch 258/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1465300.3739 - val_loss: 1724738.0929\n",
      "Epoch 259/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1476601.9948 - val_loss: 1520606.5160\n",
      "Epoch 260/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1468274.5988 - val_loss: 1621838.9614\n",
      "Epoch 261/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1460649.5078 - val_loss: 1594981.2222\n",
      "Epoch 262/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 1441515.4358 - val_loss: 1452829.4968\n",
      "Epoch 263/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1490737.8175 - val_loss: 1949054.8718\n",
      "Epoch 264/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1462728.9143 - val_loss: 1578465.0695\n",
      "Epoch 265/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1449102.5423 - val_loss: 1518781.1525\n",
      "Epoch 266/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1470188.5172 - val_loss: 1917688.0153\n",
      "Epoch 267/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1446109.3822 - val_loss: 1692946.7382\n",
      "Epoch 268/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1451669.4937 - val_loss: 1935450.5333\n",
      "Epoch 269/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1454550.1817 - val_loss: 1855417.4770\n",
      "Epoch 270/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1490307.8780 - val_loss: 1618439.5876\n",
      "Epoch 271/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1452878.5201 - val_loss: 1582447.8816\n",
      "Epoch 272/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1453403.4262 - val_loss: 1541663.7482\n",
      "Epoch 273/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1468883.5893 - val_loss: 1569692.8340\n",
      "Epoch 274/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1465203.3910 - val_loss: 1645052.7042\n",
      "Epoch 275/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1438145.5938 - val_loss: 1861567.0505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1467095.7623 - val_loss: 1548322.5316\n",
      "Epoch 277/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1441755.6942 - val_loss: 1903243.4494\n",
      "Epoch 278/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1433189.2338 - val_loss: 1592791.4258\n",
      "Epoch 279/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1417608.0769 - val_loss: 1796743.0053\n",
      "Epoch 280/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1431456.1939 - val_loss: 1761952.1671\n",
      "Epoch 281/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1443153.1131 - val_loss: 1636736.2985\n",
      "Epoch 282/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1447150.6374 - val_loss: 1750944.4365\n",
      "Epoch 283/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1414857.3809 - val_loss: 1656575.2518\n",
      "Epoch 284/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1429662.6588 - val_loss: 1580159.9253\n",
      "Epoch 285/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1451052.9890 - val_loss: 1902450.2426\n",
      "Epoch 286/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1439751.3697 - val_loss: 1600010.8563\n",
      "Epoch 287/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1434540.0691 - val_loss: 1796224.8070\n",
      "Epoch 288/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1429185.5352 - val_loss: 1668795.0417\n",
      "Epoch 289/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1426835.1088 - val_loss: 1804288.7608\n",
      "Epoch 290/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1420217.4330 - val_loss: 1623666.2958\n",
      "Epoch 291/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1416977.2484 - val_loss: 1728934.7709\n",
      "Epoch 292/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1425794.9579 - val_loss: 1752069.2120\n",
      "Epoch 293/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1430061.8519 - val_loss: 1672322.4615\n",
      "Epoch 294/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1441213.6362 - val_loss: 1808968.8225\n",
      "Epoch 295/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1419663.8235 - val_loss: 1972130.4123\n",
      "Epoch 296/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1424840.6541 - val_loss: 1620902.2457\n",
      "Epoch 297/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1433823.8978 - val_loss: 1754396.5369\n",
      "Epoch 298/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1422162.1986 - val_loss: 1753847.2773\n",
      "Epoch 299/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1423324.2582 - val_loss: 1629638.4972\n",
      "Epoch 300/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1456250.9463 - val_loss: 1607376.2539\n",
      "Epoch 301/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1418665.8174 - val_loss: 1846212.7449\n",
      "Epoch 302/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1417841.0700 - val_loss: 1453030.4861\n",
      "Epoch 303/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1452255.7488 - val_loss: 1643679.8991\n",
      "Epoch 304/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1432052.9723 - val_loss: 1491101.0718\n",
      "Epoch 305/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1440210.2822 - val_loss: 1726120.2346\n",
      "Epoch 306/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1421322.0105 - val_loss: 1532645.3949\n",
      "Epoch 307/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1413856.2199 - val_loss: 1810844.1556\n",
      "Epoch 308/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1419892.0290 - val_loss: 1699600.3837\n",
      "Epoch 309/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1415608.8412 - val_loss: 1675681.1492\n",
      "Epoch 310/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1415227.2198 - val_loss: 1906451.7429\n",
      "Epoch 311/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1425523.2231 - val_loss: 1916412.3847\n",
      "Epoch 312/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1449019.1754 - val_loss: 1619182.4437\n",
      "Epoch 313/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1420206.5758 - val_loss: 1755487.9067\n",
      "Epoch 314/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1425107.2063 - val_loss: 1579789.6076\n",
      "Epoch 315/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1429017.3148 - val_loss: 1738534.1172\n",
      "Epoch 316/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1411539.3250 - val_loss: 1556908.6059\n",
      "Epoch 317/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1406193.7731 - val_loss: 1695791.5842\n",
      "Epoch 318/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1422998.4355 - val_loss: 1871112.3425\n",
      "Epoch 319/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1452363.7072 - val_loss: 1595337.5629\n",
      "Epoch 320/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1406845.9412 - val_loss: 1810918.8988\n",
      "Epoch 321/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1412103.5296 - val_loss: 1610358.2752\n",
      "Epoch 322/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1409174.2347 - val_loss: 1745332.6212\n",
      "Epoch 323/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1406494.9312 - val_loss: 1701104.0262\n",
      "Epoch 324/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1413157.4924 - val_loss: 1645315.6690\n",
      "Epoch 325/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1411471.8672 - val_loss: 1619830.8707\n",
      "Epoch 326/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1421806.9987 - val_loss: 1511074.2640\n",
      "Epoch 327/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1438860.1423 - val_loss: 1709739.2879\n",
      "Epoch 328/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1403349.6140 - val_loss: 2003181.4510\n",
      "Epoch 329/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1449348.7350 - val_loss: 1906991.1705\n",
      "Epoch 330/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1464207.0760 - val_loss: 1739957.8137\n",
      "Epoch 331/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1445534.7491 - val_loss: 1767322.2854\n",
      "Epoch 332/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1412948.3049 - val_loss: 1922237.4150\n",
      "Epoch 333/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1407769.2227 - val_loss: 1596632.0894\n",
      "Epoch 334/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1407898.9609 - val_loss: 1942215.7244\n",
      "Epoch 335/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1407090.5633 - val_loss: 1746561.5071\n",
      "Epoch 336/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1413566.0767 - val_loss: 1598185.6904\n",
      "Epoch 337/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1407055.7390 - val_loss: 1853576.3101\n",
      "Epoch 338/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1402371.3933 - val_loss: 1543600.6334\n",
      "Epoch 339/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1430906.5925 - val_loss: 1821927.2081\n",
      "Epoch 340/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1389848.5153 - val_loss: 1564395.5679\n",
      "Epoch 341/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1402184.5102 - val_loss: 1920038.2498\n",
      "Epoch 342/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1417088.9809 - val_loss: 1787415.2824\n",
      "Epoch 343/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1415466.4073 - val_loss: 1647315.1983\n",
      "Epoch 344/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1429963.8172 - val_loss: 1627052.1404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 345/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1403936.9643 - val_loss: 1954745.6044\n",
      "Epoch 346/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1409847.9923 - val_loss: 1833441.0006\n",
      "Epoch 347/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1401308.1093 - val_loss: 1818586.1067\n",
      "Epoch 348/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1406377.7961 - val_loss: 1523568.3016\n",
      "Epoch 349/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1420404.7872 - val_loss: 1634343.1458\n",
      "Epoch 350/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1406310.1863 - val_loss: 1801783.8763\n",
      "Epoch 351/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1398536.0992 - val_loss: 1935545.2433\n",
      "Epoch 352/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1406948.3308 - val_loss: 1751532.9367\n",
      "Epoch 353/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1391781.3919 - val_loss: 1718035.5754\n",
      "Epoch 354/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1377171.4062 - val_loss: 1850414.2963\n",
      "Epoch 355/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1406599.1778 - val_loss: 1924525.7207\n",
      "Epoch 356/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1391451.1401 - val_loss: 1544097.1478\n",
      "Epoch 357/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1421955.8997 - val_loss: 1873958.0778\n",
      "Epoch 358/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1391711.1100 - val_loss: 1644609.3357\n",
      "Epoch 359/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1392609.5326 - val_loss: 1594317.8580\n",
      "Epoch 360/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1401067.3930 - val_loss: 1697331.0646\n",
      "Epoch 361/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1417813.6185 - val_loss: 1850830.6230\n",
      "Epoch 362/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1392270.3168 - val_loss: 1586657.9282\n",
      "Epoch 363/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1400429.7940 - val_loss: 1682737.5948\n",
      "Epoch 364/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1403817.3246 - val_loss: 1816633.1565\n",
      "Epoch 365/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1397862.2316 - val_loss: 1609620.3973\n",
      "Epoch 366/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1395198.7860 - val_loss: 1563738.9916\n",
      "Epoch 367/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1395699.2636 - val_loss: 1592405.6847\n",
      "Epoch 368/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1394355.0862 - val_loss: 1677071.8924\n",
      "Epoch 369/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1396267.3410 - val_loss: 1772144.2210\n",
      "Epoch 370/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1399111.9772 - val_loss: 1703166.5996\n",
      "Epoch 371/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1408058.8576 - val_loss: 1467819.2755\n",
      "Epoch 372/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1416005.0029 - val_loss: 1679291.6013\n",
      "Epoch 373/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1390130.3886 - val_loss: 1774892.3010\n",
      "Epoch 374/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1387911.3251 - val_loss: 1733802.0632\n",
      "Epoch 375/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 1401268.9157 - val_loss: 1428284.3824\n",
      "Epoch 376/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1418348.7801 - val_loss: 1629414.1241\n",
      "Epoch 377/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1383217.0298 - val_loss: 1670532.6854\n",
      "Epoch 378/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1391630.5653 - val_loss: 1777360.7654\n",
      "Epoch 379/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1375265.1859 - val_loss: 1653234.3525\n",
      "Epoch 380/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1395069.9552 - val_loss: 1639562.1892\n",
      "Epoch 381/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1387005.5612 - val_loss: 1830922.5785\n",
      "Epoch 382/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1433899.4520 - val_loss: 1660813.2880\n",
      "Epoch 383/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1377466.7708 - val_loss: 1638921.8748\n",
      "Epoch 384/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1385343.8449 - val_loss: 1667836.0872\n",
      "Epoch 385/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1403583.4687 - val_loss: 1469161.9351\n",
      "Epoch 386/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1396835.0029 - val_loss: 1638374.9871\n",
      "Epoch 387/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1393696.9331 - val_loss: 1799930.9002\n",
      "Epoch 388/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1373669.7113 - val_loss: 1535290.8547\n",
      "Epoch 389/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1410166.3159 - val_loss: 1667099.8259\n",
      "Epoch 390/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1386419.7173 - val_loss: 1596390.1633\n",
      "Epoch 391/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1386338.0620 - val_loss: 1743555.4197\n",
      "Epoch 392/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1387132.1127 - val_loss: 1663735.8858\n",
      "Epoch 393/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1370065.3056 - val_loss: 1867524.9881\n",
      "Epoch 394/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1388975.6650 - val_loss: 1650644.5742\n",
      "Epoch 395/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1381528.3561 - val_loss: 1677064.7771\n",
      "Epoch 396/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1401993.3450 - val_loss: 1928474.3349\n",
      "Epoch 397/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1397378.3144 - val_loss: 1762229.2644\n",
      "Epoch 398/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1377729.3425 - val_loss: 1966047.3799\n",
      "Epoch 399/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1399283.9339 - val_loss: 1658612.5969\n",
      "Epoch 400/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1381235.8201 - val_loss: 1697487.8183\n",
      "Epoch 401/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1388620.8246 - val_loss: 1792564.6670\n",
      "Epoch 402/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1380495.5468 - val_loss: 1840535.6475\n",
      "Epoch 403/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1390720.7962 - val_loss: 1804552.6653\n",
      "Epoch 404/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1391704.9604 - val_loss: 1808196.7903\n",
      "Epoch 405/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1386895.2117 - val_loss: 1650106.9697\n",
      "Epoch 406/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1368264.5670 - val_loss: 1607326.3639\n",
      "Epoch 407/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1389888.7255 - val_loss: 1579001.6533\n",
      "Epoch 408/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1385735.0560 - val_loss: 1873711.3834\n",
      "Epoch 409/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1400096.0692 - val_loss: 2103801.7341\n",
      "Epoch 410/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1446537.2875 - val_loss: 1766304.6505\n",
      "Epoch 411/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1391437.9948 - val_loss: 1820524.6853\n",
      "Epoch 412/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1373450.5193 - val_loss: 1620923.8175\n",
      "Epoch 413/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1380678.5284 - val_loss: 1911223.7400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 414/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1406996.3348 - val_loss: 1852798.8175\n",
      "Epoch 415/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1383675.8937 - val_loss: 1932202.9554\n",
      "Epoch 416/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1397806.4569 - val_loss: 1975635.9216\n",
      "Epoch 417/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1396743.9592 - val_loss: 1560099.4985\n",
      "Epoch 418/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1385463.0253 - val_loss: 1551071.2335\n",
      "Epoch 419/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1380137.5395 - val_loss: 1598817.6476\n",
      "Epoch 420/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1372319.1945 - val_loss: 1666906.3225\n",
      "Epoch 421/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1401459.2639 - val_loss: 1620790.9609\n",
      "Epoch 422/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1374060.9473 - val_loss: 1832551.7287\n",
      "Epoch 423/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1395545.6367 - val_loss: 1523867.8829\n",
      "Epoch 424/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1380967.5200 - val_loss: 1695977.3352\n",
      "Epoch 425/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1372377.4722 - val_loss: 1791607.6071\n",
      "Epoch 426/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1368866.3454 - val_loss: 1830576.0428\n",
      "Epoch 427/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1387228.4646 - val_loss: 1580421.9591\n",
      "Epoch 428/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1425103.0320 - val_loss: 1923708.5775\n",
      "Epoch 429/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1391775.0301 - val_loss: 1729380.2039\n",
      "Epoch 430/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1376786.3052 - val_loss: 1903716.4707\n",
      "Epoch 431/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1375572.5030 - val_loss: 1692193.7559\n",
      "Epoch 432/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1382568.4425 - val_loss: 1524830.8350\n",
      "Epoch 433/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1373058.2768 - val_loss: 1724773.9443\n",
      "Epoch 434/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1381553.1366 - val_loss: 1571757.7651\n",
      "Epoch 435/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1395347.7708 - val_loss: 1902205.0508\n",
      "Epoch 436/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1397599.6729 - val_loss: 1594390.6304\n",
      "Epoch 437/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1394741.8978 - val_loss: 1628630.9246\n",
      "Epoch 438/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1369806.3007 - val_loss: 1724449.2207\n",
      "Epoch 439/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1377388.2804 - val_loss: 1645030.3474\n",
      "Epoch 440/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1377629.3368 - val_loss: 1665538.4260\n",
      "Epoch 441/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1376191.0831 - val_loss: 1658233.8205\n",
      "Epoch 442/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1399891.9155 - val_loss: 1676894.6624\n",
      "Epoch 443/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1398541.8968 - val_loss: 1558411.0316\n",
      "Epoch 444/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1381686.3265 - val_loss: 1790172.6680\n",
      "Epoch 445/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1395083.3724 - val_loss: 1831069.4756\n",
      "Epoch 446/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1397842.3397 - val_loss: 1630703.3758\n",
      "Epoch 447/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1373684.7170 - val_loss: 1693457.5521\n",
      "Epoch 448/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1360594.4069 - val_loss: 1893774.8257\n",
      "Epoch 449/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1365548.6905 - val_loss: 1830843.7040\n",
      "Epoch 450/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1379893.0905 - val_loss: 1647907.1169\n",
      "Epoch 451/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1367170.5434 - val_loss: 1814085.6009\n",
      "Epoch 452/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1369563.2060 - val_loss: 1909721.9100\n",
      "Epoch 453/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1382239.8720 - val_loss: 1632066.4472\n",
      "Epoch 454/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1378144.2083 - val_loss: 1558010.5318\n",
      "Epoch 455/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1372968.5672 - val_loss: 1679818.1115\n",
      "Epoch 456/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1379936.8370 - val_loss: 1692377.3544\n",
      "Epoch 457/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1374923.0091 - val_loss: 1617511.7756\n",
      "Epoch 458/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1372940.8068 - val_loss: 1581507.7920\n",
      "Epoch 459/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1375158.0634 - val_loss: 2006561.5628\n",
      "Epoch 460/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1408443.8389 - val_loss: 1531013.8907\n",
      "Epoch 461/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1384942.6194 - val_loss: 1599377.6179\n",
      "Epoch 462/600\n",
      "17987/17987 [==============================] - 0s 10us/step - loss: 1377096.2053 - val_loss: 1633372.5396\n",
      "Epoch 463/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1366629.1400 - val_loss: 1824250.2961\n",
      "Epoch 464/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1396811.2373 - val_loss: 2001441.7360\n",
      "Epoch 465/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1424790.5488 - val_loss: 1533772.2364\n",
      "Epoch 466/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1386695.1852 - val_loss: 1589538.4802\n",
      "Epoch 467/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1376307.4190 - val_loss: 1541181.3526\n",
      "Epoch 468/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1373216.5850 - val_loss: 1776730.5470\n",
      "Epoch 469/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1368584.4893 - val_loss: 1784402.5606\n",
      "Epoch 470/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1357615.4778 - val_loss: 1617363.2100\n",
      "Epoch 471/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1368003.8456 - val_loss: 1650572.8008\n",
      "Epoch 472/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1372899.9630 - val_loss: 1713749.7918\n",
      "Epoch 473/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1368287.2731 - val_loss: 1630491.7233\n",
      "Epoch 474/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1400718.2772 - val_loss: 1897710.4967\n",
      "Epoch 475/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1381960.4003 - val_loss: 1457658.0269\n",
      "Epoch 476/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1390230.2945 - val_loss: 1717754.5992\n",
      "Epoch 477/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1377114.2175 - val_loss: 1616005.8842\n",
      "Epoch 478/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1382042.7996 - val_loss: 1436525.6091\n",
      "Epoch 479/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1397940.4454 - val_loss: 1804732.8516\n",
      "Epoch 480/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1365172.5899 - val_loss: 1842070.5960\n",
      "Epoch 481/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1377015.2762 - val_loss: 1750887.9485\n",
      "Epoch 482/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1346305.4291 - val_loss: 1678413.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 483/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1381259.1104 - val_loss: 1480797.7860\n",
      "Epoch 484/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1405177.1194 - val_loss: 1732530.3589\n",
      "Epoch 485/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1389121.1802 - val_loss: 2054363.1626\n",
      "Epoch 486/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1371781.3316 - val_loss: 1740592.7386\n",
      "Epoch 487/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1366988.5923 - val_loss: 1612517.7032\n",
      "Epoch 488/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1363768.0342 - val_loss: 1844109.6119\n",
      "Epoch 489/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1370903.9505 - val_loss: 1906538.6311\n",
      "Epoch 490/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1386151.9902 - val_loss: 1776618.4272\n",
      "Epoch 491/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1372272.9734 - val_loss: 1656032.3180\n",
      "Epoch 492/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1361210.6193 - val_loss: 1901481.0341\n",
      "Epoch 493/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1379099.3150 - val_loss: 1569141.7946\n",
      "Epoch 494/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1373426.1093 - val_loss: 1677802.2738\n",
      "Epoch 495/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1379864.6489 - val_loss: 1719987.8337\n",
      "Epoch 496/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1390427.1702 - val_loss: 1506104.3387\n",
      "Epoch 497/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1387606.5594 - val_loss: 1726301.6823\n",
      "Epoch 498/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1368625.1573 - val_loss: 1728145.1251\n",
      "Epoch 499/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1351964.4089 - val_loss: 1814569.6560\n",
      "Epoch 500/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1370637.2193 - val_loss: 1797961.2928\n",
      "Epoch 501/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1366787.6015 - val_loss: 1860963.2792\n",
      "Epoch 502/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1354297.9876 - val_loss: 1761126.5174\n",
      "Epoch 503/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1369195.8207 - val_loss: 1562008.2970\n",
      "Epoch 504/600\n",
      "17987/17987 [==============================] - 0s 8us/step - loss: 1360380.1190 - val_loss: 1800568.4987\n",
      "Epoch 505/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1361003.0281 - val_loss: 1660011.7719\n",
      "Epoch 506/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1357079.5221 - val_loss: 1813779.7576\n",
      "Epoch 507/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1356320.3736 - val_loss: 1795901.0561\n",
      "Epoch 508/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1370680.7691 - val_loss: 1855986.7396\n",
      "Epoch 509/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1359979.0843 - val_loss: 1778504.6027\n",
      "Epoch 510/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1356072.9496 - val_loss: 1871994.0041\n",
      "Epoch 511/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1365220.0664 - val_loss: 1679677.6831\n",
      "Epoch 512/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1362460.2757 - val_loss: 1653188.6660\n",
      "Epoch 513/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1357217.4208 - val_loss: 1721509.4210\n",
      "Epoch 514/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1365956.2098 - val_loss: 1886572.5298\n",
      "Epoch 515/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1346978.7757 - val_loss: 1647143.0590\n",
      "Epoch 516/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1354353.4202 - val_loss: 1567964.1764\n",
      "Epoch 517/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1347180.1299 - val_loss: 1877220.2553\n",
      "Epoch 518/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1375655.5602 - val_loss: 1833161.3571\n",
      "Epoch 519/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1383282.8549 - val_loss: 1779307.0233\n",
      "Epoch 520/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1371260.7171 - val_loss: 1630378.9340\n",
      "Epoch 521/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1381390.5872 - val_loss: 1919951.4849\n",
      "Epoch 522/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1357292.0584 - val_loss: 1667073.5336\n",
      "Epoch 523/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1362108.6337 - val_loss: 1532069.5900\n",
      "Epoch 524/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1376690.0096 - val_loss: 1702439.9160\n",
      "Epoch 525/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1359683.2218 - val_loss: 1855066.9135\n",
      "Epoch 526/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1361443.7569 - val_loss: 1881591.0346\n",
      "Epoch 527/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1373921.6019 - val_loss: 1683351.8534\n",
      "Epoch 528/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1351698.1226 - val_loss: 1667069.4824\n",
      "Epoch 529/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1360875.4906 - val_loss: 1750719.1797\n",
      "Epoch 530/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1372443.3603 - val_loss: 1566172.7373\n",
      "Epoch 531/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1362862.8165 - val_loss: 1878576.3144\n",
      "Epoch 532/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1364567.4551 - val_loss: 1508448.3477\n",
      "Epoch 533/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1363183.2090 - val_loss: 1576446.2805\n",
      "Epoch 534/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1341068.4075 - val_loss: 1575356.0534\n",
      "Epoch 535/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1347172.0082 - val_loss: 1727016.6983\n",
      "Epoch 536/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1377429.2760 - val_loss: 1662626.8525\n",
      "Epoch 537/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1353853.3949 - val_loss: 1738971.0923\n",
      "Epoch 538/600\n",
      "17987/17987 [==============================] - 0s 11us/step - loss: 1356659.3910 - val_loss: 1666423.4872\n",
      "Epoch 539/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1374296.7674 - val_loss: 1716253.6055\n",
      "Epoch 540/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1353741.2980 - val_loss: 1680147.7598\n",
      "Epoch 541/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1359424.1955 - val_loss: 1667784.9846\n",
      "Epoch 542/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1341141.9656 - val_loss: 1769711.9247\n",
      "Epoch 543/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1359534.8339 - val_loss: 1644495.5958\n",
      "Epoch 544/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1352139.9702 - val_loss: 2023166.9774\n",
      "Epoch 545/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1369456.6714 - val_loss: 1500938.8172\n",
      "Epoch 546/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1350675.6908 - val_loss: 1761130.6175\n",
      "Epoch 547/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1365484.5907 - val_loss: 1927808.0390\n",
      "Epoch 548/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1360421.7406 - val_loss: 1888556.4794\n",
      "Epoch 549/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1361874.7863 - val_loss: 1540560.7879\n",
      "Epoch 550/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1362237.8425 - val_loss: 2053217.0119\n",
      "Epoch 551/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1411615.4786 - val_loss: 1761955.1721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 552/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1365300.2969 - val_loss: 1524844.3833\n",
      "Epoch 553/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1373971.0335 - val_loss: 1622353.8544\n",
      "Epoch 554/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1355614.7862 - val_loss: 1734766.9245\n",
      "Epoch 555/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1341197.7769 - val_loss: 1719174.5857\n",
      "Epoch 556/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1350953.3940 - val_loss: 1572821.8462\n",
      "Epoch 557/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1342985.7211 - val_loss: 1616591.6880\n",
      "Epoch 558/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1357931.3170 - val_loss: 1838013.5917\n",
      "Epoch 559/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1354217.5157 - val_loss: 1539923.2739\n",
      "Epoch 560/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1351490.5822 - val_loss: 1857474.3779\n",
      "Epoch 561/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1355249.7475 - val_loss: 1723009.3477\n",
      "Epoch 562/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1366341.0297 - val_loss: 1981516.8263\n",
      "Epoch 563/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1370776.8788 - val_loss: 1646821.8676\n",
      "Epoch 564/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1361025.7316 - val_loss: 1738751.0600\n",
      "Epoch 565/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1347205.3250 - val_loss: 1768430.2938\n",
      "Epoch 566/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1357127.6125 - val_loss: 1567524.1270\n",
      "Epoch 567/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1343176.3252 - val_loss: 1810429.8602\n",
      "Epoch 568/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1388353.1255 - val_loss: 1700628.9373\n",
      "Epoch 569/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1347482.7062 - val_loss: 1630639.7239\n",
      "Epoch 570/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1362060.6030 - val_loss: 1511946.9850\n",
      "Epoch 571/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1358621.1057 - val_loss: 1773791.0463\n",
      "Epoch 572/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1360675.7591 - val_loss: 1459162.4339\n",
      "Epoch 573/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1366812.6228 - val_loss: 1769988.3207\n",
      "Epoch 574/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1350692.5184 - val_loss: 1745215.0992\n",
      "Epoch 575/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1340912.8297 - val_loss: 1778270.7260\n",
      "Epoch 576/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1351868.0344 - val_loss: 1638071.2165\n",
      "Epoch 577/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1346544.4237 - val_loss: 1815390.6702\n",
      "Epoch 578/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1371774.2261 - val_loss: 1538241.9576\n",
      "Epoch 579/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1364429.0190 - val_loss: 1574386.1988\n",
      "Epoch 580/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1367470.9339 - val_loss: 1857984.2157\n",
      "Epoch 581/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1356302.3649 - val_loss: 1673776.4676\n",
      "Epoch 582/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1346982.6328 - val_loss: 1757034.5792\n",
      "Epoch 583/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1362778.3127 - val_loss: 2100873.7650\n",
      "Epoch 584/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1366607.4580 - val_loss: 1696305.4295\n",
      "Epoch 585/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1369669.4600 - val_loss: 1649375.2091\n",
      "Epoch 586/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1344304.6375 - val_loss: 1633731.1679\n",
      "Epoch 587/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1342052.5237 - val_loss: 1770664.2479\n",
      "Epoch 588/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1343732.8443 - val_loss: 1542072.1180\n",
      "Epoch 589/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1398119.7630 - val_loss: 1544658.8158\n",
      "Epoch 590/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1369373.4923 - val_loss: 1596461.4529\n",
      "Epoch 591/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1345858.9856 - val_loss: 1814487.6661\n",
      "Epoch 592/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1358134.2443 - val_loss: 1911855.4415\n",
      "Epoch 593/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1354029.1444 - val_loss: 1861876.5018\n",
      "Epoch 594/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1359410.7509 - val_loss: 1527289.0342\n",
      "Epoch 595/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1358494.0876 - val_loss: 1598226.6937\n",
      "Epoch 596/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1334342.7676 - val_loss: 1612284.1351\n",
      "Epoch 597/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1349597.8651 - val_loss: 1679595.3836\n",
      "Epoch 598/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1340177.9523 - val_loss: 1557497.4955\n",
      "Epoch 599/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1340072.1209 - val_loss: 1726934.0369\n",
      "Epoch 600/600\n",
      "17987/17987 [==============================] - 0s 9us/step - loss: 1356494.2832 - val_loss: 1756830.7699\n"
     ]
    }
   ],
   "source": [
    "averaged_models = AveragingModels(models = ((GBoost, 1), (model_lgb, 1), (NNClassifier(), 1)))\n",
    "averaged_models.fit(train.values, y_train)\n",
    "averaged_models_pred = averaged_models.predict(train.values)\n",
    "averaged_models_pred = averaged_models.predict(test.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1099037.5257238343\n"
     ]
    }
   ],
   "source": [
    "print(rmsle(y_train, stacked_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "434ca649-2fa0-46a5-ab29-7f403448ddf7",
    "_execution_state": "idle",
    "_uuid": "c9f02561da543f4901dcd2051acbd6c197108dd5"
   },
   "source": [
    "**Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_cell_guid": "3db46af9-e18a-43bb-9699-45b851f835e5",
    "_execution_state": "idle",
    "_uuid": "93f6915cf25c7bb6b6fa6e74ad7b853387ac1db5"
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['id'] = test_ID\n",
    "sub['price'] = averaged_models_pred\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
